{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize K-Means (K=10) Cluster for full-bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# modify these for your own computer\n",
    "repo_directory = '/Users/Michael/Documents/GitHub/law-net/'\n",
    "\n",
    "data_dir = '/Users/Michael/Desktop/network_data/'\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cPickle  as pickle\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "\n",
    "\n",
    "# graph package\n",
    "import igraph as ig\n",
    "\n",
    "\n",
    "# stat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
    "from sklearn.metrics import adjusted_mutual_info_score as ami\n",
    "from sklearn.metrics import mutual_info_score as mi\n",
    "from sklearn.metrics import adjusted_rand_score as ar\n",
    "from sklearn.metrics import calinski_harabaz_score as ch # (X, labels)\n",
    "from sklearn.metrics import completeness_score as cs # metric isn't symmetric (labels_true, labels_predicted)\n",
    "from sklearn.metrics import fowlkes_mallows_score as fm\n",
    "from sklearn.metrics import homogeneity_completeness_v_measure as hcvm\n",
    "from sklearn.metrics import homogeneity_score as hs # metric isn't symmetric (labels_true, labels_predicted)\n",
    "from sklearn.metrics import silhouette_score as ss # (X, labels)\n",
    "from sklearn.metrics import silhouette_samples as ss2 # (X, labels)\n",
    "from sklearn.metrics import v_measure_score as vm\n",
    "\n",
    "import scipy.sparse\n",
    "import random\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "# our code\n",
    "sys.path.append(repo_directory + 'code/')\n",
    "from summarize_clusters import *\n",
    "from helpful_functions import *\n",
    "\n",
    "sys.path.append(repo_directory + 'vertex_metrics_experiment/code/')\n",
    "from bag_of_words import * \n",
    "\n",
    "# which network to download data for\n",
    "network_name = 'scotus' # 'federal', 'ca1', etc\n",
    "\n",
    "\n",
    "# some sub directories that get used\n",
    "raw_dir = data_dir + 'raw/'\n",
    "subnet_dir = data_dir + network_name + '/'\n",
    "text_dir = subnet_dir + 'textfiles/'\n",
    "nlp_dir = subnet_dir + 'nlp/'\n",
    "nlp_sub_dir = nlp_dir + 'bow_tfidf/' #tfidf matrix (and other info, i.e. vocab) computed from bag-of-words matrix\n",
    "nlp_bow_dir = nlp_dir + 'bow/' #bag-of-words matrix (and other info, i.e. vocab)\n",
    "nlp_df_sub_dir = nlp_dir + 'bow_tfidf_df/'\n",
    "\n",
    "# csv location\n",
    "csv_dir = \"C:/Users/Michael/Documents/GitHub/law-net/csv/\"\n",
    "csv_dir_mod = \"C:/Users/Michael/Documents/GitHub/law-net/csv/summarize_modularity/\"\n",
    "csv_dir_walk = \"C:/Users/Michael/Documents/GitHub/law-net/csv/summarize_walktrap/\"\n",
    "csv_dir_full_tfidf_km10 = \"C:/Users/Michael/Documents/GitHub/law-net/csv/summarize_full_tfidf_km10/\"\n",
    "csv_dir_full_tfidf_km100 = \"C:/Users/Michael/Documents/GitHub/law-net/csv/summarize_full_tfidf_km100/\"\n",
    "csv_dir_full_bow_km10 = \"C:/Users/Michael/Documents/GitHub/law-net/csv/summarize_full_bow_km10/\"\n",
    "\n",
    "# all the file paths for .txt files\n",
    "file_paths = glob.glob(text_dir + '*.txt')\n",
    "\n",
    "# all opinions\n",
    "all_the_opinions = all_opinions(file_paths)\n",
    "\n",
    "# clusters directory\n",
    "clusters_dir = \"C:/Users/Michael/Desktop/network_data/raw/scotus/clusters/\"\n",
    "\n",
    "# jupyter notebook settings\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load bow vectors\n",
    "**bow_matrix** = (row_index, column_index): token/word-count value (**CSR FORMAT**)  \n",
    "**op_id_to_bow_id** = opinion_id (corresponds to row indices)  \n",
    "**vocab** = all the words in bow_matrix (correspond to column indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_bow(nlp_dir):\n",
    "    \"\"\"\n",
    "    bow_matrix, op_id_to_bow_id = load_bow(nlp_dir)\n",
    "    \"\"\"\n",
    "    bow_matrix = load_sparse_csr(nlp_dir + 'bag_of_words_matrix.npz')\n",
    "\n",
    "    with open(nlp_dir + 'op_id_to_bow_id.p', 'rb') as f:\n",
    "        op_id_to_bow_id = pickle.load(f)\n",
    "\n",
    "    with open(nlp_dir + 'vocab.p', 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "\n",
    "    return bow_matrix, op_id_to_bow_id, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow_matrix, op_id_to_bow_id, vocab = load_bow(nlp_bow_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<27885x567570 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 20817470 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mod</th>\n",
       "      <th>wt</th>\n",
       "      <th>km_10</th>\n",
       "      <th>km_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145658</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89370</td>\n",
       "      <td>3</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89371</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89372</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89373</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  mod   wt  km_10  km_100\n",
       "0      145658    1    5      0      32\n",
       "1       89370    3  294      0      32\n",
       "2       89371    0   35      0      32\n",
       "3       89372    0    3      0      32\n",
       "4       89373    0    3      0      32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = pd.read_csv(csv_dir + 'clusters_full_bow.csv')\n",
    "clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145658    0\n",
       "89370     0\n",
       "89371     0\n",
       "89372     0\n",
       "89373     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_tfidf_clusters = clusters['km_10'].tolist()\n",
    "\n",
    "nlp_clusters = pd.Series(nlp_tfidf_clusters, index=op_id_to_bow_id)\n",
    "nlp_clusters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the top 5 biggest clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 0 : 14270 opinions\n",
      "cluster 8 : 7428 opinions\n",
      "cluster 4 : 2940 opinions\n",
      "cluster 7 : 1232 opinions\n",
      "cluster 3 : 1111 opinions\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "dict_top_n_clusters = dictionary of top K clusters \n",
    "                      (key=cluster #, value=opinions in cluster)\n",
    "                      \n",
    "biggest_n_clusters = list of top K clusters (int)\n",
    "'''\n",
    "\n",
    "dict_top_n_clusters, biggest_n_clusters = get_top_n_clusters(5, 10, nlp_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top K Words of Each Cluster\n",
    "This function summarizes a set of opinions by returning the words that appear in these opinions with the highest tf-idf scores.\n",
    "\n",
    "# Top K Words ($\\mu_{cluster}$) of Each Cluster\n",
    "compute the mean tf-idf vector of the cluster, return the top K words from this mean vector\n",
    "\n",
    "# Top K Words ($\\mu_{cluster} - \\mu_{complement}$ ) of Each Cluster\n",
    "compute the mean tf-idf vector of the cluster and also of the complement of the cluster,  \n",
    "take the difference mu_cluster - mu_complement, return the top K words in this difference\n",
    "\n",
    "# Most Relevant Opinion of Each Cluster\n",
    "compute the mean tf-idf vector, return the document in the cluster closet to the mean  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 0 Summary (14270 opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14270, 3)\n",
      "Wall time: 7.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "opinion_names = []\n",
    "opinion_dates = []\n",
    "opinion_links = []\n",
    "\n",
    "for i in dict_top_n_clusters[0]:\n",
    "    try:\n",
    "        with open(clusters_dir + i + \".json\") as data_file:\n",
    "            data = json.load(data_file)\n",
    "    except IOError:\n",
    "        pass\n",
    "        #name, date, link = case_info2(i)\n",
    "        #opinion_names.append(name)\n",
    "        #opinion_dates.append(date)\n",
    "        #opinion_links.append(link)\n",
    "        \n",
    "    name = data['case_name'].encode('utf-8')\n",
    "    date = data['date_filed'].encode('utf-8')\n",
    "    link = 'https://www.courtlistener.com' + data['absolute_url'].encode('utf-8')\n",
    "    \n",
    "    opinion_names.append(name)\n",
    "    opinion_dates.append(date)\n",
    "    opinion_links.append(link)\n",
    "    \n",
    "cluster_info = pd.DataFrame()\n",
    "cluster_info['names'] = opinion_names\n",
    "cluster_info['dates'] = opinion_dates\n",
    "cluster_info['url'] = opinion_links\n",
    "\n",
    "cluster_info.to_csv(csv_dir_full_bow_km10 + \"cluster_0.csv\")\n",
    "\n",
    "print cluster_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>names</th>\n",
       "      <th>dates</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DaimlerChrysler Corp. v. Cuno</td>\n",
       "      <td>2006-05-15</td>\n",
       "      <td>https://www.courtlistener.com/opinion/145658/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Garfielde v. United States</td>\n",
       "      <td>1876-05-18</td>\n",
       "      <td>https://www.courtlistener.com/opinion/89370/ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Whiteside v. United States</td>\n",
       "      <td>1876-11-27</td>\n",
       "      <td>https://www.courtlistener.com/opinion/89371/wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Barkley v. Levee Commissioners</td>\n",
       "      <td>1876-12-18</td>\n",
       "      <td>https://www.courtlistener.com/opinion/89372/ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Broughton v. Pensacola</td>\n",
       "      <td>1876-12-18</td>\n",
       "      <td>https://www.courtlistener.com/opinion/89373/br...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           names       dates  \\\n",
       "0           0   DaimlerChrysler Corp. v. Cuno  2006-05-15   \n",
       "1           1      Garfielde v. United States  1876-05-18   \n",
       "2           2      Whiteside v. United States  1876-11-27   \n",
       "3           3  Barkley v. Levee Commissioners  1876-12-18   \n",
       "4           4          Broughton v. Pensacola  1876-12-18   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.courtlistener.com/opinion/145658/d...  \n",
       "1  https://www.courtlistener.com/opinion/89370/ga...  \n",
       "2  https://www.courtlistener.com/opinion/89371/wh...  \n",
       "3  https://www.courtlistener.com/opinion/89372/ba...  \n",
       "4  https://www.courtlistener.com/opinion/89373/br...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_info = pd.read_csv(csv_dir_full_bow_km10 + 'cluster_0.csv')\n",
    "cluster_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "Wall time: 3min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=1000 # number of words to get\n",
    "\n",
    "top_words = top_k_words(dict_top_n_clusters[0], k, bow_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[0], k, bow_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[0], all_the_opinions, k, bow_matrix, op_id_to_bow_id, vocab)\n",
    "most_relev_op = document_closest_to_mean(dict_top_n_clusters[0], bow_matrix, op_id_to_bow_id)\n",
    "\n",
    "top_words = [x.encode('utf-8') for x in top_words]\n",
    "top_words_from_mean = [x.encode('utf-8') for x in top_words_from_mean]\n",
    "top_words_from_diff = [x.encode('utf-8') for x in top_words_from_diff]\n",
    "\n",
    "#print '\\x1b[1;31m' + \"Top K Words:\" + '\\x1b[0m', top_words\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster):\" + '\\x1b[0m', top_words_from_mean\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster - Mu_Complement):\" + '\\x1b[0m', top_words_from_diff\n",
    "#print '\\x1b[1;31m' + \"Most Relevent Opinion:\" + '\\x1b[0m', most_relev_op\n",
    "\n",
    "cluster_summary = pd.DataFrame()\n",
    "cluster_summary['top_words'] = top_words\n",
    "cluster_summary['top_words_from_mean'] = top_words_from_mean\n",
    "cluster_summary['top_words_from_diff'] = top_words_from_diff\n",
    "cluster_summary['most_relev_op'] = most_relev_op\n",
    "\n",
    "cluster_summary.to_csv(csv_dir_full_bow_km10 + \"cluster_0_summary.csv\")\n",
    "\n",
    "print cluster_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>top_words</th>\n",
       "      <th>top_words_from_mean</th>\n",
       "      <th>top_words_from_diff</th>\n",
       "      <th>most_relev_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>state</td>\n",
       "      <td>court</td>\n",
       "      <td>court</td>\n",
       "      <td>104977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>feet</td>\n",
       "      <td>state</td>\n",
       "      <td>contract</td>\n",
       "      <td>104977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>law</td>\n",
       "      <td>v</td>\n",
       "      <td>prison</td>\n",
       "      <td>104977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>punish</td>\n",
       "      <td>case</td>\n",
       "      <td>habea</td>\n",
       "      <td>104977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>contract</td>\n",
       "      <td>act</td>\n",
       "      <td>error</td>\n",
       "      <td>104977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 top_words top_words_from_mean top_words_from_diff  most_relev_op\n",
       "0           0     state               court               court         104977\n",
       "1           1      feet               state            contract         104977\n",
       "2           2       law                   v              prison         104977\n",
       "3           3    punish                case               habea         104977\n",
       "4           4  contract                 act               error         104977"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_summary = pd.read_csv(csv_dir_full_bow_km10 + 'cluster_0_summary.csv')\n",
    "cluster_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 8 Summary (7248 opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7428, 3)\n",
      "Wall time: 3.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "opinion_names = []\n",
    "opinion_dates = []\n",
    "opinion_links = []\n",
    "\n",
    "for i in dict_top_n_clusters[8]:\n",
    "    try:\n",
    "        with open(clusters_dir + i + \".json\") as data_file:\n",
    "            data = json.load(data_file)\n",
    "    except IOError:\n",
    "        pass\n",
    "        #name, date, link = case_info2(i)\n",
    "        #opinion_names.append(name)\n",
    "        #opinion_dates.append(date)\n",
    "        #opinion_links.append(link)\n",
    "        \n",
    "    name = data['case_name'].encode('utf-8')\n",
    "    date = data['date_filed'].encode('utf-8')\n",
    "    link = 'https://www.courtlistener.com' + data['absolute_url'].encode('utf-8')\n",
    "    \n",
    "    opinion_names.append(name)\n",
    "    opinion_dates.append(date)\n",
    "    opinion_links.append(link)\n",
    "    \n",
    "cluster_info = pd.DataFrame()\n",
    "cluster_info['names'] = opinion_names\n",
    "cluster_info['dates'] = opinion_dates\n",
    "cluster_info['url'] = opinion_links\n",
    "\n",
    "cluster_info.to_csv(csv_dir_full_bow_km10 + \"cluster_8.csv\")\n",
    "\n",
    "print cluster_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>names</th>\n",
       "      <th>dates</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Dalton v. Jennings</td>\n",
       "      <td>1876-12-18</td>\n",
       "      <td>https://www.courtlistener.com/opinion/89374/da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The\" Atlas\"</td>\n",
       "      <td>1876-11-27</td>\n",
       "      <td>https://www.courtlistener.com/opinion/89379/th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Wilson v. Daniel</td>\n",
       "      <td>1798-08-17</td>\n",
       "      <td>https://www.courtlistener.com/opinion/2224796/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Griffin v. McCoach</td>\n",
       "      <td>1941-06-02</td>\n",
       "      <td>https://www.courtlistener.com/opinion/103543/g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Rogers v. Ritter</td>\n",
       "      <td>1871-11-20</td>\n",
       "      <td>https://www.courtlistener.com/opinion/88395/ro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               names       dates  \\\n",
       "0           0  Dalton v. Jennings  1876-12-18   \n",
       "1           1         The\" Atlas\"  1876-11-27   \n",
       "2           2    Wilson v. Daniel  1798-08-17   \n",
       "3           3  Griffin v. McCoach  1941-06-02   \n",
       "4           4    Rogers v. Ritter  1871-11-20   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.courtlistener.com/opinion/89374/da...  \n",
       "1  https://www.courtlistener.com/opinion/89379/th...  \n",
       "2  https://www.courtlistener.com/opinion/2224796/...  \n",
       "3  https://www.courtlistener.com/opinion/103543/g...  \n",
       "4  https://www.courtlistener.com/opinion/88395/ro...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_info = pd.read_csv(csv_dir_full_bow_km10 + 'cluster_8.csv')\n",
    "cluster_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "Wall time: 57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=1000 # number of words to get\n",
    "\n",
    "top_words = top_k_words(dict_top_n_clusters[8], k, bow_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[8], k, bow_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[8], all_the_opinions, k, bow_matrix, op_id_to_bow_id, vocab)\n",
    "most_relev_op = document_closest_to_mean(dict_top_n_clusters[8], bow_matrix, op_id_to_bow_id)\n",
    "\n",
    "top_words = [x.encode('utf-8') for x in top_words]\n",
    "top_words_from_mean = [x.encode('utf-8') for x in top_words_from_mean]\n",
    "top_words_from_diff = [x.encode('utf-8') for x in top_words_from_diff]\n",
    "\n",
    "#print '\\x1b[1;31m' + \"Top K Words:\" + '\\x1b[0m', top_words\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster):\" + '\\x1b[0m', top_words_from_mean\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster - Mu_Complement):\" + '\\x1b[0m', top_words_from_diff\n",
    "#print '\\x1b[1;31m' + \"Most Relevent Opinion:\" + '\\x1b[0m', most_relev_op\n",
    "\n",
    "cluster_summary = pd.DataFrame()\n",
    "cluster_summary['top_words'] = top_words\n",
    "cluster_summary['top_words_from_mean'] = top_words_from_mean\n",
    "cluster_summary['top_words_from_diff'] = top_words_from_diff\n",
    "cluster_summary['most_relev_op'] = most_relev_op\n",
    "\n",
    "cluster_summary.to_csv(csv_dir_full_bow_km10 + \"cluster_8_summary.csv\")\n",
    "\n",
    "print cluster_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>top_words</th>\n",
       "      <th>top_words_from_mean</th>\n",
       "      <th>top_words_from_diff</th>\n",
       "      <th>most_relev_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>school</td>\n",
       "      <td>court</td>\n",
       "      <td>tax</td>\n",
       "      <td>102039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>grant</td>\n",
       "      <td>state</td>\n",
       "      <td>act</td>\n",
       "      <td>102039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>right</td>\n",
       "      <td>v</td>\n",
       "      <td>said</td>\n",
       "      <td>102039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>district</td>\n",
       "      <td>case</td>\n",
       "      <td>public</td>\n",
       "      <td>102039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>candid</td>\n",
       "      <td>act</td>\n",
       "      <td>bond</td>\n",
       "      <td>102039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 top_words top_words_from_mean top_words_from_diff  most_relev_op\n",
       "0           0    school               court                 tax         102039\n",
       "1           1     grant               state                 act         102039\n",
       "2           2     right                   v                said         102039\n",
       "3           3  district                case              public         102039\n",
       "4           4    candid                 act                bond         102039"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_summary = pd.read_csv(csv_dir_full_bow_km10 + 'cluster_8_summary.csv')\n",
    "cluster_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 4 Summary (2940 opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2940, 3)\n",
      "Wall time: 1.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "opinion_names = []\n",
    "opinion_dates = []\n",
    "opinion_links = []\n",
    "\n",
    "for i in dict_top_n_clusters[4]:\n",
    "    try:\n",
    "        with open(clusters_dir + i + \".json\") as data_file:\n",
    "            data = json.load(data_file)\n",
    "    except IOError:\n",
    "        pass\n",
    "        #name, date, link = case_info2(i)\n",
    "        #opinion_names.append(name)\n",
    "        #opinion_dates.append(date)\n",
    "        #opinion_links.append(link)\n",
    "        \n",
    "    name = data['case_name'].encode('utf-8')\n",
    "    date = data['date_filed'].encode('utf-8')\n",
    "    link = 'https://www.courtlistener.com' + data['absolute_url'].encode('utf-8')\n",
    "    \n",
    "    opinion_names.append(name)\n",
    "    opinion_dates.append(date)\n",
    "    opinion_links.append(link)\n",
    "    \n",
    "cluster_info = pd.DataFrame()\n",
    "cluster_info['names'] = opinion_names\n",
    "cluster_info['dates'] = opinion_dates\n",
    "cluster_info['url'] = opinion_links\n",
    "\n",
    "cluster_info.to_csv(csv_dir_full_bow_km10 + \"cluster_4.csv\")\n",
    "\n",
    "print cluster_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>names</th>\n",
       "      <th>dates</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Alabama v. King &amp; Boozer</td>\n",
       "      <td>1941-11-10</td>\n",
       "      <td>https://www.courtlistener.com/opinion/103545/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Fowler v. Merrill</td>\n",
       "      <td>1851-03-18</td>\n",
       "      <td>https://www.courtlistener.com/opinion/86651/fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Gaines v. Fuentes</td>\n",
       "      <td>1876-03-20</td>\n",
       "      <td>https://www.courtlistener.com/opinion/89236/ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Moore v. Mississippi</td>\n",
       "      <td>1875-04-19</td>\n",
       "      <td>https://www.courtlistener.com/opinion/89041/mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Insurance Co. v. Francis</td>\n",
       "      <td>1871-03-18</td>\n",
       "      <td>https://www.courtlistener.com/opinion/88319/in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                     names       dates  \\\n",
       "0           0  Alabama v. King & Boozer  1941-11-10   \n",
       "1           1         Fowler v. Merrill  1851-03-18   \n",
       "2           2         Gaines v. Fuentes  1876-03-20   \n",
       "3           3      Moore v. Mississippi  1875-04-19   \n",
       "4           4  Insurance Co. v. Francis  1871-03-18   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.courtlistener.com/opinion/103545/a...  \n",
       "1  https://www.courtlistener.com/opinion/86651/fo...  \n",
       "2  https://www.courtlistener.com/opinion/89236/ga...  \n",
       "3  https://www.courtlistener.com/opinion/89041/mo...  \n",
       "4  https://www.courtlistener.com/opinion/88319/in...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_info = pd.read_csv(csv_dir_full_bow_km10 + 'cluster_4.csv')\n",
    "cluster_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "Wall time: 24.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=1000 # number of words to get\n",
    "\n",
    "top_words = top_k_words(dict_top_n_clusters[4], k, bow_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[4], k, bow_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[4], all_the_opinions, k, bow_matrix, op_id_to_bow_id, vocab)\n",
    "most_relev_op = document_closest_to_mean(dict_top_n_clusters[4], bow_matrix, op_id_to_bow_id)\n",
    "\n",
    "top_words = [x.encode('utf-8') for x in top_words]\n",
    "top_words_from_mean = [x.encode('utf-8') for x in top_words_from_mean]\n",
    "top_words_from_diff = [x.encode('utf-8') for x in top_words_from_diff]\n",
    "\n",
    "#print '\\x1b[1;31m' + \"Top K Words:\" + '\\x1b[0m', top_words\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster):\" + '\\x1b[0m', top_words_from_mean\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster - Mu_Complement):\" + '\\x1b[0m', top_words_from_diff\n",
    "#print '\\x1b[1;31m' + \"Most Relevent Opinion:\" + '\\x1b[0m', most_relev_op\n",
    "\n",
    "cluster_summary = pd.DataFrame()\n",
    "cluster_summary['top_words'] = top_words\n",
    "cluster_summary['top_words_from_mean'] = top_words_from_mean\n",
    "cluster_summary['top_words_from_diff'] = top_words_from_diff\n",
    "cluster_summary['most_relev_op'] = most_relev_op\n",
    "\n",
    "cluster_summary.to_csv(csv_dir_full_bow_km10 + \"cluster_4_summary.csv\")\n",
    "\n",
    "print cluster_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>top_words</th>\n",
       "      <th>top_words_from_mean</th>\n",
       "      <th>top_words_from_diff</th>\n",
       "      <th>most_relev_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>state</td>\n",
       "      <td>court</td>\n",
       "      <td>state</td>\n",
       "      <td>104441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mine</td>\n",
       "      <td>state</td>\n",
       "      <td>sct</td>\n",
       "      <td>104441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>district</td>\n",
       "      <td>v</td>\n",
       "      <td>us</td>\n",
       "      <td>104441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>power</td>\n",
       "      <td>case</td>\n",
       "      <td>v</td>\n",
       "      <td>104441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>school</td>\n",
       "      <td>us</td>\n",
       "      <td>district</td>\n",
       "      <td>104441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 top_words top_words_from_mean top_words_from_diff  most_relev_op\n",
       "0           0     state               court               state         104441\n",
       "1           1      mine               state                 sct         104441\n",
       "2           2  district                   v                  us         104441\n",
       "3           3     power                case                   v         104441\n",
       "4           4    school                  us            district         104441"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_summary = pd.read_csv(csv_dir_full_bow_km10 + 'cluster_4_summary.csv')\n",
    "cluster_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 7 Summary (1232 opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1232, 3)\n",
      "Wall time: 550 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "opinion_names = []\n",
    "opinion_dates = []\n",
    "opinion_links = []\n",
    "\n",
    "for i in dict_top_n_clusters[7]:\n",
    "    try:\n",
    "        with open(clusters_dir + i + \".json\") as data_file:\n",
    "            data = json.load(data_file)\n",
    "    except IOError:\n",
    "        pass\n",
    "        #name, date, link = case_info2(i)\n",
    "        #opinion_names.append(name)\n",
    "        #opinion_dates.append(date)\n",
    "        #opinion_links.append(link)\n",
    "        \n",
    "    name = data['case_name'].encode('utf-8')\n",
    "    date = data['date_filed'].encode('utf-8')\n",
    "    link = 'https://www.courtlistener.com' + data['absolute_url'].encode('utf-8')\n",
    "    \n",
    "    opinion_names.append(name)\n",
    "    opinion_dates.append(date)\n",
    "    opinion_links.append(link)\n",
    "    \n",
    "cluster_info = pd.DataFrame()\n",
    "cluster_info['names'] = opinion_names\n",
    "cluster_info['dates'] = opinion_dates\n",
    "cluster_info['url'] = opinion_links\n",
    "\n",
    "cluster_info.to_csv(csv_dir_full_bow_km10 + \"cluster_7.csv\")\n",
    "\n",
    "print cluster_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>names</th>\n",
       "      <th>dates</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Bernards v. Johnson</td>\n",
       "      <td>1941-11-10</td>\n",
       "      <td>https://www.courtlistener.com/opinion/103547/b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Reetz v. Michigan</td>\n",
       "      <td>1903-02-23</td>\n",
       "      <td>https://www.courtlistener.com/opinion/95797/re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Black v. Amen</td>\n",
       "      <td>1958-03-03</td>\n",
       "      <td>https://www.courtlistener.com/opinion/105639/b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Cain v. Kentucky</td>\n",
       "      <td>1970-03-30</td>\n",
       "      <td>https://www.courtlistener.com/opinion/108104/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Smith v. United States</td>\n",
       "      <td>1896-03-02</td>\n",
       "      <td>https://www.courtlistener.com/opinion/94364/sm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   names       dates  \\\n",
       "0           0     Bernards v. Johnson  1941-11-10   \n",
       "1           1       Reetz v. Michigan  1903-02-23   \n",
       "2           2           Black v. Amen  1958-03-03   \n",
       "3           3        Cain v. Kentucky  1970-03-30   \n",
       "4           4  Smith v. United States  1896-03-02   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.courtlistener.com/opinion/103547/b...  \n",
       "1  https://www.courtlistener.com/opinion/95797/re...  \n",
       "2  https://www.courtlistener.com/opinion/105639/b...  \n",
       "3  https://www.courtlistener.com/opinion/108104/c...  \n",
       "4  https://www.courtlistener.com/opinion/94364/sm...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_info = pd.read_csv(csv_dir_full_bow_km10 + 'cluster_7.csv')\n",
    "cluster_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=1000 # number of words to get\n",
    "\n",
    "top_words = top_k_words(dict_top_n_clusters[7], k, bow_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[7], k, bow_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[7], all_the_opinions, k, bow_matrix, op_id_to_bow_id, vocab)\n",
    "most_relev_op = document_closest_to_mean(dict_top_n_clusters[7], bow_matrix, op_id_to_bow_id)\n",
    "\n",
    "top_words = [x.encode('utf-8') for x in top_words]\n",
    "top_words_from_mean = [x.encode('utf-8') for x in top_words_from_mean]\n",
    "top_words_from_diff = [x.encode('utf-8') for x in top_words_from_diff]\n",
    "\n",
    "#print '\\x1b[1;31m' + \"Top K Words:\" + '\\x1b[0m', top_words\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster):\" + '\\x1b[0m', top_words_from_mean\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster - Mu_Complement):\" + '\\x1b[0m', top_words_from_diff\n",
    "#print '\\x1b[1;31m' + \"Most Relevent Opinion:\" + '\\x1b[0m', most_relev_op\n",
    "\n",
    "cluster_summary = pd.DataFrame()\n",
    "cluster_summary['top_words'] = top_words\n",
    "cluster_summary['top_words_from_mean'] = top_words_from_mean\n",
    "cluster_summary['top_words_from_diff'] = top_words_from_diff\n",
    "cluster_summary['most_relev_op'] = most_relev_op\n",
    "\n",
    "cluster_summary.to_csv(csv_dir_full_bow_km10 + \"cluster_7_summary.csv\")\n",
    "\n",
    "print cluster_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>top_words</th>\n",
       "      <th>top_words_from_mean</th>\n",
       "      <th>top_words_from_diff</th>\n",
       "      <th>most_relev_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>state</td>\n",
       "      <td>state</td>\n",
       "      <td>state</td>\n",
       "      <td>87419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>power</td>\n",
       "      <td>court</td>\n",
       "      <td>law</td>\n",
       "      <td>87419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>law</td>\n",
       "      <td>v</td>\n",
       "      <td>commerc</td>\n",
       "      <td>87419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>commerc</td>\n",
       "      <td>case</td>\n",
       "      <td>power</td>\n",
       "      <td>87419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>congress</td>\n",
       "      <td>act</td>\n",
       "      <td>act</td>\n",
       "      <td>87419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 top_words top_words_from_mean top_words_from_diff  most_relev_op\n",
       "0           0     state               state               state          87419\n",
       "1           1     power               court                 law          87419\n",
       "2           2       law                   v             commerc          87419\n",
       "3           3   commerc                case               power          87419\n",
       "4           4  congress                 act                 act          87419"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_summary = pd.read_csv(csv_dir_full_bow_km10 + 'cluster_7_summary.csv')\n",
    "cluster_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 3 Summary (1111 opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1111, 3)\n",
      "Wall time: 490 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "opinion_names = []\n",
    "opinion_dates = []\n",
    "opinion_links = []\n",
    "\n",
    "for i in dict_top_n_clusters[3]:\n",
    "    try:\n",
    "        with open(clusters_dir + i + \".json\") as data_file:\n",
    "            data = json.load(data_file)\n",
    "    except IOError:\n",
    "        pass\n",
    "        #name, date, link = case_info2(i)\n",
    "        #opinion_names.append(name)\n",
    "        #opinion_dates.append(date)\n",
    "        #opinion_links.append(link)\n",
    "        \n",
    "    name = data['case_name'].encode('utf-8')\n",
    "    date = data['date_filed'].encode('utf-8')\n",
    "    link = 'https://www.courtlistener.com' + data['absolute_url'].encode('utf-8')\n",
    "    \n",
    "    opinion_names.append(name)\n",
    "    opinion_dates.append(date)\n",
    "    opinion_links.append(link)\n",
    "    \n",
    "cluster_info = pd.DataFrame()\n",
    "cluster_info['names'] = opinion_names\n",
    "cluster_info['dates'] = opinion_dates\n",
    "cluster_info['url'] = opinion_links\n",
    "\n",
    "cluster_info.to_csv(csv_dir_full_bow_km10 + \"cluster_3.csv\")\n",
    "\n",
    "print cluster_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>names</th>\n",
       "      <th>dates</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Central Stock Yards Co. v. Louisville &amp; Nashvi...</td>\n",
       "      <td>1904-02-23</td>\n",
       "      <td>https://www.courtlistener.com/opinion/96013/ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Fountain v. Filson</td>\n",
       "      <td>1949-05-31</td>\n",
       "      <td>https://www.courtlistener.com/opinion/104659/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>United States v. Mooney</td>\n",
       "      <td>1885-12-14</td>\n",
       "      <td>https://www.courtlistener.com/opinion/91505/un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Barrett v. United States (No. 1)</td>\n",
       "      <td>1898-02-21</td>\n",
       "      <td>https://www.courtlistener.com/opinion/94813/ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>United States v. Eichman</td>\n",
       "      <td>1990-06-11</td>\n",
       "      <td>https://www.courtlistener.com/opinion/112453/u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              names       dates  \\\n",
       "0           0  Central Stock Yards Co. v. Louisville & Nashvi...  1904-02-23   \n",
       "1           1                                 Fountain v. Filson  1949-05-31   \n",
       "2           2                            United States v. Mooney  1885-12-14   \n",
       "3           3                   Barrett v. United States (No. 1)  1898-02-21   \n",
       "4           4                           United States v. Eichman  1990-06-11   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.courtlistener.com/opinion/96013/ce...  \n",
       "1  https://www.courtlistener.com/opinion/104659/f...  \n",
       "2  https://www.courtlistener.com/opinion/91505/un...  \n",
       "3  https://www.courtlistener.com/opinion/94813/ba...  \n",
       "4  https://www.courtlistener.com/opinion/112453/u...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_info = pd.read_csv(csv_dir_full_bow_km10 + 'cluster_3.csv')\n",
    "cluster_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=1000 # number of words to get\n",
    "\n",
    "top_words = top_k_words(dict_top_n_clusters[3], k, bow_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[3], k, bow_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[3], all_the_opinions, k, bow_matrix, op_id_to_bow_id, vocab)\n",
    "most_relev_op = document_closest_to_mean(dict_top_n_clusters[3], bow_matrix, op_id_to_bow_id)\n",
    "\n",
    "top_words = [x.encode('utf-8') for x in top_words]\n",
    "top_words_from_mean = [x.encode('utf-8') for x in top_words_from_mean]\n",
    "top_words_from_diff = [x.encode('utf-8') for x in top_words_from_diff]\n",
    "\n",
    "#print '\\x1b[1;31m' + \"Top K Words:\" + '\\x1b[0m', top_words\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster):\" + '\\x1b[0m', top_words_from_mean\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster - Mu_Complement):\" + '\\x1b[0m', top_words_from_diff\n",
    "#print '\\x1b[1;31m' + \"Most Relevent Opinion:\" + '\\x1b[0m', most_relev_op\n",
    "\n",
    "cluster_summary = pd.DataFrame()\n",
    "cluster_summary['top_words'] = top_words\n",
    "cluster_summary['top_words_from_mean'] = top_words_from_mean\n",
    "cluster_summary['top_words_from_diff'] = top_words_from_diff\n",
    "cluster_summary['most_relev_op'] = most_relev_op\n",
    "\n",
    "cluster_summary.to_csv(csv_dir_full_bow_km10 + \"cluster_3_summary.csv\")\n",
    "\n",
    "print cluster_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>top_words</th>\n",
       "      <th>top_words_from_mean</th>\n",
       "      <th>top_words_from_diff</th>\n",
       "      <th>most_relev_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>state</td>\n",
       "      <td>court</td>\n",
       "      <td>land</td>\n",
       "      <td>95116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>new</td>\n",
       "      <td>state</td>\n",
       "      <td>unit</td>\n",
       "      <td>95116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>unit</td>\n",
       "      <td>v</td>\n",
       "      <td>car</td>\n",
       "      <td>95116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>case</td>\n",
       "      <td>grant</td>\n",
       "      <td>95116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>territori</td>\n",
       "      <td>act</td>\n",
       "      <td>sentenc</td>\n",
       "      <td>95116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  top_words top_words_from_mean top_words_from_diff  \\\n",
       "0           0      state               court                land   \n",
       "1           1        new               state                unit   \n",
       "2           2       unit                   v                 car   \n",
       "3           3          1                case               grant   \n",
       "4           4  territori                 act             sentenc   \n",
       "\n",
       "   most_relev_op  \n",
       "0          95116  \n",
       "1          95116  \n",
       "2          95116  \n",
       "3          95116  \n",
       "4          95116  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_summary = pd.read_csv(csv_dir_full_bow_km10 + 'cluster_3_summary.csv')\n",
    "cluster_summary.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
