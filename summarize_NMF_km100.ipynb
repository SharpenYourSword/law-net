{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize K-Means (K=100) Cluster for NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# modify these for your own computer\n",
    "repo_directory = '/Users/Michael/Documents/GitHub/law-net/'\n",
    "\n",
    "data_dir = '/Users/Michael/Desktop/network_data/'\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cPickle  as pickle\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "\n",
    "\n",
    "# graph package\n",
    "import igraph as ig\n",
    "\n",
    "\n",
    "# stat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
    "from sklearn.metrics import adjusted_mutual_info_score as ami\n",
    "from sklearn.metrics import mutual_info_score as mi\n",
    "from sklearn.metrics import adjusted_rand_score as ar\n",
    "from sklearn.metrics import calinski_harabaz_score as ch # (X, labels)\n",
    "from sklearn.metrics import completeness_score as cs # metric isn't symmetric (labels_true, labels_predicted)\n",
    "from sklearn.metrics import fowlkes_mallows_score as fm\n",
    "from sklearn.metrics import homogeneity_completeness_v_measure as hcvm\n",
    "from sklearn.metrics import homogeneity_score as hs # metric isn't symmetric (labels_true, labels_predicted)\n",
    "from sklearn.metrics import silhouette_score as ss # (X, labels)\n",
    "from sklearn.metrics import silhouette_samples as ss2 # (X, labels)\n",
    "from sklearn.metrics import v_measure_score as vm\n",
    "\n",
    "import scipy.sparse\n",
    "import random\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "# our code\n",
    "sys.path.append(repo_directory + 'code/')\n",
    "from summarize_clusters import *\n",
    "from helpful_functions import *\n",
    "\n",
    "sys.path.append(repo_directory + 'vertex_metrics_experiment/code/')\n",
    "from bag_of_words import * \n",
    "\n",
    "# which network to download data for\n",
    "network_name = 'scotus' # 'federal', 'ca1', etc\n",
    "\n",
    "\n",
    "# some sub directories that get used\n",
    "raw_dir = data_dir + 'raw/'\n",
    "subnet_dir = data_dir + network_name + '/'\n",
    "text_dir = subnet_dir + 'textfiles/'\n",
    "nlp_dir = subnet_dir + 'nlp/'\n",
    "nlp_sub_dir = nlp_dir + 'bow_tfidf/' #tfidf matrix (and other info, i.e. vocab) computed from bag-of-words matrix\n",
    "nlp_bow_dir = nlp_dir + 'bow/' #bag-of-words matrix (and other info, i.e. vocab)\n",
    "nlp_df_sub_dir = nlp_dir + 'bow_tfidf_df/'\n",
    "\n",
    "# csv location\n",
    "csv_dir = \"C:/Users/Michael/Documents/GitHub/law-net/csv/\"\n",
    "csv_dir_NMF_km100 = \"C:/Users/Michael/Documents/GitHub/law-net/csv/summarize_NMF_km100/\"\n",
    "csv_dir_NMF_km100_info = \"C:/Users/Michael/Documents/GitHub/law-net/csv/summarize_NMF_km100/info/\"\n",
    "csv_dir_NMF_km100_summary = \"C:/Users/Michael/Documents/GitHub/law-net/csv/summarize_NMF_km100/summary/\"\n",
    "\n",
    "# all the file paths for .txt files\n",
    "file_paths = glob.glob(text_dir + '*.txt')\n",
    "\n",
    "# all opinions\n",
    "all_the_opinions = all_opinions(file_paths)\n",
    "\n",
    "# clusters directory\n",
    "clusters_dir = \"C:/Users/Michael/Desktop/network_data/raw/scotus/clusters/\"\n",
    "\n",
    "# jupyter notebook settings\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load tf-idf vectors\n",
    "**tfidf_matrix** = (row_index, column_index): tf_idf value (**CSR FORMAT**)  \n",
    "**op_id_to_bow_id** = opinion_id (corresponds to row indices)  \n",
    "**vocab** = all the words in tfidf_matrix (correspond to column indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_matrix, op_id_to_bow_id, vocab = load_tf_idf(nlp_sub_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<27885x567570 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 20817470 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>km_10</th>\n",
       "      <th>km_100</th>\n",
       "      <th>km_1000</th>\n",
       "      <th>gmm_10</th>\n",
       "      <th>gmm_100</th>\n",
       "      <th>gmm_1000</th>\n",
       "      <th>hc_10</th>\n",
       "      <th>hc_100</th>\n",
       "      <th>hc_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145658</td>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "      <td>356</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>807</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89370</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>557</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89371</td>\n",
       "      <td>4</td>\n",
       "      <td>73</td>\n",
       "      <td>546</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89372</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>719</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>523</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89373</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>602</td>\n",
       "      <td>6</td>\n",
       "      <td>74</td>\n",
       "      <td>681</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  km_10  km_100  km_1000  gmm_10  gmm_100  gmm_1000  hc_10  \\\n",
       "0      145658      5      71      356       0       37       807      1   \n",
       "1       89370      4      71      557       0       37       145      1   \n",
       "2       89371      4      73      546       7       11       560      1   \n",
       "3       89372      4      12      719       0       13       523      1   \n",
       "4       89373      9      10      602       6       74       681      1   \n",
       "\n",
       "   hc_100  hc_1000  \n",
       "0      86       74  \n",
       "1      61      267  \n",
       "2      85      144  \n",
       "3       1      814  \n",
       "4      47       79  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = pd.read_csv(csv_dir + 'clusters_NMF.csv')\n",
    "clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145658    71\n",
       "89370     71\n",
       "89371     73\n",
       "89372     12\n",
       "89373     10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_tfidf_clusters = clusters['km_100'].tolist()\n",
    "\n",
    "nlp_clusters = pd.Series(nlp_tfidf_clusters, index=op_id_to_bow_id)\n",
    "nlp_clusters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the top 5 biggest clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 12 : 4326 opinions\n",
      "cluster 4 : 1625 opinions\n",
      "cluster 76 : 1229 opinions\n",
      "cluster 85 : 922 opinions\n",
      "cluster 84 : 816 opinions\n",
      "cluster 10 : 793 opinions\n",
      "cluster 28 : 787 opinions\n",
      "cluster 31 : 770 opinions\n",
      "cluster 25 : 747 opinions\n",
      "cluster 1 : 742 opinions\n",
      "cluster 5 : 576 opinions\n",
      "cluster 11 : 575 opinions\n",
      "cluster 89 : 556 opinions\n",
      "cluster 49 : 431 opinions\n",
      "cluster 2 : 398 opinions\n",
      "cluster 75 : 369 opinions\n",
      "cluster 63 : 351 opinions\n",
      "cluster 22 : 342 opinions\n",
      "cluster 87 : 342 opinions\n",
      "cluster 73 : 340 opinions\n",
      "cluster 97 : 324 opinions\n",
      "cluster 74 : 312 opinions\n",
      "cluster 52 : 309 opinions\n",
      "cluster 72 : 297 opinions\n",
      "cluster 68 : 288 opinions\n",
      "cluster 59 : 280 opinions\n",
      "cluster 7 : 277 opinions\n",
      "cluster 29 : 270 opinions\n",
      "cluster 55 : 243 opinions\n",
      "cluster 36 : 240 opinions\n",
      "cluster 21 : 238 opinions\n",
      "cluster 44 : 236 opinions\n",
      "cluster 88 : 232 opinions\n",
      "cluster 69 : 225 opinions\n",
      "cluster 50 : 217 opinions\n",
      "cluster 43 : 214 opinions\n",
      "cluster 8 : 212 opinions\n",
      "cluster 54 : 209 opinions\n",
      "cluster 19 : 197 opinions\n",
      "cluster 30 : 196 opinions\n",
      "cluster 35 : 188 opinions\n",
      "cluster 78 : 185 opinions\n",
      "cluster 60 : 184 opinions\n",
      "cluster 53 : 182 opinions\n",
      "cluster 65 : 178 opinions\n",
      "cluster 0 : 171 opinions\n",
      "cluster 6 : 168 opinions\n",
      "cluster 90 : 168 opinions\n",
      "cluster 23 : 159 opinions\n",
      "cluster 67 : 157 opinions\n",
      "cluster 71 : 153 opinions\n",
      "cluster 37 : 149 opinions\n",
      "cluster 39 : 147 opinions\n",
      "cluster 62 : 139 opinions\n",
      "cluster 82 : 132 opinions\n",
      "cluster 3 : 127 opinions\n",
      "cluster 24 : 127 opinions\n",
      "cluster 58 : 123 opinions\n",
      "cluster 96 : 120 opinions\n",
      "cluster 77 : 114 opinions\n",
      "cluster 45 : 113 opinions\n",
      "cluster 16 : 109 opinions\n",
      "cluster 99 : 104 opinions\n",
      "cluster 80 : 100 opinions\n",
      "cluster 98 : 98 opinions\n",
      "cluster 40 : 97 opinions\n",
      "cluster 70 : 96 opinions\n",
      "cluster 93 : 95 opinions\n",
      "cluster 83 : 91 opinions\n",
      "cluster 41 : 89 opinions\n",
      "cluster 48 : 89 opinions\n",
      "cluster 81 : 89 opinions\n",
      "cluster 18 : 87 opinions\n",
      "cluster 9 : 83 opinions\n",
      "cluster 66 : 83 opinions\n",
      "cluster 92 : 83 opinions\n",
      "cluster 95 : 82 opinions\n",
      "cluster 20 : 77 opinions\n",
      "cluster 27 : 74 opinions\n",
      "cluster 32 : 73 opinions\n",
      "cluster 46 : 73 opinions\n",
      "cluster 56 : 71 opinions\n",
      "cluster 79 : 70 opinions\n",
      "cluster 17 : 65 opinions\n",
      "cluster 26 : 65 opinions\n",
      "cluster 91 : 62 opinions\n",
      "cluster 15 : 61 opinions\n",
      "cluster 86 : 61 opinions\n",
      "cluster 61 : 51 opinions\n",
      "cluster 94 : 45 opinions\n",
      "cluster 38 : 43 opinions\n",
      "cluster 13 : 41 opinions\n",
      "cluster 14 : 39 opinions\n",
      "cluster 47 : 36 opinions\n",
      "cluster 34 : 33 opinions\n",
      "cluster 64 : 33 opinions\n",
      "cluster 51 : 30 opinions\n",
      "cluster 57 : 29 opinions\n",
      "cluster 42 : 26 opinions\n",
      "cluster 33 : 15 opinions\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "dict_top_n_clusters = dictionary of top K clusters \n",
    "                      (key=cluster #, value=opinions in cluster)\n",
    "                      \n",
    "biggest_n_clusters = list of top K clusters (int)\n",
    "'''\n",
    "\n",
    "dict_top_n_clusters, biggest_n_clusters = get_top_n_clusters(100, 100, nlp_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top K Words of Each Cluster\n",
    "This function summarizes a set of opinions by returning the words that appear in these opinions with the highest tf-idf scores.\n",
    "\n",
    "# Top K Words ($\\mu_{cluster}$) of Each Cluster\n",
    "compute the mean tf-idf vector of the cluster, return the top K words from this mean vector\n",
    "\n",
    "# Top K Words ($\\mu_{cluster} - \\mu_{complement}$ ) of Each Cluster\n",
    "compute the mean tf-idf vector of the cluster and also of the complement of the cluster,  \n",
    "take the difference mu_cluster - mu_complement, return the top K words in this difference\n",
    "\n",
    "# Most Relevant Opinion of Each Cluster\n",
    "compute the mean tf-idf vector, return the document in the cluster closet to the mean  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_infos_csv(biggest_n_clusters, dict_top_n_clusters, clusters_dir, csv_dir_info):\n",
    "    \n",
    "    for i in biggest_n_clusters:\n",
    "        \n",
    "        opinion_names = []\n",
    "        opinion_dates = []\n",
    "        opinion_links = []\n",
    "        \n",
    "        for j in dict_top_n_clusters[i]:\n",
    "            try:\n",
    "                with open(clusters_dir + j + \".json\") as data_file:\n",
    "                    data = json.load(data_file)\n",
    "            except IOError:\n",
    "                pass\n",
    "                #name, date, link = case_info2(i)\n",
    "                #opinion_names.append(name)\n",
    "                #opinion_dates.append(date)\n",
    "                #opinion_links.append(link)\n",
    "            \n",
    "            name = data['case_name'].encode('utf-8')\n",
    "            date = data['date_filed'].encode('utf-8')\n",
    "            link = 'https://www.courtlistener.com' + data['absolute_url'].encode('utf-8')\n",
    "\n",
    "            opinion_names.append(name)\n",
    "            opinion_dates.append(date)\n",
    "            opinion_links.append(link)\n",
    "\n",
    "        cluster_info = pd.DataFrame()\n",
    "        cluster_info['names'] = opinion_names\n",
    "        cluster_info['dates'] = opinion_dates\n",
    "        cluster_info['url'] = opinion_links\n",
    "\n",
    "        cluster_info.to_csv(csv_dir_info + \"cluster_\"+str(i)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cluster_infos_csv(biggest_n_clusters, dict_top_n_clusters, clusters_dir, csv_dir_NMF_km100_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_summaries_csv(k, biggest_n_clusters, dict_top_n_clusters, tfidf_matrix, op_id_to_bow_id, vocab, csv_dir_summary):\n",
    "    for i in biggest_n_clusters:\n",
    "        top_words = top_k_words(dict_top_n_clusters[i], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "        top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[i], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "        top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[i], all_the_opinions, k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "        most_relev_op = document_closest_to_mean(dict_top_n_clusters[i], tfidf_matrix, op_id_to_bow_id)\n",
    "        \n",
    "        top_words = [x.encode('utf-8') for x in top_words]\n",
    "        top_words_from_mean = [x.encode('utf-8') for x in top_words_from_mean]\n",
    "        top_words_from_diff = [x.encode('utf-8') for x in top_words_from_diff]\n",
    "\n",
    "        len_old_top_words = len(top_words)\n",
    "        len_old_top_words_from_mean = len(top_words_from_mean)\n",
    "        len_old_top_words_from_diff = len(top_words_from_diff)\n",
    "\n",
    "        if len(top_words) != len(top_words_from_mean):\n",
    "            for j in range(0,len(top_words_from_mean)-len(top_words)):\n",
    "                top_words.append(np.nan)\n",
    "\n",
    "        cluster_summary = pd.DataFrame()\n",
    "        cluster_summary['top_words'] = top_words\n",
    "        cluster_summary['top_words_from_mean'] = top_words_from_mean\n",
    "        cluster_summary['top_words_from_diff'] = top_words_from_diff\n",
    "        cluster_summary['most_relev_op'] = most_relev_op\n",
    "\n",
    "        cluster_summary.to_csv(csv_dir_summary + \"cluster_\"+str(i)+\"_summary.csv\")\n",
    "        print \"cluster\", i, \"is done\", \"(\", len(dict_top_n_clusters[i]), \"opinions )\", len_old_top_words, len_old_top_words_from_mean, len_old_top_words_from_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 12 is done ( 4326 opinions ) 1000 1000 1000\n",
      "cluster 4 is done ( 1625 opinions ) 1000 1000 1000\n",
      "cluster 76 is done ( 1229 opinions ) 1000 1000 1000\n",
      "cluster 85 is done ( 922 opinions ) 1000 1000 1000\n",
      "cluster 84 is done ( 816 opinions ) 1000 1000 1000\n",
      "cluster 10 is done ( 793 opinions ) 1000 1000 1000\n",
      "cluster 28 is done ( 787 opinions ) 1000 1000 1000\n",
      "cluster 31 is done ( 770 opinions ) 1000 1000 1000\n",
      "cluster 25 is done ( 747 opinions ) 1000 1000 1000\n",
      "cluster 1 is done ( 742 opinions ) 1000 1000 1000\n",
      "cluster 5 is done ( 576 opinions ) 1000 1000 1000\n",
      "cluster 11 is done ( 575 opinions ) 1000 1000 1000\n",
      "cluster 89 is done ( 556 opinions ) 1000 1000 1000\n",
      "cluster 49 is done ( 431 opinions ) 1000 1000 1000\n",
      "cluster 2 is done ( 398 opinions ) 1000 1000 1000\n",
      "cluster 75 is done ( 369 opinions ) 1000 1000 1000\n",
      "cluster 63 is done ( 351 opinions ) 1000 1000 1000\n",
      "cluster 22 is done ( 342 opinions ) 1000 1000 1000\n",
      "cluster 87 is done ( 342 opinions ) 1000 1000 1000\n",
      "cluster 73 is done ( 340 opinions ) 1000 1000 1000\n",
      "cluster 97 is done ( 324 opinions ) 1000 1000 1000\n",
      "cluster 74 is done ( 312 opinions ) 1000 1000 1000\n",
      "cluster 52 is done ( 309 opinions ) 1000 1000 1000\n",
      "cluster 72 is done ( 297 opinions ) 1000 1000 1000\n",
      "cluster 68 is done ( 288 opinions ) 1000 1000 1000\n",
      "cluster 59 is done ( 280 opinions ) 1000 1000 1000\n",
      "cluster 7 is done ( 277 opinions ) 1000 1000 1000\n",
      "cluster 29 is done ( 270 opinions ) 1000 1000 1000\n",
      "cluster 55 is done ( 243 opinions ) 1000 1000 1000\n",
      "cluster 36 is done ( 240 opinions ) 1000 1000 1000\n",
      "cluster 21 is done ( 238 opinions ) 1000 1000 1000\n",
      "cluster 44 is done ( 236 opinions ) 1000 1000 1000\n",
      "cluster 88 is done ( 232 opinions ) 1000 1000 1000\n",
      "cluster 69 is done ( 225 opinions ) 1000 1000 1000\n",
      "cluster 50 is done ( 217 opinions ) 1000 1000 1000\n",
      "cluster 43 is done ( 214 opinions ) 1000 1000 1000\n",
      "cluster 8 is done ( 212 opinions ) 1000 1000 1000\n",
      "cluster 54 is done ( 209 opinions ) 1000 1000 1000\n",
      "cluster 19 is done ( 197 opinions ) 1000 1000 1000\n",
      "cluster 30 is done ( 196 opinions ) 1000 1000 1000\n",
      "cluster 35 is done ( 188 opinions ) 1000 1000 1000\n",
      "cluster 78 is done ( 185 opinions ) 1000 1000 1000\n",
      "cluster 60 is done ( 184 opinions ) 1000 1000 1000\n",
      "cluster 53 is done ( 182 opinions ) 1000 1000 1000\n",
      "cluster 65 is done ( 178 opinions ) 1000 1000 1000\n",
      "cluster 0 is done ( 171 opinions ) 1000 1000 1000\n",
      "cluster 6 is done ( 168 opinions ) 1000 1000 1000\n",
      "cluster 90 is done ( 168 opinions ) 1000 1000 1000\n",
      "cluster 23 is done ( 159 opinions ) 1000 1000 1000\n",
      "cluster 67 is done ( 157 opinions ) 1000 1000 1000\n",
      "cluster 71 is done ( 153 opinions ) 1000 1000 1000\n",
      "cluster 37 is done ( 149 opinions ) 1000 1000 1000\n",
      "cluster 39 is done ( 147 opinions ) 1000 1000 1000\n",
      "cluster 62 is done ( 139 opinions ) 1000 1000 1000\n",
      "cluster 82 is done ( 132 opinions ) 1000 1000 1000\n",
      "cluster 3 is done ( 127 opinions ) 1000 1000 1000\n",
      "cluster 24 is done ( 127 opinions ) 1000 1000 1000\n",
      "cluster 58 is done ( 123 opinions ) 1000 1000 1000\n",
      "cluster 96 is done ( 120 opinions ) 1000 1000 1000\n",
      "cluster 77 is done ( 114 opinions ) 1000 1000 1000\n",
      "cluster 45 is done ( 113 opinions ) 1000 1000 1000\n",
      "cluster 16 is done ( 109 opinions ) 1000 1000 1000\n",
      "cluster 99 is done ( 104 opinions ) 1000 1000 1000\n",
      "cluster 80 is done ( 100 opinions ) 1000 1000 1000\n",
      "cluster 98 is done ( 98 opinions ) 1000 1000 1000\n",
      "cluster 40 is done ( 97 opinions ) 1000 1000 1000\n",
      "cluster 70 is done ( 96 opinions ) 1000 1000 1000\n",
      "cluster 93 is done ( 95 opinions ) 1000 1000 1000\n",
      "cluster 83 is done ( 91 opinions ) 1000 1000 1000\n",
      "cluster 41 is done ( 89 opinions ) 1000 1000 1000\n",
      "cluster 48 is done ( 89 opinions ) 1000 1000 1000\n",
      "cluster 81 is done ( 89 opinions ) 1000 1000 1000\n",
      "cluster 18 is done ( 87 opinions ) 1000 1000 1000\n",
      "cluster 9 is done ( 83 opinions ) 1000 1000 1000\n",
      "cluster 66 is done ( 83 opinions ) 1000 1000 1000\n",
      "cluster 92 is done ( 83 opinions ) 1000 1000 1000\n",
      "cluster 95 is done ( 82 opinions ) 1000 1000 1000\n",
      "cluster 20 is done ( 77 opinions ) 1000 1000 1000\n",
      "cluster 27 is done ( 74 opinions ) 1000 1000 1000\n",
      "cluster 32 is done ( 73 opinions ) 1000 1000 1000\n",
      "cluster 46 is done ( 73 opinions ) 1000 1000 1000\n",
      "cluster 56 is done ( 71 opinions ) 1000 1000 1000\n",
      "cluster 79 is done ( 70 opinions ) 1000 1000 1000\n",
      "cluster 17 is done ( 65 opinions ) 1000 1000 1000\n",
      "cluster 26 is done ( 65 opinions ) 1000 1000 1000\n",
      "cluster 91 is done ( 62 opinions ) 1000 1000 1000\n",
      "cluster 15 is done ( 61 opinions ) 1000 1000 1000\n",
      "cluster 86 is done ( 61 opinions ) 1000 1000 1000\n",
      "cluster 61 is done ( 51 opinions ) 1000 1000 1000\n",
      "cluster 94 is done ( 45 opinions ) 1000 1000 1000\n",
      "cluster 38 is done ( 43 opinions ) 1000 1000 1000\n",
      "cluster 13 is done ( 41 opinions ) 1000 1000 1000\n",
      "cluster 14 is done ( 39 opinions ) 1000 1000 1000\n",
      "cluster 47 is done ( 36 opinions ) 1000 1000 1000\n",
      "cluster 34 is done ( 33 opinions ) 1000 1000 1000\n",
      "cluster 64 is done ( 33 opinions ) 1000 1000 1000\n",
      "cluster 51 is done ( 30 opinions ) 1000 1000 1000\n",
      "cluster 57 is done ( 29 opinions ) 1000 1000 1000\n",
      "cluster 42 is done ( 26 opinions ) 1000 1000 1000\n",
      "cluster 33 is done ( 15 opinions ) 1000 1000 1000\n",
      "Wall time: 13min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cluster_summaries_csv(1000, biggest_n_clusters, dict_top_n_clusters, tfidf_matrix, op_id_to_bow_id, vocab, csv_dir_NMF_km100_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
