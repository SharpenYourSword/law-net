{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are working with a csr matrix the get similarity function in this script is an order of magnitude fastesr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check out http://www.philippsinger.info/?p=464 for working with large matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_directory = '/Users/iaincarmichael/Dropbox/Research/law/law-net/'\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from math import *\n",
    "import copy\n",
    "import cPickle as pickle\n",
    "\n",
    "# data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# viz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# graph\n",
    "import igraph as ig\n",
    "\n",
    "\n",
    "# NLP\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# our code\n",
    "sys.path.append(top_directory + 'code/')\n",
    "from load_data import load_and_clean_graph, case_info\n",
    "from pipeline.download_data import download_bulk_resource\n",
    "from pipeline.make_clean_data import *\n",
    "from viz import print_describe\n",
    "\n",
    "\n",
    "sys.path.append(top_directory + 'explore/vertex_metrics_experiment/code/')\n",
    "from make_snapshots import *\n",
    "from make_edge_df import *\n",
    "from attachment_model_inference import *\n",
    "from compute_ranking_metrics import *\n",
    "from pipeline_helper_functions import *\n",
    "from make_case_text_files import *\n",
    "from bag_of_words import *\n",
    "from similarity_matrix import *\n",
    "\n",
    "# directory set up\n",
    "data_dir = top_directory + 'data/'\n",
    "experiment_data_dir = data_dir + 'vertex_metrics_experiment/'\n",
    "\n",
    "court_name = 'scotus'\n",
    "\n",
    "# jupyter notebook settings\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G = load_and_clean_graph(data_dir, court_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "active_years = range(1900, 2015 + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# similarity matrix functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similarity_matrix, CLid_to_index = load_similarity_matrix(experiment_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clids_ing = CLid_to_index.keys()[:5]\n",
    "clids_ing.append(CLid_to_index.keys()[0])\n",
    "clids_ing.append('0')\n",
    "clids_ing.append(CLid_to_index.keys()[423])\n",
    "\n",
    "clids_ed = CLid_to_index.keys()[5:10]\n",
    "clids_ed.append(CLid_to_index.keys()[35])\n",
    "clids_ed.append('0')\n",
    "clids_ed.append(CLid_to_index.keys()[34])\n",
    "\n",
    "Clid_pairs = zip(clids_ing, clids_ed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_similarity_index(CLid_pair, CLid_to_index):\n",
    "#     \"\"\"\n",
    "#     Workhorse function for get_similarities\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         ida = CLid_to_index[CLid_pair[0]]\n",
    "#         idb = CLid_to_index[CLid_pair[1]]\n",
    "\n",
    "#         return (ida, idb)\n",
    "#     except KeyError:\n",
    "#         return (np.nan, np.nan)\n",
    "    \n",
    "# def get_similarity_indices(Clid_pairs, CLid_to_index):\n",
    "#     return zip(*[get_similarity_index(pair, CLid_to_index) for pair in Clid_pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this ends up being faseter for csr matrices\n",
    "def get_similarity_index(clid, CLid_to_index):\n",
    "    \"\"\"\n",
    "    Workhorse function for get_similarities\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return CLid_to_index[clid]\n",
    "    except KeyError:\n",
    "        return np.nan\n",
    "    \n",
    "def get_similarity_indices(CLid_pairs, CLid_to_index):\n",
    "    \n",
    "    # get lists of CL ids\n",
    "    CLids = zip(*CLid_pairs)\n",
    "    citing_clids = list(CLids[0])\n",
    "    cited_clids = list(CLids[1])\n",
    "\n",
    "    # get similarity matrix indices\n",
    "    idA = np.array([get_similarity_index(clid, CLid_to_index) for clid in citing_clids])\n",
    "    idB = np.array([get_similarity_index(clid, CLid_to_index) for clid in cited_clids])\n",
    "\n",
    "    # which indices don't have nans\n",
    "    not_nan_indices = np.where(~(np.isnan(idB) | np.isnan(idA)))[0]\n",
    "\n",
    "    similarities = np.array([np.nan]*len(idA))\n",
    "    similarities[not_nan_indices] = 0.0\n",
    "    \n",
    "    # row indices should be smaller set\n",
    "    if len(set(idA[not_nan_indices])) <= len(set(idB[not_nan_indices])):\n",
    "        row_indices = idA[not_nan_indices].astype(int)\n",
    "        col_indices = idB[not_nan_indices].astype(int)\n",
    "    else:\n",
    "        col_indices = idA[not_nan_indices].astype(int)\n",
    "        row_indices = idB[not_nan_indices].astype(int)\n",
    "    \n",
    "    return row_indices, col_indices, similarities\n",
    "\n",
    "\n",
    "def get_similarities2(similarity_matrix, CLid_pairs, CLid_to_index):\n",
    "    # row/column indices of similarity matrix \n",
    "    row_indices, col_indices, similarities = get_similarity_indices(CLid_pairs, CLid_to_index)\n",
    "\n",
    "    # the rows we want to get from the similarity matrix\n",
    "    rows_to_get = list(set(row_indices))\n",
    "\n",
    "    # get row subsetted similarity matrix\n",
    "    row_subsetted_matrix = similarity_matrix[rows_to_get, :]\n",
    "\n",
    "    # map the row indices from original matrix to row indices in row subsetting matrix\n",
    "    row_indices_subseted = [np.where(rows_to_get == i)[0][0] for i in row_indices]\n",
    "\n",
    "    # get the similarities that we actually have\n",
    "    if type(row_subsetted_matrix) == np.ndarray:\n",
    "        sims = row_subsetted_matrix[row_indices_subseted, col_indices]\n",
    "    else:\n",
    "        sims = row_subsetted_matrix.toarray()[row_indices_subseted, col_indices]\n",
    "\n",
    "    \n",
    "    # update similarities\n",
    "    similarities[~np.isnan(similarities)] = sims\n",
    "    \n",
    "    return similarities.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_similarity(similarity_matrix, CLid_pair, CLid_to_index):\n",
    "    \"\"\"\n",
    "    Workhorse function for get_similarities\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ida = CLid_to_index[CLid_pair[0]]\n",
    "        idb = CLid_to_index[CLid_pair[1]]\n",
    "\n",
    "        return similarity_matrix[ida, idb]\n",
    "    except KeyError:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def get_similarities1(similarity_matrix, CLid_pairs, CLid_to_index):\n",
    "    \"\"\"\n",
    "    Returns the similarities for cases index by CL ids as a list from\n",
    "    precomuted similarity matrix\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    similarity_matrix: precomputed similarity matrix\n",
    "\n",
    "    CLid_pair: lists of CL id pairs whose similarities we want\n",
    "\n",
    "    CLid_to_index: dict that maps CL ids to similarity_matrix indices\n",
    "    \"\"\"\n",
    "    return [get_similarity(similarity_matrix, pair, CLid_to_index) for pair in CLid_pairs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare similarity matrix functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time1 = 0\n",
    "time2 = 0\n",
    "\n",
    "seed = 243\n",
    "\n",
    "R = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute ranking metrics function\n",
    "\n",
    "# get list of test cases\n",
    "test_vertices = get_test_cases(G, active_years, R, seed)\n",
    "\n",
    "# load snapshots\n",
    "snapshots_dict = load_snapshots(experiment_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "similarity_matrix, CLid_to_index = load_similarity_matrix(experiment_data_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# run until we get R test cases (some cases might not have any citations)\n",
    "for i in range(R):\n",
    "\n",
    "\n",
    "    # randomly select a case\n",
    "    test_case = test_vertices[i]\n",
    "\n",
    "    # converted ig index to CL id\n",
    "    cited_cases = get_cited_cases(G, test_case)\n",
    "\n",
    "\n",
    "    # get vetex metrics in year before citing year\n",
    "    snapshot_year = test_case['year'] - 1\n",
    "\n",
    "    # grab data frame of vertex metrics for test case's snapshot\n",
    "    snapshot_df = snapshots_dict['vertex_metrics_' +\n",
    "                                 str(int(snapshot_year))]\n",
    "\n",
    "    # restrict ourselves to ancestors of ing\n",
    "    # case strictly before ing year\n",
    "    ancentors = [v.index for v in G.vs.select(year_le=snapshot_year)]\n",
    "\n",
    "    # all edges from ing case to previous cases\n",
    "    edgelist = zip([test_case.index] * len(ancentors), ancentors)\n",
    "\n",
    "    # get edge data function\n",
    "\n",
    "    ed_CLids = [G.vs[edge[1]]['name'] for edge in edgelist]\n",
    "    ing_CLids = [G.vs[edge[0]]['name'] for edge in edgelist]\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    sims1 = get_similarities1(similarity_matrix, zip(ing_CLids, ed_CLids), CLid_to_index)\n",
    "    time1 += (time.time() - start)\n",
    "    \n",
    "    start = time.time()\n",
    "    sims2 = get_similarities2(similarity_matrix, zip(ing_CLids, ed_CLids), CLid_to_index)\n",
    "    time2 += (time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix time1: 2 seconds \n",
      "matrix time2: 12 seconds \n"
     ]
    }
   ],
   "source": [
    "print 'matrix time1: %d seconds ' % time1\n",
    "print 'matrix time2: %d seconds ' % time2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
