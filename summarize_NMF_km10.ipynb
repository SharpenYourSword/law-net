{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize K-Means (K=10) Cluster for NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# modify these for your own computer\n",
    "repo_directory = '/Users/Michael/Documents/GitHub/law-net/'\n",
    "\n",
    "data_dir = '/Users/Michael/Desktop/network_data/'\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cPickle  as pickle\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "\n",
    "\n",
    "# graph package\n",
    "import igraph as ig\n",
    "\n",
    "\n",
    "# stat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
    "from sklearn.metrics import adjusted_mutual_info_score as ami\n",
    "from sklearn.metrics import mutual_info_score as mi\n",
    "from sklearn.metrics import adjusted_rand_score as ar\n",
    "from sklearn.metrics import calinski_harabaz_score as ch # (X, labels)\n",
    "from sklearn.metrics import completeness_score as cs # metric isn't symmetric (labels_true, labels_predicted)\n",
    "from sklearn.metrics import fowlkes_mallows_score as fm\n",
    "from sklearn.metrics import homogeneity_completeness_v_measure as hcvm\n",
    "from sklearn.metrics import homogeneity_score as hs # metric isn't symmetric (labels_true, labels_predicted)\n",
    "from sklearn.metrics import silhouette_score as ss # (X, labels)\n",
    "from sklearn.metrics import silhouette_samples as ss2 # (X, labels)\n",
    "from sklearn.metrics import v_measure_score as vm\n",
    "\n",
    "import scipy.sparse\n",
    "import random\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "# our code\n",
    "sys.path.append(repo_directory + 'code/')\n",
    "from summarize_clusters import *\n",
    "from helpful_functions import *\n",
    "\n",
    "sys.path.append(repo_directory + 'vertex_metrics_experiment/code/')\n",
    "from bag_of_words import * \n",
    "\n",
    "# which network to download data for\n",
    "network_name = 'scotus' # 'federal', 'ca1', etc\n",
    "\n",
    "\n",
    "# some sub directories that get used\n",
    "raw_dir = data_dir + 'raw/'\n",
    "subnet_dir = data_dir + network_name + '/'\n",
    "text_dir = subnet_dir + 'textfiles/'\n",
    "nlp_dir = subnet_dir + 'nlp/'\n",
    "nlp_sub_dir = nlp_dir + 'bow_tfidf/' #tfidf matrix (and other info, i.e. vocab) computed from bag-of-words matrix\n",
    "nlp_bow_dir = nlp_dir + 'bow/' #bag-of-words matrix (and other info, i.e. vocab)\n",
    "nlp_df_sub_dir = nlp_dir + 'bow_tfidf_df/'\n",
    "\n",
    "# csv location\n",
    "csv_dir = \"C:/Users/Michael/Documents/GitHub/law-net/csv/\"\n",
    "csv_dir_NMF_km10 = \"C:/Users/Michael/Documents/GitHub/law-net/csv/summarize_NMF_km10/\"\n",
    "csv_dir_NMF_km10_info = \"C:/Users/Michael/Documents/GitHub/law-net/csv/summarize_NMF_km10/info/\"\n",
    "csv_dir_NMF_km10_summary = \"C:/Users/Michael/Documents/GitHub/law-net/csv/summarize_NMF_km10/summary/\"\n",
    "\n",
    "# all the file paths for .txt files\n",
    "file_paths = glob.glob(text_dir + '*.txt')\n",
    "\n",
    "# all opinions\n",
    "all_the_opinions = all_opinions(file_paths)\n",
    "\n",
    "# clusters directory\n",
    "clusters_dir = \"C:/Users/Michael/Desktop/network_data/raw/scotus/clusters/\"\n",
    "\n",
    "# jupyter notebook settings\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load tf-idf vectors\n",
    "**tfidf_matrix** = (row_index, column_index): tf_idf value (**CSR FORMAT**)  \n",
    "**op_id_to_bow_id** = opinion_id (corresponds to row indices)  \n",
    "**vocab** = all the words in tfidf_matrix (correspond to column indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_matrix, op_id_to_bow_id, vocab = load_tf_idf(nlp_sub_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<27885x567570 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 20817470 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>km_10</th>\n",
       "      <th>km_100</th>\n",
       "      <th>km_1000</th>\n",
       "      <th>gmm_10</th>\n",
       "      <th>gmm_100</th>\n",
       "      <th>gmm_1000</th>\n",
       "      <th>hc_10</th>\n",
       "      <th>hc_100</th>\n",
       "      <th>hc_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145658</td>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "      <td>356</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>807</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89370</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>557</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89371</td>\n",
       "      <td>4</td>\n",
       "      <td>73</td>\n",
       "      <td>546</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89372</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>719</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>523</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89373</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>602</td>\n",
       "      <td>6</td>\n",
       "      <td>74</td>\n",
       "      <td>681</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  km_10  km_100  km_1000  gmm_10  gmm_100  gmm_1000  hc_10  \\\n",
       "0      145658      5      71      356       0       37       807      1   \n",
       "1       89370      4      71      557       0       37       145      1   \n",
       "2       89371      4      73      546       7       11       560      1   \n",
       "3       89372      4      12      719       0       13       523      1   \n",
       "4       89373      9      10      602       6       74       681      1   \n",
       "\n",
       "   hc_100  hc_1000  \n",
       "0      86       74  \n",
       "1      61      267  \n",
       "2      85      144  \n",
       "3       1      814  \n",
       "4      47       79  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = pd.read_csv(csv_dir + 'clusters_NMF.csv')\n",
    "clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145658    5\n",
       "89370     4\n",
       "89371     4\n",
       "89372     4\n",
       "89373     9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_tfidf_clusters = clusters['km_10'].tolist()\n",
    "\n",
    "nlp_clusters = pd.Series(nlp_tfidf_clusters, index=op_id_to_bow_id)\n",
    "nlp_clusters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the top 5 biggest clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 4 : 20556 opinions\n",
      "cluster 9 : 3563 opinions\n",
      "cluster 5 : 1641 opinions\n",
      "cluster 7 : 759 opinions\n",
      "cluster 0 : 472 opinions\n",
      "cluster 1 : 272 opinions\n",
      "cluster 2 : 261 opinions\n",
      "cluster 3 : 195 opinions\n",
      "cluster 8 : 107 opinions\n",
      "cluster 6 : 59 opinions\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "dict_top_n_clusters = dictionary of top K clusters \n",
    "                      (key=cluster #, value=opinions in cluster)\n",
    "                      \n",
    "biggest_n_clusters = list of top K clusters (int)\n",
    "'''\n",
    "\n",
    "dict_top_n_clusters, biggest_n_clusters = get_top_n_clusters(10, 10, nlp_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top K Words of Each Cluster\n",
    "This function summarizes a set of opinions by returning the words that appear in these opinions with the highest tf-idf scores.\n",
    "\n",
    "# Top K Words ($\\mu_{cluster}$) of Each Cluster\n",
    "compute the mean tf-idf vector of the cluster, return the top K words from this mean vector\n",
    "\n",
    "# Top K Words ($\\mu_{cluster} - \\mu_{complement}$ ) of Each Cluster\n",
    "compute the mean tf-idf vector of the cluster and also of the complement of the cluster,  \n",
    "take the difference mu_cluster - mu_complement, return the top K words in this difference\n",
    "\n",
    "# Most Relevant Opinion of Each Cluster\n",
    "compute the mean tf-idf vector, return the document in the cluster closet to the mean  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_infos_csv(biggest_n_clusters, dict_top_n_clusters, clusters_dir, csv_dir_info):\n",
    "    \n",
    "    for i in biggest_n_clusters:\n",
    "        \n",
    "        opinion_names = []\n",
    "        opinion_dates = []\n",
    "        opinion_links = []\n",
    "        \n",
    "        for j in dict_top_n_clusters[i]:\n",
    "            try:\n",
    "                with open(clusters_dir + j + \".json\") as data_file:\n",
    "                    data = json.load(data_file)\n",
    "            except IOError:\n",
    "                pass\n",
    "                #name, date, link = case_info2(i)\n",
    "                #opinion_names.append(name)\n",
    "                #opinion_dates.append(date)\n",
    "                #opinion_links.append(link)\n",
    "            \n",
    "            name = data['case_name'].encode('utf-8')\n",
    "            date = data['date_filed'].encode('utf-8')\n",
    "            link = 'https://www.courtlistener.com' + data['absolute_url'].encode('utf-8')\n",
    "\n",
    "            opinion_names.append(name)\n",
    "            opinion_dates.append(date)\n",
    "            opinion_links.append(link)\n",
    "\n",
    "        cluster_info = pd.DataFrame()\n",
    "        cluster_info['names'] = opinion_names\n",
    "        cluster_info['dates'] = opinion_dates\n",
    "        cluster_info['url'] = opinion_links\n",
    "\n",
    "        cluster_info.to_csv(csv_dir_info + \"cluster_\"+str(i)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cluster_infos_csv(biggest_n_clusters, dict_top_n_clusters, clusters_dir, csv_dir_NMF_km10_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_summaries_csv(k, biggest_n_clusters, dict_top_n_clusters, tfidf_matrix, op_id_to_bow_id, vocab, csv_dir_summary):\n",
    "    for i in biggest_n_clusters:\n",
    "        top_words = top_k_words(dict_top_n_clusters[i], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "        top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[i], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "        top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[i], all_the_opinions, k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "        most_relev_op = document_closest_to_mean(dict_top_n_clusters[i], tfidf_matrix, op_id_to_bow_id)\n",
    "        \n",
    "        top_words = [x.encode('utf-8') for x in top_words]\n",
    "        top_words_from_mean = [x.encode('utf-8') for x in top_words_from_mean]\n",
    "        top_words_from_diff = [x.encode('utf-8') for x in top_words_from_diff]\n",
    "\n",
    "        len_old_top_words = len(top_words)\n",
    "        len_old_top_words_from_mean = len(top_words_from_mean)\n",
    "        len_old_top_words_from_diff = len(top_words_from_diff)\n",
    "\n",
    "        if len(top_words) != len(top_words_from_mean):\n",
    "            for j in range(0,len(top_words_from_mean)-len(top_words)):\n",
    "                top_words.append(np.nan)\n",
    "\n",
    "        cluster_summary = pd.DataFrame()\n",
    "        cluster_summary['top_words'] = top_words\n",
    "        cluster_summary['top_words_from_mean'] = top_words_from_mean\n",
    "        cluster_summary['top_words_from_diff'] = top_words_from_diff\n",
    "        cluster_summary['most_relev_op'] = most_relev_op\n",
    "\n",
    "        cluster_summary.to_csv(csv_dir_summary + \"cluster_\"+str(i)+\"_summary.csv\")\n",
    "        print \"cluster\", i, \"is done\", \"(\", len(dict_top_n_clusters[i]), \"opinions )\", len_old_top_words, len_old_top_words_from_mean, len_old_top_words_from_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 4 is done ( 20556 opinions ) 1000 1000 1000\n",
      "cluster 9 is done ( 3563 opinions ) 1000 1000 1000\n",
      "cluster 5 is done ( 1641 opinions ) 1000 1000 1000\n",
      "cluster 7 is done ( 759 opinions ) 1000 1000 1000\n",
      "cluster 0 is done ( 472 opinions ) 1000 1000 1000\n",
      "cluster 1 is done ( 272 opinions ) 1000 1000 1000\n",
      "cluster 2 is done ( 261 opinions ) 1000 1000 1000\n",
      "cluster 3 is done ( 195 opinions ) 1000 1000 1000\n",
      "cluster 8 is done ( 107 opinions ) 1000 1000 1000\n",
      "cluster 6 is done ( 59 opinions ) 1000 1000 1000\n",
      "Wall time: 7min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cluster_summaries_csv(1000, biggest_n_clusters, dict_top_n_clusters, tfidf_matrix, op_id_to_bow_id, vocab, csv_dir_NMF_km10_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
