{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize HC (K=100) Cluster for NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# modify these for your own computer\n",
    "repo_directory = '/Users/Michael/Documents/GitHub/law-net/'\n",
    "\n",
    "data_dir = '/Users/Michael/Desktop/network_data/'\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cPickle  as pickle\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "\n",
    "\n",
    "# graph package\n",
    "import igraph as ig\n",
    "\n",
    "\n",
    "# stat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
    "from sklearn.metrics import adjusted_mutual_info_score as ami\n",
    "from sklearn.metrics import mutual_info_score as mi\n",
    "from sklearn.metrics import adjusted_rand_score as ar\n",
    "from sklearn.metrics import calinski_harabaz_score as ch # (X, labels)\n",
    "from sklearn.metrics import completeness_score as cs # metric isn't symmetric (labels_true, labels_predicted)\n",
    "from sklearn.metrics import fowlkes_mallows_score as fm\n",
    "from sklearn.metrics import homogeneity_completeness_v_measure as hcvm\n",
    "from sklearn.metrics import homogeneity_score as hs # metric isn't symmetric (labels_true, labels_predicted)\n",
    "from sklearn.metrics import silhouette_score as ss # (X, labels)\n",
    "from sklearn.metrics import silhouette_samples as ss2 # (X, labels)\n",
    "from sklearn.metrics import v_measure_score as vm\n",
    "\n",
    "import scipy.sparse\n",
    "import random\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "# our code\n",
    "sys.path.append(repo_directory + 'code/')\n",
    "from summarize_clusters import *\n",
    "from helpful_functions import *\n",
    "\n",
    "sys.path.append(repo_directory + 'vertex_metrics_experiment/code/')\n",
    "from bag_of_words import * \n",
    "\n",
    "# which network to download data for\n",
    "network_name = 'scotus' # 'federal', 'ca1', etc\n",
    "\n",
    "\n",
    "# some sub directories that get used\n",
    "raw_dir = data_dir + 'raw/'\n",
    "subnet_dir = data_dir + network_name + '/'\n",
    "text_dir = subnet_dir + 'textfiles/'\n",
    "nlp_dir = subnet_dir + 'nlp/'\n",
    "nlp_sub_dir = nlp_dir + 'bow_tfidf/' #tfidf matrix (and other info, i.e. vocab) computed from bag-of-words matrix\n",
    "nlp_bow_dir = nlp_dir + 'bow/' #bag-of-words matrix (and other info, i.e. vocab)\n",
    "nlp_df_sub_dir = nlp_dir + 'bow_tfidf_df/'\n",
    "\n",
    "# csv location\n",
    "csv_dir = \"C:/Users/Michael/Documents/GitHub/law-net/csv/\"\n",
    "csv_dir_NMF_hc100 = \"C:/Users/Michael/Documents/GitHub/law-net/csv/summarize_NMF_hc100/\"\n",
    "csv_dir_NMF_hc100_info = \"C:/Users/Michael/Documents/GitHub/law-net/csv/summarize_NMF_hc100/info/\"\n",
    "csv_dir_NMF_hc100_summary = \"C:/Users/Michael/Documents/GitHub/law-net/csv/summarize_NMF_hc100/summary/\"\n",
    "\n",
    "# all the file paths for .txt files\n",
    "file_paths = glob.glob(text_dir + '*.txt')\n",
    "\n",
    "# all opinions\n",
    "all_the_opinions = all_opinions(file_paths)\n",
    "\n",
    "# clusters directory\n",
    "clusters_dir = \"C:/Users/Michael/Desktop/network_data/raw/scotus/clusters/\"\n",
    "\n",
    "# jupyter notebook settings\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load tf-idf vectors\n",
    "**tfidf_matrix** = (row_index, column_index): tf_idf value (**CSR FORMAT**)  \n",
    "**op_id_to_bow_id** = opinion_id (corresponds to row indices)  \n",
    "**vocab** = all the words in tfidf_matrix (correspond to column indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_matrix, op_id_to_bow_id, vocab = load_tf_idf(nlp_sub_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<27885x567570 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 20817470 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>km_10</th>\n",
       "      <th>km_100</th>\n",
       "      <th>km_1000</th>\n",
       "      <th>gmm_10</th>\n",
       "      <th>gmm_100</th>\n",
       "      <th>gmm_1000</th>\n",
       "      <th>hc_10</th>\n",
       "      <th>hc_100</th>\n",
       "      <th>hc_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145658</td>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "      <td>356</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>807</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89370</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>557</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89371</td>\n",
       "      <td>4</td>\n",
       "      <td>73</td>\n",
       "      <td>546</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89372</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>719</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>523</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89373</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>602</td>\n",
       "      <td>6</td>\n",
       "      <td>74</td>\n",
       "      <td>681</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  km_10  km_100  km_1000  gmm_10  gmm_100  gmm_1000  hc_10  \\\n",
       "0      145658      5      71      356       0       37       807      1   \n",
       "1       89370      4      71      557       0       37       145      1   \n",
       "2       89371      4      73      546       7       11       560      1   \n",
       "3       89372      4      12      719       0       13       523      1   \n",
       "4       89373      9      10      602       6       74       681      1   \n",
       "\n",
       "   hc_100  hc_1000  \n",
       "0      86       74  \n",
       "1      61      267  \n",
       "2      85      144  \n",
       "3       1      814  \n",
       "4      47       79  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = pd.read_csv(csv_dir + 'clusters_NMF.csv')\n",
    "clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145658    86\n",
       "89370     61\n",
       "89371     85\n",
       "89372      1\n",
       "89373     47\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_tfidf_clusters = clusters['hc_100'].tolist()\n",
    "\n",
    "nlp_clusters = pd.Series(nlp_tfidf_clusters, index=op_id_to_bow_id)\n",
    "nlp_clusters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the top 5 biggest clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 1 : 5305 opinions\n",
      "cluster 8 : 1408 opinions\n",
      "cluster 9 : 1139 opinions\n",
      "cluster 29 : 1094 opinions\n",
      "cluster 21 : 634 opinions\n",
      "cluster 32 : 583 opinions\n",
      "cluster 53 : 552 opinions\n",
      "cluster 2 : 535 opinions\n",
      "cluster 64 : 530 opinions\n",
      "cluster 15 : 516 opinions\n",
      "cluster 47 : 463 opinions\n",
      "cluster 39 : 450 opinions\n",
      "cluster 23 : 440 opinions\n",
      "cluster 14 : 429 opinions\n",
      "cluster 28 : 427 opinions\n",
      "cluster 85 : 420 opinions\n",
      "cluster 0 : 419 opinions\n",
      "cluster 16 : 394 opinions\n",
      "cluster 36 : 349 opinions\n",
      "cluster 40 : 341 opinions\n",
      "cluster 10 : 336 opinions\n",
      "cluster 59 : 320 opinions\n",
      "cluster 41 : 319 opinions\n",
      "cluster 75 : 309 opinions\n",
      "cluster 44 : 302 opinions\n",
      "cluster 11 : 295 opinions\n",
      "cluster 31 : 292 opinions\n",
      "cluster 46 : 292 opinions\n",
      "cluster 58 : 287 opinions\n",
      "cluster 49 : 283 opinions\n",
      "cluster 12 : 263 opinions\n",
      "cluster 27 : 252 opinions\n",
      "cluster 45 : 252 opinions\n",
      "cluster 22 : 250 opinions\n",
      "cluster 6 : 221 opinions\n",
      "cluster 76 : 220 opinions\n",
      "cluster 34 : 219 opinions\n",
      "cluster 71 : 216 opinions\n",
      "cluster 86 : 204 opinions\n",
      "cluster 30 : 201 opinions\n",
      "cluster 13 : 198 opinions\n",
      "cluster 38 : 194 opinions\n",
      "cluster 96 : 189 opinions\n",
      "cluster 4 : 188 opinions\n",
      "cluster 33 : 179 opinions\n",
      "cluster 56 : 176 opinions\n",
      "cluster 95 : 164 opinions\n",
      "cluster 54 : 162 opinions\n",
      "cluster 20 : 161 opinions\n",
      "cluster 87 : 161 opinions\n",
      "cluster 7 : 159 opinions\n",
      "cluster 69 : 156 opinions\n",
      "cluster 98 : 156 opinions\n",
      "cluster 42 : 152 opinions\n",
      "cluster 70 : 149 opinions\n",
      "cluster 24 : 143 opinions\n",
      "cluster 17 : 141 opinions\n",
      "cluster 80 : 140 opinions\n",
      "cluster 84 : 135 opinions\n",
      "cluster 79 : 128 opinions\n",
      "cluster 19 : 125 opinions\n",
      "cluster 92 : 117 opinions\n",
      "cluster 81 : 112 opinions\n",
      "cluster 89 : 112 opinions\n",
      "cluster 93 : 110 opinions\n",
      "cluster 88 : 109 opinions\n",
      "cluster 68 : 107 opinions\n",
      "cluster 60 : 105 opinions\n",
      "cluster 78 : 105 opinions\n",
      "cluster 66 : 103 opinions\n",
      "cluster 91 : 97 opinions\n",
      "cluster 51 : 94 opinions\n",
      "cluster 90 : 93 opinions\n",
      "cluster 48 : 92 opinions\n",
      "cluster 77 : 89 opinions\n",
      "cluster 26 : 83 opinions\n",
      "cluster 25 : 81 opinions\n",
      "cluster 50 : 76 opinions\n",
      "cluster 61 : 76 opinions\n",
      "cluster 74 : 75 opinions\n",
      "cluster 97 : 73 opinions\n",
      "cluster 52 : 71 opinions\n",
      "cluster 37 : 70 opinions\n",
      "cluster 63 : 64 opinions\n",
      "cluster 5 : 63 opinions\n",
      "cluster 43 : 59 opinions\n",
      "cluster 35 : 56 opinions\n",
      "cluster 18 : 55 opinions\n",
      "cluster 72 : 52 opinions\n",
      "cluster 82 : 45 opinions\n",
      "cluster 94 : 45 opinions\n",
      "cluster 3 : 43 opinions\n",
      "cluster 83 : 38 opinions\n",
      "cluster 55 : 35 opinions\n",
      "cluster 67 : 33 opinions\n",
      "cluster 65 : 32 opinions\n",
      "cluster 99 : 30 opinions\n",
      "cluster 57 : 28 opinions\n",
      "cluster 62 : 23 opinions\n",
      "cluster 73 : 17 opinions\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "dict_top_n_clusters = dictionary of top K clusters \n",
    "                      (key=cluster #, value=opinions in cluster)\n",
    "                      \n",
    "biggest_n_clusters = list of top K clusters (int)\n",
    "'''\n",
    "\n",
    "dict_top_n_clusters, biggest_n_clusters = get_top_n_clusters(100, 100, nlp_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top K Words of Each Cluster\n",
    "This function summarizes a set of opinions by returning the words that appear in these opinions with the highest tf-idf scores.\n",
    "\n",
    "# Top K Words ($\\mu_{cluster}$) of Each Cluster\n",
    "compute the mean tf-idf vector of the cluster, return the top K words from this mean vector\n",
    "\n",
    "# Top K Words ($\\mu_{cluster} - \\mu_{complement}$ ) of Each Cluster\n",
    "compute the mean tf-idf vector of the cluster and also of the complement of the cluster,  \n",
    "take the difference mu_cluster - mu_complement, return the top K words in this difference\n",
    "\n",
    "# Most Relevant Opinion of Each Cluster\n",
    "compute the mean tf-idf vector, return the document in the cluster closet to the mean  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_infos_csv(biggest_n_clusters, dict_top_n_clusters, clusters_dir, csv_dir_info):\n",
    "    \n",
    "    for i in biggest_n_clusters:\n",
    "        \n",
    "        opinion_names = []\n",
    "        opinion_dates = []\n",
    "        opinion_links = []\n",
    "        \n",
    "        for j in dict_top_n_clusters[i]:\n",
    "            try:\n",
    "                with open(clusters_dir + j + \".json\") as data_file:\n",
    "                    data = json.load(data_file)\n",
    "            except IOError:\n",
    "                pass\n",
    "                #name, date, link = case_info2(i)\n",
    "                #opinion_names.append(name)\n",
    "                #opinion_dates.append(date)\n",
    "                #opinion_links.append(link)\n",
    "            \n",
    "            name = data['case_name'].encode('utf-8')\n",
    "            date = data['date_filed'].encode('utf-8')\n",
    "            link = 'https://www.courtlistener.com' + data['absolute_url'].encode('utf-8')\n",
    "\n",
    "            opinion_names.append(name)\n",
    "            opinion_dates.append(date)\n",
    "            opinion_links.append(link)\n",
    "\n",
    "        cluster_info = pd.DataFrame()\n",
    "        cluster_info['names'] = opinion_names\n",
    "        cluster_info['dates'] = opinion_dates\n",
    "        cluster_info['url'] = opinion_links\n",
    "\n",
    "        cluster_info.to_csv(csv_dir_info + \"cluster_\"+str(i)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cluster_infos_csv(biggest_n_clusters, dict_top_n_clusters, clusters_dir, csv_dir_NMF_hc100_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_summaries_csv(k, biggest_n_clusters, dict_top_n_clusters, tfidf_matrix, op_id_to_bow_id, vocab, csv_dir_summary):\n",
    "    for i in biggest_n_clusters:\n",
    "        top_words = top_k_words(dict_top_n_clusters[i], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "        top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[i], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "        top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[i], all_the_opinions, k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "        most_relev_op = document_closest_to_mean(dict_top_n_clusters[i], tfidf_matrix, op_id_to_bow_id)\n",
    "        \n",
    "        top_words = [x.encode('utf-8') for x in top_words]\n",
    "        top_words_from_mean = [x.encode('utf-8') for x in top_words_from_mean]\n",
    "        top_words_from_diff = [x.encode('utf-8') for x in top_words_from_diff]\n",
    "\n",
    "        len_old_top_words = len(top_words)\n",
    "        len_old_top_words_from_mean = len(top_words_from_mean)\n",
    "        len_old_top_words_from_diff = len(top_words_from_diff)\n",
    "\n",
    "        if len(top_words) != len(top_words_from_mean):\n",
    "            for j in range(0,len(top_words_from_mean)-len(top_words)):\n",
    "                top_words.append(np.nan)\n",
    "\n",
    "        cluster_summary = pd.DataFrame()\n",
    "        cluster_summary['top_words'] = top_words\n",
    "        cluster_summary['top_words_from_mean'] = top_words_from_mean\n",
    "        cluster_summary['top_words_from_diff'] = top_words_from_diff\n",
    "        cluster_summary['most_relev_op'] = most_relev_op\n",
    "\n",
    "        cluster_summary.to_csv(csv_dir_summary + \"cluster_\"+str(i)+\"_summary.csv\")\n",
    "        print \"cluster\", i, \"is done\", \"(\", len(dict_top_n_clusters[i]), \"opinions )\", len_old_top_words, len_old_top_words_from_mean, len_old_top_words_from_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 1 is done ( 5305 opinions ) 1000 1000 1000\n",
      "cluster 8 is done ( 1408 opinions ) 1000 1000 1000\n",
      "cluster 9 is done ( 1139 opinions ) 1000 1000 1000\n",
      "cluster 29 is done ( 1094 opinions ) 1000 1000 1000\n",
      "cluster 21 is done ( 634 opinions ) 1000 1000 1000\n",
      "cluster 32 is done ( 583 opinions ) 1000 1000 1000\n",
      "cluster 53 is done ( 552 opinions ) 1000 1000 1000\n",
      "cluster 2 is done ( 535 opinions ) 1000 1000 1000\n",
      "cluster 64 is done ( 530 opinions ) 1000 1000 1000\n",
      "cluster 15 is done ( 516 opinions ) 1000 1000 1000\n",
      "cluster 47 is done ( 463 opinions ) 1000 1000 1000\n",
      "cluster 39 is done ( 450 opinions ) 1000 1000 1000\n",
      "cluster 23 is done ( 440 opinions ) 1000 1000 1000\n",
      "cluster 14 is done ( 429 opinions ) 1000 1000 1000\n",
      "cluster 28 is done ( 427 opinions ) 1000 1000 1000\n",
      "cluster 85 is done ( 420 opinions ) 1000 1000 1000\n",
      "cluster 0 is done ( 419 opinions ) 1000 1000 1000\n",
      "cluster 16 is done ( 394 opinions ) 1000 1000 1000\n",
      "cluster 36 is done ( 349 opinions ) 1000 1000 1000\n",
      "cluster 40 is done ( 341 opinions ) 1000 1000 1000\n",
      "cluster 10 is done ( 336 opinions ) 1000 1000 1000\n",
      "cluster 59 is done ( 320 opinions ) 1000 1000 1000\n",
      "cluster 41 is done ( 319 opinions ) 1000 1000 1000\n",
      "cluster 75 is done ( 309 opinions ) 1000 1000 1000\n",
      "cluster 44 is done ( 302 opinions ) 1000 1000 1000\n",
      "cluster 11 is done ( 295 opinions ) 1000 1000 1000\n",
      "cluster 31 is done ( 292 opinions ) 1000 1000 1000\n",
      "cluster 46 is done ( 292 opinions ) 1000 1000 1000\n",
      "cluster 58 is done ( 287 opinions ) 1000 1000 1000\n",
      "cluster 49 is done ( 283 opinions ) 1000 1000 1000\n",
      "cluster 12 is done ( 263 opinions ) 1000 1000 1000\n",
      "cluster 27 is done ( 252 opinions ) 1000 1000 1000\n",
      "cluster 45 is done ( 252 opinions ) 1000 1000 1000\n",
      "cluster 22 is done ( 250 opinions ) 1000 1000 1000\n",
      "cluster 6 is done ( 221 opinions ) 1000 1000 1000\n",
      "cluster 76 is done ( 220 opinions ) 1000 1000 1000\n",
      "cluster 34 is done ( 219 opinions ) 1000 1000 1000\n",
      "cluster 71 is done ( 216 opinions ) 1000 1000 1000\n",
      "cluster 86 is done ( 204 opinions ) 1000 1000 1000\n",
      "cluster 30 is done ( 201 opinions ) 1000 1000 1000\n",
      "cluster 13 is done ( 198 opinions ) 1000 1000 1000\n",
      "cluster 38 is done ( 194 opinions ) 1000 1000 1000\n",
      "cluster 96 is done ( 189 opinions ) 1000 1000 1000\n",
      "cluster 4 is done ( 188 opinions ) 1000 1000 1000\n",
      "cluster 33 is done ( 179 opinions ) 1000 1000 1000\n",
      "cluster 56 is done ( 176 opinions ) 1000 1000 1000\n",
      "cluster 95 is done ( 164 opinions ) 1000 1000 1000\n",
      "cluster 54 is done ( 162 opinions ) 1000 1000 1000\n",
      "cluster 20 is done ( 161 opinions ) 1000 1000 1000\n",
      "cluster 87 is done ( 161 opinions ) 1000 1000 1000\n",
      "cluster 7 is done ( 159 opinions ) 1000 1000 1000\n",
      "cluster 69 is done ( 156 opinions ) 1000 1000 1000\n",
      "cluster 98 is done ( 156 opinions ) 1000 1000 1000\n",
      "cluster 42 is done ( 152 opinions ) 1000 1000 1000\n",
      "cluster 70 is done ( 149 opinions ) 1000 1000 1000\n",
      "cluster 24 is done ( 143 opinions ) 1000 1000 1000\n",
      "cluster 17 is done ( 141 opinions ) 1000 1000 1000\n",
      "cluster 80 is done ( 140 opinions ) 1000 1000 1000\n",
      "cluster 84 is done ( 135 opinions ) 1000 1000 1000\n",
      "cluster 79 is done ( 128 opinions ) 1000 1000 1000\n",
      "cluster 19 is done ( 125 opinions ) 1000 1000 1000\n",
      "cluster 92 is done ( 117 opinions ) 1000 1000 1000\n",
      "cluster 81 is done ( 112 opinions ) 1000 1000 1000\n",
      "cluster 89 is done ( 112 opinions ) 1000 1000 1000\n",
      "cluster 93 is done ( 110 opinions ) 1000 1000 1000\n",
      "cluster 88 is done ( 109 opinions ) 1000 1000 1000\n",
      "cluster 68 is done ( 107 opinions ) 1000 1000 1000\n",
      "cluster 60 is done ( 105 opinions ) 1000 1000 1000\n",
      "cluster 78 is done ( 105 opinions ) 1000 1000 1000\n",
      "cluster 66 is done ( 103 opinions ) 1000 1000 1000\n",
      "cluster 91 is done ( 97 opinions ) 1000 1000 1000\n",
      "cluster 51 is done ( 94 opinions ) 1000 1000 1000\n",
      "cluster 90 is done ( 93 opinions ) 1000 1000 1000\n",
      "cluster 48 is done ( 92 opinions ) 1000 1000 1000\n",
      "cluster 77 is done ( 89 opinions ) 1000 1000 1000\n",
      "cluster 26 is done ( 83 opinions ) 1000 1000 1000\n",
      "cluster 25 is done ( 81 opinions ) 1000 1000 1000\n",
      "cluster 50 is done ( 76 opinions ) 1000 1000 1000\n",
      "cluster 61 is done ( 76 opinions ) 1000 1000 1000\n",
      "cluster 74 is done ( 75 opinions ) 1000 1000 1000\n",
      "cluster 97 is done ( 73 opinions ) 1000 1000 1000\n",
      "cluster 52 is done ( 71 opinions ) 1000 1000 1000\n",
      "cluster 37 is done ( 70 opinions ) 1000 1000 1000\n",
      "cluster 63 is done ( 64 opinions ) 1000 1000 1000\n",
      "cluster 5 is done ( 63 opinions ) 1000 1000 1000\n",
      "cluster 43 is done ( 59 opinions ) 1000 1000 1000\n",
      "cluster 35 is done ( 56 opinions ) 1000 1000 1000\n",
      "cluster 18 is done ( 55 opinions ) 1000 1000 1000\n",
      "cluster 72 is done ( 52 opinions ) 1000 1000 1000\n",
      "cluster 82 is done ( 45 opinions ) 1000 1000 1000\n",
      "cluster 94 is done ( 45 opinions ) 1000 1000 1000\n",
      "cluster 3 is done ( 43 opinions ) 1000 1000 1000\n",
      "cluster 83 is done ( 38 opinions ) 1000 1000 1000\n",
      "cluster 55 is done ( 35 opinions ) 1000 1000 1000\n",
      "cluster 67 is done ( 33 opinions ) 1000 1000 1000\n",
      "cluster 65 is done ( 32 opinions ) 1000 1000 1000\n",
      "cluster 99 is done ( 30 opinions ) 1000 1000 1000\n",
      "cluster 57 is done ( 28 opinions ) 1000 1000 1000\n",
      "cluster 62 is done ( 23 opinions ) 1000 1000 1000\n",
      "cluster 73 is done ( 17 opinions ) 1000 1000 1000\n",
      "Wall time: 10min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cluster_summaries_csv(1000, biggest_n_clusters, dict_top_n_clusters, tfidf_matrix, op_id_to_bow_id, vocab, csv_dir_NMF_hc100_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
