{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize Modularity Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# modify these for your own computer\n",
    "repo_directory = '/Users/Michael/Documents/GitHub/law-net/'\n",
    "\n",
    "data_dir = '/Users/Michael/Desktop/network_data/'\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cPickle  as pickle\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "\n",
    "\n",
    "# graph package\n",
    "import igraph as ig\n",
    "\n",
    "\n",
    "# stat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
    "from sklearn.metrics import adjusted_mutual_info_score as ami\n",
    "from sklearn.metrics import mutual_info_score as mi\n",
    "from sklearn.metrics import adjusted_rand_score as ar\n",
    "from sklearn.metrics import calinski_harabaz_score as ch # (X, labels)\n",
    "from sklearn.metrics import completeness_score as cs # metric isn't symmetric (labels_true, labels_predicted)\n",
    "from sklearn.metrics import fowlkes_mallows_score as fm\n",
    "from sklearn.metrics import homogeneity_completeness_v_measure as hcvm\n",
    "from sklearn.metrics import homogeneity_score as hs # metric isn't symmetric (labels_true, labels_predicted)\n",
    "from sklearn.metrics import silhouette_score as ss # (X, labels)\n",
    "from sklearn.metrics import silhouette_samples as ss2 # (X, labels)\n",
    "from sklearn.metrics import v_measure_score as vm\n",
    "\n",
    "import scipy.sparse\n",
    "import random\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "# our code\n",
    "sys.path.append(repo_directory + 'code/')\n",
    "from summarize_clusters import *\n",
    "from helpful_functions import *\n",
    "\n",
    "sys.path.append(repo_directory + 'vertex_metrics_experiment/code/')\n",
    "from bag_of_words import * \n",
    "\n",
    "# which network to download data for\n",
    "network_name = 'scotus' # 'federal', 'ca1', etc\n",
    "\n",
    "\n",
    "# some sub directories that get used\n",
    "raw_dir = data_dir + 'raw/'\n",
    "subnet_dir = data_dir + network_name + '/'\n",
    "text_dir = subnet_dir + 'textfiles/'\n",
    "nlp_dir = subnet_dir + 'nlp/'\n",
    "nlp_sub_dir = nlp_dir + 'bow_tfidf/' #tfidf matrix (and other info, i.e. vocab) computed from bag-of-words matrix\n",
    "nlp_bow_dir = nlp_dir + 'bow/' #bag-of-words matrix (and other info, i.e. vocab)\n",
    "nlp_df_sub_dir = nlp_dir + 'bow_tfidf_df/'\n",
    "\n",
    "# csv location\n",
    "csv_dir = \"C:/Users/Michael/Documents/GitHub/law-net/csv/\"\n",
    "csv_dir_mod = \"C:/Users/Michael/Documents/GitHub/law-net/csv/summarize_modularity/\"\n",
    "csv_dir_mod_info = \"C:/Users/Michael/Documents/GitHub/law-net/csv/summarize_modularity/info/\"\n",
    "csv_dir_mod_summary = \"C:/Users/Michael/Documents/GitHub/law-net/csv/summarize_modularity/summary/\"\n",
    "csv_dir_walk = \"C:/Users/Michael/Documents/GitHub/law-net/csv/summarize_walktrap/\"\n",
    "\n",
    "# all the file paths for .txt files\n",
    "file_paths = glob.glob(text_dir + '*.txt')\n",
    "\n",
    "# all opinions\n",
    "all_the_opinions = all_opinions(file_paths)\n",
    "\n",
    "# clusters directory\n",
    "clusters_dir = \"C:/Users/Michael/Desktop/network_data/raw/scotus/clusters/\"\n",
    "\n",
    "# jupyter notebook settings\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load tf-idf vectors\n",
    "**tfidf_matrix** = (row_index, column_index): tf_idf value (**CSR FORMAT**)  \n",
    "**op_id_to_bow_id** = opinion_id (corresponds to row indices)  \n",
    "**vocab** = all the words in tfidf_matrix (correspond to column indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_matrix, op_id_to_bow_id, vocab = load_tf_idf(nlp_sub_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<27885x567570 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 20817470 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print type(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Work:\n",
    "focus on largest connected component of **undirected scotus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the graph\n",
    "G = ig.Graph.Read_GraphML(subnet_dir + network_name +'_network.graphml')\n",
    "\n",
    "# limit ourselves to cases upto and including 2015 since we are missing some textfiles from 2016\n",
    "G = G.subgraph(G.vs.select(year_le=2015))\n",
    "\n",
    "# make graph undirected\n",
    "Gud = G.copy()\n",
    "Gud = Gud.as_undirected()\n",
    "\n",
    "# get largest connected componenet\n",
    "components = Gud.clusters(mode='STRONG')\n",
    "g = components.subgraphs()[np.argmax(components.sizes())]\n",
    "\n",
    "# CL ids of cases in largest connected component\n",
    "CLids = g.vs['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modularity on undirected scotus\n",
    "\"For a given division of the network's vertices into some modules, modularity reflects the concentration of edges within modules compared with random distribution of links between all nodes regardless of modules\"--*Wikipedia*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering with 24724 elements and 126 clusters\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# modularity clustering\n",
    "cd_modularity = g.community_fastgreedy() # .as_clustering().membership\n",
    "\n",
    "mod_clust = cd_modularity.as_clustering()\n",
    "\n",
    "print mod_clust.summary()\n",
    "\n",
    "# save clusters in pandas\n",
    "graph_clusters = pd.Series(mod_clust.membership, index=g.vs['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the top 5 biggest clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 2 : 9273 opinions\n",
      "cluster 0 : 6870 opinions\n",
      "cluster 1 : 6234 opinions\n",
      "cluster 3 : 1458 opinions\n",
      "cluster 15 : 76 opinions\n",
      "cluster 7 : 75 opinions\n",
      "cluster 8 : 69 opinions\n",
      "cluster 4 : 52 opinions\n",
      "cluster 31 : 50 opinions\n",
      "cluster 17 : 36 opinions\n",
      "cluster 48 : 20 opinions\n",
      "cluster 36 : 18 opinions\n",
      "cluster 13 : 16 opinions\n",
      "cluster 40 : 16 opinions\n",
      "cluster 23 : 15 opinions\n",
      "cluster 51 : 15 opinions\n",
      "cluster 54 : 14 opinions\n",
      "cluster 16 : 13 opinions\n",
      "cluster 45 : 12 opinions\n",
      "cluster 42 : 11 opinions\n",
      "cluster 10 : 10 opinions\n",
      "cluster 28 : 10 opinions\n",
      "cluster 19 : 9 opinions\n",
      "cluster 47 : 8 opinions\n",
      "cluster 65 : 8 opinions\n",
      "cluster 6 : 7 opinions\n",
      "cluster 26 : 7 opinions\n",
      "cluster 43 : 7 opinions\n",
      "cluster 46 : 7 opinions\n",
      "cluster 79 : 7 opinions\n",
      "cluster 82 : 7 opinions\n",
      "cluster 94 : 7 opinions\n",
      "cluster 24 : 6 opinions\n",
      "cluster 49 : 6 opinions\n",
      "cluster 21 : 5 opinions\n",
      "cluster 29 : 5 opinions\n",
      "cluster 41 : 5 opinions\n",
      "cluster 44 : 5 opinions\n",
      "cluster 50 : 5 opinions\n",
      "cluster 55 : 5 opinions\n",
      "cluster 58 : 5 opinions\n",
      "cluster 64 : 5 opinions\n",
      "cluster 77 : 5 opinions\n",
      "cluster 96 : 5 opinions\n",
      "cluster 9 : 4 opinions\n",
      "cluster 12 : 4 opinions\n",
      "cluster 20 : 4 opinions\n",
      "cluster 56 : 4 opinions\n",
      "cluster 62 : 4 opinions\n",
      "cluster 80 : 4 opinions\n",
      "cluster 88 : 4 opinions\n",
      "cluster 89 : 4 opinions\n",
      "cluster 90 : 4 opinions\n",
      "cluster 95 : 4 opinions\n",
      "cluster 97 : 4 opinions\n",
      "cluster 98 : 4 opinions\n",
      "cluster 99 : 4 opinions\n",
      "cluster 104 : 4 opinions\n",
      "cluster 113 : 4 opinions\n",
      "cluster 117 : 4 opinions\n",
      "cluster 5 : 3 opinions\n",
      "cluster 14 : 3 opinions\n",
      "cluster 32 : 3 opinions\n",
      "cluster 33 : 3 opinions\n",
      "cluster 34 : 3 opinions\n",
      "cluster 35 : 3 opinions\n",
      "cluster 38 : 3 opinions\n",
      "cluster 39 : 3 opinions\n",
      "cluster 52 : 3 opinions\n",
      "cluster 57 : 3 opinions\n",
      "cluster 61 : 3 opinions\n",
      "cluster 68 : 3 opinions\n",
      "cluster 71 : 3 opinions\n",
      "cluster 72 : 3 opinions\n",
      "cluster 75 : 3 opinions\n",
      "cluster 81 : 3 opinions\n",
      "cluster 83 : 3 opinions\n",
      "cluster 84 : 3 opinions\n",
      "cluster 92 : 3 opinions\n",
      "cluster 103 : 3 opinions\n",
      "cluster 105 : 3 opinions\n",
      "cluster 108 : 3 opinions\n",
      "cluster 109 : 3 opinions\n",
      "cluster 114 : 3 opinions\n",
      "cluster 115 : 3 opinions\n",
      "cluster 119 : 3 opinions\n",
      "cluster 121 : 3 opinions\n",
      "cluster 123 : 3 opinions\n",
      "cluster 124 : 3 opinions\n",
      "cluster 11 : 2 opinions\n",
      "cluster 18 : 2 opinions\n",
      "cluster 22 : 2 opinions\n",
      "cluster 25 : 2 opinions\n",
      "cluster 27 : 2 opinions\n",
      "cluster 30 : 2 opinions\n",
      "cluster 37 : 2 opinions\n",
      "cluster 53 : 2 opinions\n",
      "cluster 59 : 2 opinions\n",
      "cluster 60 : 2 opinions\n",
      "cluster 63 : 2 opinions\n",
      "cluster 66 : 2 opinions\n",
      "cluster 67 : 2 opinions\n",
      "cluster 69 : 2 opinions\n",
      "cluster 70 : 2 opinions\n",
      "cluster 73 : 2 opinions\n",
      "cluster 74 : 2 opinions\n",
      "cluster 76 : 2 opinions\n",
      "cluster 78 : 2 opinions\n",
      "cluster 85 : 2 opinions\n",
      "cluster 86 : 2 opinions\n",
      "cluster 87 : 2 opinions\n",
      "cluster 91 : 2 opinions\n",
      "cluster 93 : 2 opinions\n",
      "cluster 100 : 2 opinions\n",
      "cluster 101 : 2 opinions\n",
      "cluster 102 : 2 opinions\n",
      "cluster 106 : 2 opinions\n",
      "cluster 107 : 2 opinions\n",
      "cluster 110 : 2 opinions\n",
      "cluster 111 : 2 opinions\n",
      "cluster 112 : 2 opinions\n",
      "cluster 116 : 2 opinions\n",
      "cluster 118 : 2 opinions\n",
      "cluster 120 : 2 opinions\n",
      "cluster 122 : 2 opinions\n",
      "cluster 125 : 2 opinions\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "dict_top_n_clusters = dictionary of top K clusters \n",
    "                      (key=cluster #, value=opinions in cluster)\n",
    "                      \n",
    "biggest_n_clusters = list of top K clusters (int)\n",
    "'''\n",
    "\n",
    "dict_top_n_clusters, biggest_n_clusters = get_top_n_clusters(len(mod_clust), len(mod_clust), graph_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print 'p' opinions in biggest cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing 100 out of 9273 opinions in cluster 2 ...\n",
      "\n",
      "['89374', '89375', '89376', '89378', '89379', '91138', '106304', '103549', '103543', '103542', '103547', '97818', '102819', '88397', '88391', '88390', '88398', '97159', '93172', '97157', '102812', '97155', '89377', '88023', '88022', '88021', '88024', '88029', '100014', '91070', '95798', '91132', '97029', '85513', '90312', '90313', '90314', '90316', '90317', '90319', '97027', '96133', '97025', '94542', '94545', '94546', '97934', '97021', '87996', '92260', '89580', '107895', '92887', '92884', '92885', '92883', '92880', '92889', '93139', '104278', '104279', '104276', '104275', '104271', '98102', '97152', '97749', '97156', '98641', '99019', '105639', '105633', '105636', '102946', '102947', '94276', '99013', '94275', '102367', '102364', '102365', '102363', '107704', '112230', '108107', '108103', '109859', '109858', '92600', '92602', '92603', '92605', '103706', '103704', '103703', '107161', '103709', '111955', '104715', '145772']\n"
     ]
    }
   ],
   "source": [
    "cluster = 2\n",
    "p = 100 # to print all opinions in the cluster, let p = len(dict_top_n_clusters[cluster])\n",
    "\n",
    "cluster_opinions = dict_top_n_clusters[cluster]\n",
    "print \"printing\", p, \"out of\", len(cluster_opinions), \"opinions in cluster\", cluster, \"...\"\n",
    "print ''\n",
    "print cluster_opinions[0:p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top K Words of Each Cluster\n",
    "This function summarizes a set of opinions by returning the words that appear in these opinions with the highest tf-idf scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mcluster 2\u001b[0m: ['squier', 'reinsur', 'scophoni', 'graeff', 'arbitr', 'sugg', 'passport', 'wenzel', 'vetterlein', 'meserv']\n",
      "\u001b[1;31mcluster 0\u001b[0m: ['dispensari', 'pension', 'fslic', 'wass', 'bicknel', 'milk', 'jumel', 'boom', 'merriam', 'ch']\n",
      "\u001b[1;31mcluster 1\u001b[0m: ['baal', 'stumpf', 'lagrand', 'ree', 'lesag', 'bail', 'kaupp', 'ashcraft', 'penri', 'mazzei']\n",
      "\u001b[1;31mcluster 3\u001b[0m: ['shaeffer', 'wool', 'carusi', 'toy', 'seed', 'jen', 'paper', 'renfrow', 'pearl', 'cork']\n",
      "\u001b[1;31mcluster 15\u001b[0m: ['flaglor', 'dippold', 'nailor', 'goff', 'turpin', 'reeder', 'bilsland', 'shappirio', 'randel', 'forsyth']\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=10 # number of words to get\n",
    "\n",
    "for i in biggest_n_clusters:\n",
    "    top_words = top_k_words(dict_top_n_clusters[i], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "    print '\\x1b[1;31m' + 'cluster ' + str(i) + '\\x1b[0m' + \":\", [x.encode('utf-8') for x in top_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top K Words ($\\mu_{cluster}$) of Each Cluster\n",
    "compute the mean tf-idf vector of the cluster, return the top K words from this mean vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mcluster 2\u001b[0m: ['court', 'state', 'v', 'case', 'compani', 'plaintiff', 'defend', 'act', 'upon', 'law']\n",
      "\u001b[1;31mcluster 0\u001b[0m: ['state', 'tax', 'court', 'land', 'v', 'act', 'compani', 'upon', 'case', 'unit']\n",
      "\u001b[1;31mcluster 1\u001b[0m: ['court', 'state', 'v', 'sct', 'us', 'led2d', 'case', 'petition', '\\xc2\\xa7', 'unit']\n",
      "\u001b[1;31mcluster 3\u001b[0m: ['court', 'state', 'act', 'unit', 'case', 'v', 'upon', 'said', 'contract', 'offic']\n",
      "\u001b[1;31mcluster 15\u001b[0m: ['deed', 'court', 'properti', 'wife', 'convey', 'husband', 'estat', 'said', 'land', 'upon']\n",
      "Wall time: 4.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=10 # number of words to get\n",
    "\n",
    "for i in biggest_n_clusters:\n",
    "    top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[i], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "    print '\\x1b[1;31m' + 'cluster ' + str(i) + '\\x1b[0m' + \":\", [x.encode('utf-8') for x in top_words_from_mean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top K Words ($\\mu_{cluster} - \\mu_{complement}$ ) of Each Cluster\n",
    "compute the mean tf-idf vector of the cluster and also of the complement of the cluster,  \n",
    "take the difference mu_cluster - mu_complement, return the top K words in this difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mcluster 2\u001b[0m: ['plaintiff', 'bankruptci', 'court', 'suit', 'patent', 'jurisdict', 'compani', 'creditor', 'decre', 'defend']\n",
      "\u001b[1;31mcluster 0\u001b[0m: ['tax', 'land', 'state', 'compani', 'commiss', 'indian', 'railroad', 'rate', 'l', 'ct']\n",
      "\u001b[1;31mcluster 1\u001b[0m: ['led2d', 'sct', 'us', 'petition', 'v', 'convict', 'constitut', 'sentenc', 'state', 'crimin']\n",
      "\u001b[1;31mcluster 3\u001b[0m: ['indict', 'offic', 'collector', 'duti', 'unit', 'contract', 'navi', 'claimant', 'treasuri', 'act']\n",
      "\u001b[1;31mcluster 15\u001b[0m: ['deed', 'wife', 'convey', 'husband', 'estat', 'properti', 'titl', 'lot', 'said', 'complain']\n",
      "Wall time: 27.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=10 # number of words to get\n",
    "\n",
    "for i in biggest_n_clusters:\n",
    "    top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[i], all_the_opinions, \n",
    "                                                      k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "    print '\\x1b[1;31m' + 'cluster ' + str(i) + '\\x1b[0m' + \":\", [x.encode('utf-8') for x in top_words_from_diff]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Relevant Opinion of Each Cluster\n",
    "compute the mean tf-idf vector, return the document in the cluster closet to the mean  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mcluster 2\u001b[0m: opinion 89905\n",
      "\u001b[1;31mcluster 0\u001b[0m: opinion 95354\n",
      "\u001b[1;31mcluster 1\u001b[0m: opinion 104135\n",
      "\u001b[1;31mcluster 3\u001b[0m: opinion 86062\n",
      "\u001b[1;31mcluster 15\u001b[0m: opinion 87645\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in biggest_n_clusters:\n",
    "    most_relev_op = document_closest_to_mean(dict_top_n_clusters[i], tfidf_matrix, op_id_to_bow_id)\n",
    "    print '\\x1b[1;31m' + 'cluster ' + str(i) + '\\x1b[0m' + \": opinion \" + most_relev_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cluster_infos_csv(biggest_n_clusters, dict_top_n_clusters, clusters_dir, csv_dir_mod_info):\n",
    "    \n",
    "    for i in biggest_n_clusters:\n",
    "        \n",
    "        opinion_names = []\n",
    "        opinion_dates = []\n",
    "        opinion_links = []\n",
    "        \n",
    "        for j in dict_top_n_clusters[i]:\n",
    "            try:\n",
    "                with open(clusters_dir + j + \".json\") as data_file:\n",
    "                    data = json.load(data_file)\n",
    "            except IOError:\n",
    "                pass\n",
    "                #name, date, link = case_info2(i)\n",
    "                #opinion_names.append(name)\n",
    "                #opinion_dates.append(date)\n",
    "                #opinion_links.append(link)\n",
    "            \n",
    "            name = data['case_name'].encode('utf-8')\n",
    "            date = data['date_filed'].encode('utf-8')\n",
    "            link = 'https://www.courtlistener.com' + data['absolute_url'].encode('utf-8')\n",
    "\n",
    "            opinion_names.append(name)\n",
    "            opinion_dates.append(date)\n",
    "            opinion_links.append(link)\n",
    "\n",
    "        cluster_info = pd.DataFrame()\n",
    "        cluster_info['names'] = opinion_names\n",
    "        cluster_info['dates'] = opinion_dates\n",
    "        cluster_info['url'] = opinion_links\n",
    "\n",
    "        cluster_info.to_csv(csv_dir_mod_info + \"cluster_\"+str(i)+\".csv\")\n",
    "        print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n",
      "1\n",
      "3\n",
      "15\n",
      "7\n",
      "8\n",
      "4\n",
      "31\n",
      "17\n",
      "48\n",
      "36\n",
      "13\n",
      "40\n",
      "23\n",
      "51\n",
      "54\n",
      "16\n",
      "45\n",
      "42\n",
      "10\n",
      "28\n",
      "19\n",
      "47\n",
      "65\n",
      "6\n",
      "26\n",
      "43\n",
      "46\n",
      "79\n",
      "82\n",
      "94\n",
      "24\n",
      "49\n",
      "21\n",
      "29\n",
      "41\n",
      "44\n",
      "50\n",
      "55\n",
      "58\n",
      "64\n",
      "77\n",
      "96\n",
      "9\n",
      "12\n",
      "20\n",
      "56\n",
      "62\n",
      "80\n",
      "88\n",
      "89\n",
      "90\n",
      "95\n",
      "97\n",
      "98\n",
      "99\n",
      "104\n",
      "113\n",
      "117\n",
      "5\n",
      "14\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "38\n",
      "39\n",
      "52\n",
      "57\n",
      "61\n",
      "68\n",
      "71\n",
      "72\n",
      "75\n",
      "81\n",
      "83\n",
      "84\n",
      "92\n",
      "103\n",
      "105\n",
      "108\n",
      "109\n",
      "114\n",
      "115\n",
      "119\n",
      "121\n",
      "123\n",
      "124\n",
      "11\n",
      "18\n",
      "22\n",
      "25\n",
      "27\n",
      "30\n",
      "37\n",
      "53\n",
      "59\n",
      "60\n",
      "63\n",
      "66\n",
      "67\n",
      "69\n",
      "70\n",
      "73\n",
      "74\n",
      "76\n",
      "78\n",
      "85\n",
      "86\n",
      "87\n",
      "91\n",
      "93\n",
      "100\n",
      "101\n",
      "102\n",
      "106\n",
      "107\n",
      "110\n",
      "111\n",
      "112\n",
      "116\n",
      "118\n",
      "120\n",
      "122\n",
      "125\n",
      "Wall time: 5.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cluster_infos_csv(biggest_n_clusters, dict_top_n_clusters, clusters_dir, csv_dir_mod_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cluster_summaries_csv(k, biggest_n_clusters, dict_top_n_clusters, tfidf_matrix, op_id_to_bow_id, vocab, csv_dir_mod_summary):\n",
    "    for i in biggest_n_clusters:\n",
    "        top_words = top_k_words(dict_top_n_clusters[i], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "        top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[i], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "        top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[i], all_the_opinions, k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "        most_relev_op = document_closest_to_mean(dict_top_n_clusters[i], tfidf_matrix, op_id_to_bow_id)\n",
    "        \n",
    "        top_words = [x.encode('utf-8') for x in top_words]\n",
    "        top_words_from_mean = [x.encode('utf-8') for x in top_words_from_mean]\n",
    "        top_words_from_diff = [x.encode('utf-8') for x in top_words_from_diff]\n",
    "\n",
    "        len_old_top_words = len(top_words)\n",
    "        len_old_top_words_from_mean = len(top_words_from_mean)\n",
    "        len_old_top_words_from_diff = len(top_words_from_diff)\n",
    "\n",
    "        if len(top_words) != len(top_words_from_mean):\n",
    "            for j in range(0,len(top_words_from_mean)-len(top_words)):\n",
    "                top_words.append(np.nan)\n",
    "\n",
    "        cluster_summary = pd.DataFrame()\n",
    "        cluster_summary['top_words'] = top_words\n",
    "        cluster_summary['top_words_from_mean'] = top_words_from_mean\n",
    "        cluster_summary['top_words_from_diff'] = top_words_from_diff\n",
    "        cluster_summary['most_relev_op'] = most_relev_op\n",
    "\n",
    "        cluster_summary.to_csv(csv_dir_mod_summary + \"cluster_\"+str(i)+\"_summary.csv\")\n",
    "        print \"cluster\", i, \"is done\", \"(\", len(dict_top_n_clusters[i]), \"opinions )\", len_old_top_words, len_old_top_words_from_mean, len_old_top_words_from_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 2 is done ( 9273 opinions ) 1000 1000 1000\n",
      "cluster 0 is done ( 6870 opinions ) 1000 1000 1000\n",
      "cluster 1 is done ( 6234 opinions ) 1000 1000 1000\n",
      "cluster 3 is done ( 1458 opinions ) 1000 1000 1000\n",
      "cluster 15 is done ( 76 opinions ) 1000 1000 1000\n",
      "cluster 7 is done ( 75 opinions ) 1000 1000 1000\n",
      "cluster 8 is done ( 69 opinions ) 1000 1000 1000\n",
      "cluster 4 is done ( 52 opinions ) 1000 1000 1000\n",
      "cluster 31 is done ( 50 opinions ) 1000 1000 1000\n",
      "cluster 17 is done ( 36 opinions ) 1000 1000 1000\n",
      "cluster 48 is done ( 20 opinions ) 1000 1000 1000\n",
      "cluster 36 is done ( 18 opinions ) 1000 1000 1000\n",
      "cluster 13 is done ( 16 opinions ) 1000 1000 1000\n",
      "cluster 40 is done ( 16 opinions ) 1000 1000 1000\n",
      "cluster 23 is done ( 15 opinions ) 1000 1000 1000\n",
      "cluster 51 is done ( 15 opinions ) 1000 1000 1000\n",
      "cluster 54 is done ( 14 opinions ) 1000 1000 1000\n",
      "cluster 16 is done ( 13 opinions ) 1000 1000 1000\n",
      "cluster 45 is done ( 12 opinions ) 1000 1000 1000\n",
      "cluster 42 is done ( 11 opinions ) 1000 1000 1000\n",
      "cluster 10 is done ( 10 opinions ) 1000 1000 1000\n",
      "cluster 28 is done ( 10 opinions ) 1000 1000 1000\n",
      "cluster 19 is done ( 9 opinions ) 1000 1000 1000\n",
      "cluster 47 is done ( 8 opinions ) 1000 1000 1000\n",
      "cluster 65 is done ( 8 opinions ) 1000 1000 1000\n",
      "cluster 6 is done ( 7 opinions ) 1000 1000 1000\n",
      "cluster 26 is done ( 7 opinions ) 1000 1000 1000\n",
      "cluster 43 is done ( 7 opinions ) 1000 1000 1000\n",
      "cluster 46 is done ( 7 opinions ) 1000 1000 1000\n",
      "cluster 79 is done ( 7 opinions ) 1000 1000 1000\n",
      "cluster 82 is done ( 7 opinions ) 1000 1000 1000\n",
      "cluster 94 is done ( 7 opinions ) 988 1000 1000\n",
      "cluster 24 is done ( 6 opinions ) 1000 1000 1000\n",
      "cluster 49 is done ( 6 opinions ) 1000 1000 1000\n",
      "cluster 21 is done ( 5 opinions ) 1000 1000 1000\n",
      "cluster 29 is done ( 5 opinions ) 1000 1000 1000\n",
      "cluster 41 is done ( 5 opinions ) 1000 1000 1000\n",
      "cluster 44 is done ( 5 opinions ) 1000 1000 1000\n",
      "cluster 50 is done ( 5 opinions ) 1000 1000 1000\n",
      "cluster 55 is done ( 5 opinions ) 1000 1000 1000\n",
      "cluster 58 is done ( 5 opinions ) 883 1000 1000\n",
      "cluster 64 is done ( 5 opinions ) 1000 1000 1000\n",
      "cluster 77 is done ( 5 opinions ) 957 1000 1000\n",
      "cluster 96 is done ( 5 opinions ) 1000 1000 1000\n",
      "cluster 9 is done ( 4 opinions ) 1000 1000 1000\n",
      "cluster 12 is done ( 4 opinions ) 1000 1000 1000\n",
      "cluster 20 is done ( 4 opinions ) 417 1000 1000\n",
      "cluster 56 is done ( 4 opinions ) 626 1000 1000\n",
      "cluster 62 is done ( 4 opinions ) 516 1000 1000\n",
      "cluster 80 is done ( 4 opinions ) 590 1000 1000\n",
      "cluster 88 is done ( 4 opinions ) 905 1000 1000\n",
      "cluster 89 is done ( 4 opinions ) 1000 1000 1000\n",
      "cluster 90 is done ( 4 opinions ) 1000 1000 1000\n",
      "cluster 95 is done ( 4 opinions ) 758 1000 1000\n",
      "cluster 97 is done ( 4 opinions ) 1000 1000 1000\n",
      "cluster 98 is done ( 4 opinions ) 1000 1000 1000\n",
      "cluster 99 is done ( 4 opinions ) 1000 1000 1000\n",
      "cluster 104 is done ( 4 opinions ) 981 1000 1000\n",
      "cluster 113 is done ( 4 opinions ) 1000 1000 1000\n",
      "cluster 117 is done ( 4 opinions ) 776 1000 1000\n",
      "cluster 5 is done ( 3 opinions ) 700 1000 1000\n",
      "cluster 14 is done ( 3 opinions ) 905 1000 1000\n",
      "cluster 32 is done ( 3 opinions ) 401 1000 1000\n",
      "cluster 33 is done ( 3 opinions ) 1000 1000 1000\n",
      "cluster 34 is done ( 3 opinions ) 1000 1000 1000\n",
      "cluster 35 is done ( 3 opinions ) 880 1000 1000\n",
      "cluster 38 is done ( 3 opinions ) 735 1000 1000\n",
      "cluster 39 is done ( 3 opinions ) 567 1000 1000\n",
      "cluster 52 is done ( 3 opinions ) 873 1000 1000\n",
      "cluster 57 is done ( 3 opinions ) 1000 1000 1000\n",
      "cluster 61 is done ( 3 opinions ) 745 1000 1000\n",
      "cluster 68 is done ( 3 opinions ) 1000 1000 1000\n",
      "cluster 71 is done ( 3 opinions ) 1000 1000 1000\n",
      "cluster 72 is done ( 3 opinions ) 887 1000 1000\n",
      "cluster 75 is done ( 3 opinions ) 1000 1000 1000\n",
      "cluster 81 is done ( 3 opinions ) 1000 1000 1000\n",
      "cluster 83 is done ( 3 opinions ) 1000 1000 1000\n",
      "cluster 84 is done ( 3 opinions ) 883 1000 1000\n",
      "cluster 92 is done ( 3 opinions ) 1000 1000 1000\n",
      "cluster 103 is done ( 3 opinions ) 1000 1000 1000\n",
      "cluster 105 is done ( 3 opinions ) 1000 1000 1000\n",
      "cluster 108 is done ( 3 opinions ) 1000 1000 1000\n",
      "cluster 109 is done ( 3 opinions ) 719 1000 1000\n",
      "cluster 114 is done ( 3 opinions ) 780 1000 1000\n",
      "cluster 115 is done ( 3 opinions ) 744 1000 1000\n",
      "cluster 119 is done ( 3 opinions ) 656 1000 1000\n",
      "cluster 121 is done ( 3 opinions ) 1000 1000 1000\n",
      "cluster 123 is done ( 3 opinions ) 1000 1000 1000\n",
      "cluster 124 is done ( 3 opinions ) 731 1000 1000\n",
      "cluster 11 is done ( 2 opinions ) 409 1000 1000\n",
      "cluster 18 is done ( 2 opinions ) 875 1000 1000\n",
      "cluster 22 is done ( 2 opinions ) 1000 1000 1000\n",
      "cluster 25 is done ( 2 opinions ) 363 1000 1000\n",
      "cluster 27 is done ( 2 opinions ) 67 1000 1000\n",
      "cluster 30 is done ( 2 opinions ) 512 1000 1000\n",
      "cluster 37 is done ( 2 opinions ) 384 1000 1000\n",
      "cluster 53 is done ( 2 opinions ) 130 1000 1000\n",
      "cluster 59 is done ( 2 opinions ) 296 1000 1000\n",
      "cluster 60 is done ( 2 opinions ) 943 1000 1000\n",
      "cluster 63 is done ( 2 opinions ) 377 1000 1000\n",
      "cluster 66 is done ( 2 opinions ) 1000 1000 1000\n",
      "cluster 67 is done ( 2 opinions ) 370 1000 1000\n",
      "cluster 69 is done ( 2 opinions ) 733 1000 1000\n",
      "cluster 70 is done ( 2 opinions ) 176 1000 1000\n",
      "cluster 73 is done ( 2 opinions ) 74 1000 1000\n",
      "cluster 74 is done ( 2 opinions ) 1000 1000 1000\n",
      "cluster 76 is done ( 2 opinions ) 573 1000 1000\n",
      "cluster 78 is done ( 2 opinions ) 867 1000 1000\n",
      "cluster 85 is done ( 2 opinions ) 1000 1000 1000\n",
      "cluster 86 is done ( 2 opinions ) 723 1000 1000\n",
      "cluster 87 is done ( 2 opinions ) 813 1000 1000\n",
      "cluster 91 is done ( 2 opinions ) 405 1000 1000\n",
      "cluster 93 is done ( 2 opinions ) 172 1000 1000\n",
      "cluster 100 is done ( 2 opinions ) 1000 1000 1000\n",
      "cluster 101 is done ( 2 opinions ) 689 1000 1000\n",
      "cluster 102 is done ( 2 opinions ) 965 1000 1000\n",
      "cluster 106 is done ( 2 opinions ) 1000 1000 1000\n",
      "cluster 107 is done ( 2 opinions ) 82 1000 1000\n",
      "cluster 110 is done ( 2 opinions ) 135 1000 1000\n",
      "cluster 111 is done ( 2 opinions ) 253 1000 1000\n",
      "cluster 112 is done ( 2 opinions ) 1000 1000 1000\n",
      "cluster 116 is done ( 2 opinions ) 1000 1000 1000\n",
      "cluster 118 is done ( 2 opinions ) 245 1000 1000\n",
      "cluster 120 is done ( 2 opinions ) 736 1000 1000\n",
      "cluster 122 is done ( 2 opinions ) 964 1000 1000\n",
      "cluster 125 is done ( 2 opinions ) 383 1000 1000\n",
      "Wall time: 11min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cluster_summaries_csv(1000, biggest_n_clusters, dict_top_n_clusters, tfidf_matrix, op_id_to_bow_id, vocab, csv_dir_mod_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 2 Summary (9273 opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9273, 3)\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "opinion_names = []\n",
    "opinion_dates = []\n",
    "opinion_links = []\n",
    "\n",
    "for i in dict_top_n_clusters[2]:\n",
    "    try:\n",
    "        with open(clusters_dir + i + \".json\") as data_file:\n",
    "            data = json.load(data_file)\n",
    "    except IOError:\n",
    "        pass\n",
    "        #name, date, link = case_info2(i)\n",
    "        #opinion_names.append(name)\n",
    "        #opinion_dates.append(date)\n",
    "        #opinion_links.append(link)\n",
    "        \n",
    "    name = data['case_name'].encode('utf-8')\n",
    "    date = data['date_filed'].encode('utf-8')\n",
    "    link = 'https://www.courtlistener.com' + data['absolute_url'].encode('utf-8')\n",
    "    \n",
    "    opinion_names.append(name)\n",
    "    opinion_dates.append(date)\n",
    "    opinion_links.append(link)\n",
    "    \n",
    "cluster_info = pd.DataFrame()\n",
    "cluster_info['names'] = opinion_names\n",
    "cluster_info['dates'] = opinion_dates\n",
    "cluster_info['url'] = opinion_links\n",
    "\n",
    "cluster_info.to_csv(csv_dir_mod + \"cluster_2.csv\")\n",
    "\n",
    "print cluster_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>names</th>\n",
       "      <th>dates</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Dalton v. Jennings</td>\n",
       "      <td>1876-12-18</td>\n",
       "      <td>https://www.courtlistener.com/opinion/89374/da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Windsor v. McVeigh</td>\n",
       "      <td>1876-12-11</td>\n",
       "      <td>https://www.courtlistener.com/opinion/89375/wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Bigelow v. Berkshire Life Ins. Co.</td>\n",
       "      <td>1876-12-11</td>\n",
       "      <td>https://www.courtlistener.com/opinion/89376/bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Indianapolis &amp; St. Louis R. Co. v. Horst</td>\n",
       "      <td>1876-12-18</td>\n",
       "      <td>https://www.courtlistener.com/opinion/89378/in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The\" Atlas\"</td>\n",
       "      <td>1876-11-27</td>\n",
       "      <td>https://www.courtlistener.com/opinion/89379/th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                     names       dates  \\\n",
       "0           0                        Dalton v. Jennings  1876-12-18   \n",
       "1           1                        Windsor v. McVeigh  1876-12-11   \n",
       "2           2        Bigelow v. Berkshire Life Ins. Co.  1876-12-11   \n",
       "3           3  Indianapolis & St. Louis R. Co. v. Horst  1876-12-18   \n",
       "4           4                               The\" Atlas\"  1876-11-27   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.courtlistener.com/opinion/89374/da...  \n",
       "1  https://www.courtlistener.com/opinion/89375/wi...  \n",
       "2  https://www.courtlistener.com/opinion/89376/bi...  \n",
       "3  https://www.courtlistener.com/opinion/89378/in...  \n",
       "4  https://www.courtlistener.com/opinion/89379/th...  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_info = pd.read_csv(csv_dir_mod + 'cluster_2.csv')\n",
    "cluster_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=1000 # number of words to get\n",
    "\n",
    "top_words = top_k_words(dict_top_n_clusters[2], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[2], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[2], all_the_opinions, k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "most_relev_op = document_closest_to_mean(dict_top_n_clusters[2], tfidf_matrix, op_id_to_bow_id)\n",
    "\n",
    "top_words = [x.encode('utf-8') for x in top_words]\n",
    "top_words_from_mean = [x.encode('utf-8') for x in top_words_from_mean]\n",
    "top_words_from_diff = [x.encode('utf-8') for x in top_words_from_diff]\n",
    "\n",
    "#print '\\x1b[1;31m' + \"Top K Words:\" + '\\x1b[0m', top_words\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster):\" + '\\x1b[0m', top_words_from_mean\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster - Mu_Complement):\" + '\\x1b[0m', top_words_from_diff\n",
    "#print '\\x1b[1;31m' + \"Most Relevent Opinion:\" + '\\x1b[0m', most_relev_op\n",
    "\n",
    "cluster_summary = pd.DataFrame()\n",
    "cluster_summary['top_words'] = top_words\n",
    "cluster_summary['top_words_from_mean'] = top_words_from_mean\n",
    "cluster_summary['top_words_from_diff'] = top_words_from_diff\n",
    "cluster_summary['most_relev_op'] = most_relev_op\n",
    "\n",
    "cluster_summary.to_csv(csv_dir_mod + \"cluster_2_summary.csv\")\n",
    "\n",
    "print cluster_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>top_words</th>\n",
       "      <th>top_words_from_mean</th>\n",
       "      <th>top_words_from_diff</th>\n",
       "      <th>most_relev_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>squier</td>\n",
       "      <td>court</td>\n",
       "      <td>plaintiff</td>\n",
       "      <td>89905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>reinsur</td>\n",
       "      <td>state</td>\n",
       "      <td>bankruptci</td>\n",
       "      <td>89905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>scophoni</td>\n",
       "      <td>v</td>\n",
       "      <td>court</td>\n",
       "      <td>89905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>graeff</td>\n",
       "      <td>case</td>\n",
       "      <td>suit</td>\n",
       "      <td>89905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>arbitr</td>\n",
       "      <td>compani</td>\n",
       "      <td>patent</td>\n",
       "      <td>89905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 top_words top_words_from_mean top_words_from_diff  most_relev_op\n",
       "0           0    squier               court           plaintiff          89905\n",
       "1           1   reinsur               state          bankruptci          89905\n",
       "2           2  scophoni                   v               court          89905\n",
       "3           3    graeff                case                suit          89905\n",
       "4           4    arbitr             compani              patent          89905"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_summary = pd.read_csv(csv_dir_mod + 'cluster_2_summary.csv')\n",
    "cluster_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 0 Summary (6870 opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6870, 3)\n",
      "Wall time: 1.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "opinion_names = []\n",
    "opinion_dates = []\n",
    "opinion_links = []\n",
    "\n",
    "for i in dict_top_n_clusters[0]:\n",
    "    try:\n",
    "        with open(clusters_dir + i + \".json\") as data_file:\n",
    "            data = json.load(data_file)\n",
    "    except IOError:\n",
    "        pass\n",
    "        #name, date, link = case_info2(i)\n",
    "        #opinion_names.append(name)\n",
    "        #opinion_dates.append(date)\n",
    "        #opinion_links.append(link)\n",
    "        \n",
    "    name = data['case_name'].encode('utf-8')\n",
    "    date = data['date_filed'].encode('utf-8')\n",
    "    link = 'https://www.courtlistener.com' + data['absolute_url'].encode('utf-8')\n",
    "    \n",
    "    opinion_names.append(name)\n",
    "    opinion_dates.append(date)\n",
    "    opinion_links.append(link)\n",
    "    \n",
    "cluster_info = pd.DataFrame()\n",
    "cluster_info['names'] = opinion_names\n",
    "cluster_info['dates'] = opinion_dates\n",
    "cluster_info['url'] = opinion_links\n",
    "\n",
    "cluster_info.to_csv(csv_dir_mod + \"cluster_0.csv\")\n",
    "\n",
    "print cluster_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>names</th>\n",
       "      <th>dates</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>New Jersey v. Anderson</td>\n",
       "      <td>1906-12-10</td>\n",
       "      <td>https://www.courtlistener.com/opinion/96546/ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Barkley v. Levee Commissioners</td>\n",
       "      <td>1876-12-18</td>\n",
       "      <td>https://www.courtlistener.com/opinion/89372/ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Broughton v. Pensacola</td>\n",
       "      <td>1876-12-18</td>\n",
       "      <td>https://www.courtlistener.com/opinion/89373/br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Western Union Telegraph Co. v. Pennsylvania</td>\n",
       "      <td>1961-12-04</td>\n",
       "      <td>https://www.courtlistener.com/opinion/106303/w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Reitz v. Mealey</td>\n",
       "      <td>1941-11-10</td>\n",
       "      <td>https://www.courtlistener.com/opinion/103548/r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        names       dates  \\\n",
       "0           0                       New Jersey v. Anderson  1906-12-10   \n",
       "1           1               Barkley v. Levee Commissioners  1876-12-18   \n",
       "2           2                       Broughton v. Pensacola  1876-12-18   \n",
       "3           3  Western Union Telegraph Co. v. Pennsylvania  1961-12-04   \n",
       "4           4                              Reitz v. Mealey  1941-11-10   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.courtlistener.com/opinion/96546/ne...  \n",
       "1  https://www.courtlistener.com/opinion/89372/ba...  \n",
       "2  https://www.courtlistener.com/opinion/89373/br...  \n",
       "3  https://www.courtlistener.com/opinion/106303/w...  \n",
       "4  https://www.courtlistener.com/opinion/103548/r...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_info = pd.read_csv(csv_dir_mod + 'cluster_0.csv')\n",
    "cluster_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=1000 # number of words to get\n",
    "\n",
    "top_words = top_k_words(dict_top_n_clusters[0], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[0], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[0], all_the_opinions, k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "most_relev_op = document_closest_to_mean(dict_top_n_clusters[0], tfidf_matrix, op_id_to_bow_id)\n",
    "\n",
    "top_words = [x.encode('utf-8') for x in top_words]\n",
    "top_words_from_mean = [x.encode('utf-8') for x in top_words_from_mean]\n",
    "top_words_from_diff = [x.encode('utf-8') for x in top_words_from_diff]\n",
    "\n",
    "#print '\\x1b[1;31m' + \"Top K Words:\" + '\\x1b[0m', top_words\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster):\" + '\\x1b[0m', top_words_from_mean\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster - Mu_Complement):\" + '\\x1b[0m', top_words_from_diff\n",
    "#print '\\x1b[1;31m' + \"Most Relevent Opinion:\" + '\\x1b[0m', most_relev_op\n",
    "\n",
    "cluster_summary = pd.DataFrame()\n",
    "cluster_summary['top_words'] = top_words\n",
    "cluster_summary['top_words_from_mean'] = top_words_from_mean\n",
    "cluster_summary['top_words_from_diff'] = top_words_from_diff\n",
    "cluster_summary['most_relev_op'] = most_relev_op\n",
    "\n",
    "cluster_summary.to_csv(csv_dir_mod + \"cluster_0_summary.csv\")\n",
    "\n",
    "print cluster_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>top_words</th>\n",
       "      <th>top_words_from_mean</th>\n",
       "      <th>top_words_from_diff</th>\n",
       "      <th>most_relev_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dispensari</td>\n",
       "      <td>state</td>\n",
       "      <td>tax</td>\n",
       "      <td>95354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>pension</td>\n",
       "      <td>tax</td>\n",
       "      <td>land</td>\n",
       "      <td>95354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fslic</td>\n",
       "      <td>court</td>\n",
       "      <td>state</td>\n",
       "      <td>95354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>wass</td>\n",
       "      <td>land</td>\n",
       "      <td>compani</td>\n",
       "      <td>95354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>bicknel</td>\n",
       "      <td>v</td>\n",
       "      <td>commiss</td>\n",
       "      <td>95354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   top_words top_words_from_mean top_words_from_diff  \\\n",
       "0           0  dispensari               state                 tax   \n",
       "1           1     pension                 tax                land   \n",
       "2           2       fslic               court               state   \n",
       "3           3        wass                land             compani   \n",
       "4           4     bicknel                   v             commiss   \n",
       "\n",
       "   most_relev_op  \n",
       "0          95354  \n",
       "1          95354  \n",
       "2          95354  \n",
       "3          95354  \n",
       "4          95354  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_summary = pd.read_csv(csv_dir_mod + 'cluster_0_summary.csv')\n",
    "cluster_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 1 Summary (6234 opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6234, 3)\n",
      "Wall time: 3.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "opinion_names = []\n",
    "opinion_dates = []\n",
    "opinion_links = []\n",
    "\n",
    "for i in dict_top_n_clusters[1]:\n",
    "    try:\n",
    "        with open(clusters_dir + i + \".json\") as data_file:\n",
    "            data = json.load(data_file)\n",
    "    except IOError:\n",
    "        pass\n",
    "        #name, date, link = case_info2(i)\n",
    "        #opinion_names.append(name)\n",
    "        #opinion_dates.append(date)\n",
    "        #opinion_links.append(link)\n",
    "        \n",
    "    name = data['case_name'].encode('utf-8')\n",
    "    date = data['date_filed'].encode('utf-8')\n",
    "    link = 'https://www.courtlistener.com' + data['absolute_url'].encode('utf-8')\n",
    "    \n",
    "    opinion_names.append(name)\n",
    "    opinion_dates.append(date)\n",
    "    opinion_links.append(link)\n",
    "    \n",
    "cluster_info = pd.DataFrame()\n",
    "cluster_info['names'] = opinion_names\n",
    "cluster_info['dates'] = opinion_dates\n",
    "cluster_info['url'] = opinion_links\n",
    "\n",
    "cluster_info.to_csv(csv_dir_mod + \"cluster_1.csv\")\n",
    "\n",
    "print cluster_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>names</th>\n",
       "      <th>dates</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CBS v. Federal Communications Commission</td>\n",
       "      <td>1981-07-01</td>\n",
       "      <td>https://www.courtlistener.com/opinion/110557/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hamilton v. Alabama</td>\n",
       "      <td>1961-11-13</td>\n",
       "      <td>https://www.courtlistener.com/opinion/106300/h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>United States v. Sing Tuck</td>\n",
       "      <td>1904-04-25</td>\n",
       "      <td>https://www.courtlistener.com/opinion/96076/un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Hoyt v. Florida</td>\n",
       "      <td>1961-11-20</td>\n",
       "      <td>https://www.courtlistener.com/opinion/106302/h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>California Medical Assn. v. Federal Election C...</td>\n",
       "      <td>1981-06-26</td>\n",
       "      <td>https://www.courtlistener.com/opinion/110551/c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              names       dates  \\\n",
       "0           0           CBS v. Federal Communications Commission  1981-07-01   \n",
       "1           1                                Hamilton v. Alabama  1961-11-13   \n",
       "2           2                         United States v. Sing Tuck  1904-04-25   \n",
       "3           3                                    Hoyt v. Florida  1961-11-20   \n",
       "4           4  California Medical Assn. v. Federal Election C...  1981-06-26   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.courtlistener.com/opinion/110557/c...  \n",
       "1  https://www.courtlistener.com/opinion/106300/h...  \n",
       "2  https://www.courtlistener.com/opinion/96076/un...  \n",
       "3  https://www.courtlistener.com/opinion/106302/h...  \n",
       "4  https://www.courtlistener.com/opinion/110551/c...  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_info = pd.read_csv(csv_dir_mod + 'cluster_1.csv')\n",
    "cluster_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=1000 # number of words to get\n",
    "\n",
    "top_words = top_k_words(dict_top_n_clusters[1], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[1], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[1], all_the_opinions, k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "most_relev_op = document_closest_to_mean(dict_top_n_clusters[1], tfidf_matrix, op_id_to_bow_id)\n",
    "\n",
    "top_words = [x.encode('utf-8') for x in top_words]\n",
    "top_words_from_mean = [x.encode('utf-8') for x in top_words_from_mean]\n",
    "top_words_from_diff = [x.encode('utf-8') for x in top_words_from_diff]\n",
    "\n",
    "#print '\\x1b[1;31m' + \"Top K Words:\" + '\\x1b[0m', top_words\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster):\" + '\\x1b[0m', top_words_from_mean\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster - Mu_Complement):\" + '\\x1b[0m', top_words_from_diff\n",
    "#print '\\x1b[1;31m' + \"Most Relevent Opinion:\" + '\\x1b[0m', most_relev_op\n",
    "\n",
    "cluster_summary = pd.DataFrame()\n",
    "cluster_summary['top_words'] = top_words\n",
    "cluster_summary['top_words_from_mean'] = top_words_from_mean\n",
    "cluster_summary['top_words_from_diff'] = top_words_from_diff\n",
    "cluster_summary['most_relev_op'] = most_relev_op\n",
    "\n",
    "cluster_summary.to_csv(csv_dir_mod + \"cluster_1_summary.csv\")\n",
    "\n",
    "print cluster_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>top_words</th>\n",
       "      <th>top_words_from_mean</th>\n",
       "      <th>top_words_from_diff</th>\n",
       "      <th>most_relev_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>baal</td>\n",
       "      <td>court</td>\n",
       "      <td>led2d</td>\n",
       "      <td>104135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>stumpf</td>\n",
       "      <td>state</td>\n",
       "      <td>sct</td>\n",
       "      <td>104135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>lagrand</td>\n",
       "      <td>v</td>\n",
       "      <td>us</td>\n",
       "      <td>104135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ree</td>\n",
       "      <td>sct</td>\n",
       "      <td>petition</td>\n",
       "      <td>104135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>lesag</td>\n",
       "      <td>us</td>\n",
       "      <td>v</td>\n",
       "      <td>104135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 top_words top_words_from_mean top_words_from_diff  most_relev_op\n",
       "0           0      baal               court               led2d         104135\n",
       "1           1    stumpf               state                 sct         104135\n",
       "2           2   lagrand                   v                  us         104135\n",
       "3           3       ree                 sct            petition         104135\n",
       "4           4     lesag                  us                   v         104135"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_summary = pd.read_csv(csv_dir_mod + 'cluster_1_summary.csv')\n",
    "cluster_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 3 Summary (1458 opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1458, 3)\n",
      "Wall time: 814 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "opinion_names = []\n",
    "opinion_dates = []\n",
    "opinion_links = []\n",
    "\n",
    "for i in dict_top_n_clusters[3]:\n",
    "    try:\n",
    "        with open(clusters_dir + i + \".json\") as data_file:\n",
    "            data = json.load(data_file)\n",
    "    except IOError:\n",
    "        pass\n",
    "        #name, date, link = case_info2(i)\n",
    "        #opinion_names.append(name)\n",
    "        #opinion_dates.append(date)\n",
    "        #opinion_links.append(link)\n",
    "        \n",
    "    name = data['case_name'].encode('utf-8')\n",
    "    date = data['date_filed'].encode('utf-8')\n",
    "    link = 'https://www.courtlistener.com' + data['absolute_url'].encode('utf-8')\n",
    "    \n",
    "    opinion_names.append(name)\n",
    "    opinion_dates.append(date)\n",
    "    opinion_links.append(link)\n",
    "    \n",
    "cluster_info = pd.DataFrame()\n",
    "cluster_info['names'] = opinion_names\n",
    "cluster_info['dates'] = opinion_dates\n",
    "cluster_info['url'] = opinion_links\n",
    "\n",
    "cluster_info.to_csv(csv_dir_mod + \"cluster_3.csv\")\n",
    "\n",
    "print cluster_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>names</th>\n",
       "      <th>dates</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>United States Ex Rel. French v. Weeks</td>\n",
       "      <td>1922-05-29</td>\n",
       "      <td>https://www.courtlistener.com/opinion/100016/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>United States Ex Rel. Creary v. Weeks</td>\n",
       "      <td>1922-06-05</td>\n",
       "      <td>https://www.courtlistener.com/opinion/100017/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Ex Parte Harley-Davidson Motor Co.</td>\n",
       "      <td>1922-06-05</td>\n",
       "      <td>https://www.courtlistener.com/opinion/100019/e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Cutler v. Kouns</td>\n",
       "      <td>1884-03-10</td>\n",
       "      <td>https://www.courtlistener.com/opinion/91071/cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Amado v. United States</td>\n",
       "      <td>1904-11-07</td>\n",
       "      <td>https://www.courtlistener.com/opinion/96135/am...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                  names       dates  \\\n",
       "0           0  United States Ex Rel. French v. Weeks  1922-05-29   \n",
       "1           1  United States Ex Rel. Creary v. Weeks  1922-06-05   \n",
       "2           2     Ex Parte Harley-Davidson Motor Co.  1922-06-05   \n",
       "3           3                        Cutler v. Kouns  1884-03-10   \n",
       "4           4                 Amado v. United States  1904-11-07   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.courtlistener.com/opinion/100016/u...  \n",
       "1  https://www.courtlistener.com/opinion/100017/u...  \n",
       "2  https://www.courtlistener.com/opinion/100019/e...  \n",
       "3  https://www.courtlistener.com/opinion/91071/cu...  \n",
       "4  https://www.courtlistener.com/opinion/96135/am...  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_info = pd.read_csv(csv_dir_mod + 'cluster_3.csv')\n",
    "cluster_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "Wall time: 15.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=1000 # number of words to get\n",
    "\n",
    "top_words = top_k_words(dict_top_n_clusters[3], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[3], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[3], all_the_opinions, k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "most_relev_op = document_closest_to_mean(dict_top_n_clusters[3], tfidf_matrix, op_id_to_bow_id)\n",
    "\n",
    "top_words = [x.encode('utf-8') for x in top_words]\n",
    "top_words_from_mean = [x.encode('utf-8') for x in top_words_from_mean]\n",
    "top_words_from_diff = [x.encode('utf-8') for x in top_words_from_diff]\n",
    "\n",
    "#print '\\x1b[1;31m' + \"Top K Words:\" + '\\x1b[0m', top_words\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster):\" + '\\x1b[0m', top_words_from_mean\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster - Mu_Complement):\" + '\\x1b[0m', top_words_from_diff\n",
    "#print '\\x1b[1;31m' + \"Most Relevent Opinion:\" + '\\x1b[0m', most_relev_op\n",
    "\n",
    "cluster_summary = pd.DataFrame()\n",
    "cluster_summary['top_words'] = top_words\n",
    "cluster_summary['top_words_from_mean'] = top_words_from_mean\n",
    "cluster_summary['top_words_from_diff'] = top_words_from_diff\n",
    "cluster_summary['most_relev_op'] = most_relev_op\n",
    "\n",
    "cluster_summary.to_csv(csv_dir_mod + \"cluster_3_summary.csv\")\n",
    "\n",
    "print cluster_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>top_words</th>\n",
       "      <th>top_words_from_mean</th>\n",
       "      <th>top_words_from_diff</th>\n",
       "      <th>most_relev_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>shaeffer</td>\n",
       "      <td>court</td>\n",
       "      <td>indict</td>\n",
       "      <td>86062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>wool</td>\n",
       "      <td>state</td>\n",
       "      <td>offic</td>\n",
       "      <td>86062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>carusi</td>\n",
       "      <td>act</td>\n",
       "      <td>collector</td>\n",
       "      <td>86062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>toy</td>\n",
       "      <td>unit</td>\n",
       "      <td>duti</td>\n",
       "      <td>86062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>seed</td>\n",
       "      <td>case</td>\n",
       "      <td>unit</td>\n",
       "      <td>86062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 top_words top_words_from_mean top_words_from_diff  most_relev_op\n",
       "0           0  shaeffer               court              indict          86062\n",
       "1           1      wool               state               offic          86062\n",
       "2           2    carusi                 act           collector          86062\n",
       "3           3       toy                unit                duti          86062\n",
       "4           4      seed                case                unit          86062"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_summary = pd.read_csv(csv_dir_mod + 'cluster_3_summary.csv')\n",
    "cluster_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 15 Summary (76 opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76, 3)\n",
      "Wall time: 31 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "opinion_names = []\n",
    "opinion_dates = []\n",
    "opinion_links = []\n",
    "\n",
    "for i in dict_top_n_clusters[15]:\n",
    "    try:\n",
    "        with open(clusters_dir + i + \".json\") as data_file:\n",
    "            data = json.load(data_file)\n",
    "    except IOError:\n",
    "        pass\n",
    "        #name, date, link = case_info2(i)\n",
    "        #opinion_names.append(name)\n",
    "        #opinion_dates.append(date)\n",
    "        #opinion_links.append(link)\n",
    "        \n",
    "    name = data['case_name'].encode('utf-8')\n",
    "    date = data['date_filed'].encode('utf-8')\n",
    "    link = 'https://www.courtlistener.com' + data['absolute_url'].encode('utf-8')\n",
    "    \n",
    "    opinion_names.append(name)\n",
    "    opinion_dates.append(date)\n",
    "    opinion_links.append(link)\n",
    "    \n",
    "cluster_info = pd.DataFrame()\n",
    "cluster_info['names'] = opinion_names\n",
    "cluster_info['dates'] = opinion_dates\n",
    "cluster_info['url'] = opinion_links\n",
    "\n",
    "cluster_info.to_csv(csv_dir_mod + \"cluster_15.csv\")\n",
    "\n",
    "print cluster_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>names</th>\n",
       "      <th>dates</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Watt v. Starke</td>\n",
       "      <td>1880-01-18</td>\n",
       "      <td>https://www.courtlistener.com/opinion/90120/wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Armstrong v. Morrill</td>\n",
       "      <td>1872-01-22</td>\n",
       "      <td>https://www.courtlistener.com/opinion/88525/ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Brandies v. Cochrane</td>\n",
       "      <td>1884-12-01</td>\n",
       "      <td>https://www.courtlistener.com/opinion/91214/br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Union R. Co. v. Dull</td>\n",
       "      <td>1888-01-16</td>\n",
       "      <td>https://www.courtlistener.com/opinion/92109/un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Cooper v. Dasher</td>\n",
       "      <td>1933-11-06</td>\n",
       "      <td>https://www.courtlistener.com/opinion/102138/c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 names       dates  \\\n",
       "0           0        Watt v. Starke  1880-01-18   \n",
       "1           1  Armstrong v. Morrill  1872-01-22   \n",
       "2           2  Brandies v. Cochrane  1884-12-01   \n",
       "3           3  Union R. Co. v. Dull  1888-01-16   \n",
       "4           4      Cooper v. Dasher  1933-11-06   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.courtlistener.com/opinion/90120/wa...  \n",
       "1  https://www.courtlistener.com/opinion/88525/ar...  \n",
       "2  https://www.courtlistener.com/opinion/91214/br...  \n",
       "3  https://www.courtlistener.com/opinion/92109/un...  \n",
       "4  https://www.courtlistener.com/opinion/102138/c...  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_info = pd.read_csv(csv_dir_mod + 'cluster_15.csv')\n",
    "cluster_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "Wall time: 4.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=1000 # number of words to get\n",
    "\n",
    "top_words = top_k_words(dict_top_n_clusters[15], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[15], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[15], all_the_opinions, k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "most_relev_op = document_closest_to_mean(dict_top_n_clusters[15], tfidf_matrix, op_id_to_bow_id)\n",
    "\n",
    "top_words = [x.encode('utf-8') for x in top_words]\n",
    "top_words_from_mean = [x.encode('utf-8') for x in top_words_from_mean]\n",
    "top_words_from_diff = [x.encode('utf-8') for x in top_words_from_diff]\n",
    "\n",
    "#print '\\x1b[1;31m' + \"Top K Words:\" + '\\x1b[0m', top_words\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster):\" + '\\x1b[0m', top_words_from_mean\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster - Mu_Complement):\" + '\\x1b[0m', top_words_from_diff\n",
    "#print '\\x1b[1;31m' + \"Most Relevent Opinion:\" + '\\x1b[0m', most_relev_op\n",
    "\n",
    "cluster_summary = pd.DataFrame()\n",
    "cluster_summary['top_words'] = top_words\n",
    "cluster_summary['top_words_from_mean'] = top_words_from_mean\n",
    "cluster_summary['top_words_from_diff'] = top_words_from_diff\n",
    "cluster_summary['most_relev_op'] = most_relev_op\n",
    "\n",
    "cluster_summary.to_csv(csv_dir_mod + \"cluster_15_summary.csv\")\n",
    "\n",
    "print cluster_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>top_words</th>\n",
       "      <th>top_words_from_mean</th>\n",
       "      <th>top_words_from_diff</th>\n",
       "      <th>most_relev_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>flaglor</td>\n",
       "      <td>deed</td>\n",
       "      <td>deed</td>\n",
       "      <td>87645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dippold</td>\n",
       "      <td>court</td>\n",
       "      <td>wife</td>\n",
       "      <td>87645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>nailor</td>\n",
       "      <td>properti</td>\n",
       "      <td>convey</td>\n",
       "      <td>87645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>goff</td>\n",
       "      <td>wife</td>\n",
       "      <td>husband</td>\n",
       "      <td>87645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>turpin</td>\n",
       "      <td>convey</td>\n",
       "      <td>estat</td>\n",
       "      <td>87645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 top_words top_words_from_mean top_words_from_diff  most_relev_op\n",
       "0           0   flaglor                deed                deed          87645\n",
       "1           1   dippold               court                wife          87645\n",
       "2           2    nailor            properti              convey          87645\n",
       "3           3      goff                wife             husband          87645\n",
       "4           4    turpin              convey               estat          87645"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_summary = pd.read_csv(csv_dir_mod + 'cluster_15_summary.csv')\n",
    "cluster_summary.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
