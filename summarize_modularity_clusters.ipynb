{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize Modularity Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# modify these for your own computer\n",
    "repo_directory = '/Users/Michael/Documents/GitHub/law-net/'\n",
    "\n",
    "data_dir = '/Users/Michael/Desktop/network_data/'\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cPickle as pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "# graph package\n",
    "import igraph as ig\n",
    "\n",
    "\n",
    "# stat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import scipy.sparse\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "\n",
    "# our code\n",
    "sys.path.append(repo_directory + 'code/')\n",
    "from summarize_clusters import *\n",
    "\n",
    "sys.path.append(repo_directory + 'vertex_metrics_experiment/code/')\n",
    "from bag_of_words import * \n",
    "\n",
    "# which network to download data for\n",
    "network_name = 'scotus' # 'federal', 'ca1', etc\n",
    "\n",
    "\n",
    "# some sub directories that get used\n",
    "raw_dir = data_dir + 'raw/'\n",
    "subnet_dir = data_dir + network_name + '/'\n",
    "text_dir = subnet_dir + 'textfiles/'\n",
    "nlp_dir = subnet_dir + 'nlp/'\n",
    "nlp_sub_dir = nlp_dir + 'bow_tfidf/' #tfidf matrix (and other info, i.e. vocab) computed from bag-of-words matrix\n",
    "nlp_bow_dir = nlp_dir + 'bow/' #bag-of-words matrix (and other info, i.e. vocab)\n",
    "\n",
    "# all the file paths for .txt files\n",
    "file_paths = glob.glob(text_dir + '*.txt')\n",
    "\n",
    "# all opinions\n",
    "all_the_opinions = all_opinions(file_paths)\n",
    "\n",
    "\n",
    "# jupyter notebook settings\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load tf-idf vectors\n",
    "**tfidf_matrix** = (row_index, column_index): tf_idf value (**CSR FORMAT**)  \n",
    "**op_id_to_bow_id** = opinion_id (corresponds to row indices)  \n",
    "**vocab** = all the words in tfidf_matrix (correspond to column indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_matrix, op_id_to_bow_id, vocab = load_tf_idf(nlp_sub_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Work:\n",
    "focus on largest connected component of **undirected scotus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the graph\n",
    "G = ig.Graph.Read_GraphML(subnet_dir + network_name +'_network.graphml')\n",
    "\n",
    "# limit ourselves to cases upto and including 2015 since we are missing some textfiles from 2016\n",
    "G = G.subgraph(G.vs.select(year_le=2015))\n",
    "\n",
    "# make graph undirected\n",
    "Gud = G.copy()\n",
    "Gud = Gud.as_undirected()\n",
    "\n",
    "# get largest connected componenet\n",
    "components = Gud.clusters(mode='STRONG')\n",
    "g = components.subgraphs()[np.argmax(components.sizes())]\n",
    "\n",
    "# CL ids of cases in largest connected component\n",
    "CLids = g.vs['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modularity on undirected scotus\n",
    "\"For a given division of the network's vertices into some modules, modularity reflects the concentration of edges within modules compared with random distribution of links between all nodes regardless of modules\"--*Wikipedia*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering with 24724 elements and 126 clusters\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# modularity clustering\n",
    "cd_modularity = g.community_fastgreedy() # .as_clustering().membership\n",
    "\n",
    "mod_clust = cd_modularity.as_clustering()\n",
    "\n",
    "print mod_clust.summary()\n",
    "\n",
    "# save clusters in pandas\n",
    "graph_clusters = pd.Series(mod_clust.membership, index=g.vs['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the top 5 biggest clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 2 : 9273 opinions\n",
      "cluster 0 : 6870 opinions\n",
      "cluster 1 : 6234 opinions\n",
      "cluster 3 : 1458 opinions\n",
      "cluster 15 : 76 opinions\n"
     ]
    }
   ],
   "source": [
    "dict_top_n_clusters, biggest_n_clusters = get_top_n_clusters(5, len(mod_clust), graph_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top K Words of Each Cluster\n",
    "This function summarizes a set of opinions by returning the words that appear in these opinions with the highest tf-idf scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mcluster 2\u001b[0m: ['squier', 'reinsur', 'scophoni', 'reinsur', 'graeff', 'arbitr', 'arbitr', 'sugg', 'passport', 'arbitr']\n",
      "\u001b[1;31mcluster 0\u001b[0m: ['dispensari', 'pension', 'fslic', 'wass', 'bicknel', 'milk', 'jumel', 'boom', 'merriam', 'ch']\n",
      "\u001b[1;31mcluster 1\u001b[0m: ['baal', 'stumpf', 'lagrand', 'ree', 'lesag', 'bail', 'kaupp', 'ashcraft', 'penri', 'mazzei']\n",
      "\u001b[1;31mcluster 3\u001b[0m: ['shaeffer', 'wool', 'carusi', 'toy', 'seed', 'jen', 'paper', 'renfrow', 'pearl', 'cork']\n",
      "\u001b[1;31mcluster 15\u001b[0m: ['flaglor', 'dippold', 'nailor', 'goff', 'turpin', 'reeder', 'bilsland', 'shappirio', 'randel', 'forsyth']\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=10 # number of words to get\n",
    "\n",
    "for i in biggest_n_clusters:\n",
    "    top_words = top_k_words(dict_top_n_clusters[i], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "    print '\\x1b[1;31m' + 'cluster ' + str(i) + '\\x1b[0m' + \":\", [x.encode('utf-8') for x in top_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top K Words ($\\mu_{cluster}$) of Each Cluster\n",
    "compute the mean tf-idf vector of the cluster, return the top K words from this mean vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mcluster 2\u001b[0m: ['court', 'state', 'v', 'case', 'compani', 'plaintiff', 'defend', 'act', 'upon', 'law']\n",
      "\u001b[1;31mcluster 0\u001b[0m: ['state', 'tax', 'court', 'land', 'v', 'act', 'compani', 'upon', 'case', 'unit']\n",
      "\u001b[1;31mcluster 1\u001b[0m: ['court', 'state', 'v', 'sct', 'us', 'led2d', 'case', 'petition', '\\xc2\\xa7', 'unit']\n",
      "\u001b[1;31mcluster 3\u001b[0m: ['court', 'state', 'act', 'unit', 'case', 'v', 'upon', 'said', 'contract', 'offic']\n",
      "\u001b[1;31mcluster 15\u001b[0m: ['deed', 'court', 'properti', 'wife', 'convey', 'husband', 'estat', 'said', 'land', 'upon']\n",
      "Wall time: 4.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=10 # number of words to get\n",
    "\n",
    "for i in biggest_n_clusters:\n",
    "    top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[i], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "    print '\\x1b[1;31m' + 'cluster ' + str(i) + '\\x1b[0m' + \":\", [x.encode('utf-8') for x in top_words_from_mean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top K Words ($\\mu_{cluster} - \\mu_{complement}$ ) of Each Cluster\n",
    "compute the mean tf-idf vector of the cluster and also of the complement of the cluster,  \n",
    "take the difference mu_cluster - mu_complement, return the top K words in this difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mcluster 2\u001b[0m: ['plaintiff', 'bankruptci', 'court', 'suit', 'patent', 'jurisdict', 'compani', 'creditor', 'decre', 'defend']\n",
      "\u001b[1;31mcluster 0\u001b[0m: ['tax', 'land', 'state', 'compani', 'commiss', 'indian', 'railroad', 'rate', 'l', 'ct']\n",
      "\u001b[1;31mcluster 1\u001b[0m: ['led2d', 'sct', 'us', 'petition', 'v', 'convict', 'constitut', 'sentenc', 'state', 'crimin']\n",
      "\u001b[1;31mcluster 3\u001b[0m: ['indict', 'offic', 'collector', 'duti', 'unit', 'contract', 'navi', 'claimant', 'treasuri', 'act']\n",
      "\u001b[1;31mcluster 15\u001b[0m: ['deed', 'wife', 'convey', 'husband', 'estat', 'properti', 'titl', 'lot', 'said', 'complain']\n",
      "Wall time: 26.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=10 # number of words to get\n",
    "\n",
    "for i in biggest_n_clusters:\n",
    "    top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[i], all_the_opinions, \n",
    "                                                      k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "    print '\\x1b[1;31m' + 'cluster ' + str(i) + '\\x1b[0m' + \":\", [x.encode('utf-8') for x in top_words_from_diff]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Relevant Opinion of Each Cluster\n",
    "compute the mean tf-idf vector, return the document in the cluster closet to the mean  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mcluster 2\u001b[0m: opinion 89905\n",
      "\u001b[1;31mcluster 0\u001b[0m: opinion 95354\n",
      "\u001b[1;31mcluster 1\u001b[0m: opinion 104135\n",
      "\u001b[1;31mcluster 3\u001b[0m: opinion 86062\n",
      "\u001b[1;31mcluster 15\u001b[0m: opinion 87645\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in biggest_n_clusters:\n",
    "    most_relev_op = document_closest_to_mean(dict_top_n_clusters[i], tfidf_matrix, op_id_to_bow_id)\n",
    "    print '\\x1b[1;31m' + 'cluster ' + str(i) + '\\x1b[0m' + \": opinion \" + most_relev_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 2 Summary (9273 opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mTop K Words:\u001b[0m ['squier', 'reinsur', 'scophoni', 'reinsur', 'graeff', 'arbitr', 'arbitr', 'sugg', 'passport', 'arbitr']\n",
      "\u001b[1;31mTop K Words (Mu_Cluster):\u001b[0m ['court', 'state', 'v', 'case', 'compani', 'plaintiff', 'defend', 'act', 'upon', 'law']\n",
      "\u001b[1;31mTop K Words (Mu_Cluster - Mu_Complement):\u001b[0m ['plaintiff', 'bankruptci', 'court', 'suit', 'patent', 'jurisdict', 'compani', 'creditor', 'decre', 'defend']\n",
      "\u001b[1;31mMost Relevent Opinion:\u001b[0m 89905\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=10 # number of words to get\n",
    "\n",
    "top_words = top_k_words(dict_top_n_clusters[2], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[2], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[2], all_the_opinions, k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "most_relev_op = document_closest_to_mean(dict_top_n_clusters[2], tfidf_matrix, op_id_to_bow_id)\n",
    "\n",
    "\n",
    "print '\\x1b[1;31m' + \"Top K Words:\" + '\\x1b[0m', [x.encode('utf-8') for x in top_words]\n",
    "print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster):\" + '\\x1b[0m', [x.encode('utf-8') for x in top_words_from_mean]\n",
    "print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster - Mu_Complement):\" + '\\x1b[0m', [x.encode('utf-8') for x in top_words_from_diff]\n",
    "print '\\x1b[1;31m' + \"Most Relevent Opinion:\" + '\\x1b[0m', most_relev_op\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 0 Summary (6870 opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mTop K Words:\u001b[0m ['dispensari', 'pension', 'fslic', 'wass', 'bicknel', 'milk', 'jumel', 'boom', 'merriam', 'ch']\n",
      "\u001b[1;31mTop K Words (Mu_Cluster):\u001b[0m ['state', 'tax', 'court', 'land', 'v', 'act', 'compani', 'upon', 'case', 'unit']\n",
      "\u001b[1;31mTop K Words (Mu_Cluster - Mu_Complement):\u001b[0m ['tax', 'land', 'state', 'compani', 'commiss', 'indian', 'railroad', 'rate', 'l', 'ct']\n",
      "\u001b[1;31mMost Relevent Opinion:\u001b[0m 95354\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=10 # number of words to get\n",
    "\n",
    "top_words = top_k_words(dict_top_n_clusters[0], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[0], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[0], all_the_opinions, k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "most_relev_op = document_closest_to_mean(dict_top_n_clusters[0], tfidf_matrix, op_id_to_bow_id)\n",
    "\n",
    "\n",
    "print '\\x1b[1;31m' + \"Top K Words:\" + '\\x1b[0m', [x.encode('utf-8') for x in top_words]\n",
    "print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster):\" + '\\x1b[0m', [x.encode('utf-8') for x in top_words_from_mean]\n",
    "print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster - Mu_Complement):\" + '\\x1b[0m', [x.encode('utf-8') for x in top_words_from_diff]\n",
    "print '\\x1b[1;31m' + \"Most Relevent Opinion:\" + '\\x1b[0m', most_relev_op\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 1 Summary (6234 opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mTop K Words:\u001b[0m ['baal', 'stumpf', 'lagrand', 'ree', 'lesag', 'bail', 'kaupp', 'ashcraft', 'penri', 'mazzei']\n",
      "\u001b[1;31mTop K Words (Mu_Cluster):\u001b[0m ['court', 'state', 'v', 'sct', 'us', 'led2d', 'case', 'petition', '\\xc2\\xa7', 'unit']\n",
      "\u001b[1;31mTop K Words (Mu_Cluster - Mu_Complement):\u001b[0m ['led2d', 'sct', 'us', 'petition', 'v', 'convict', 'constitut', 'sentenc', 'state', 'crimin']\n",
      "\u001b[1;31mMost Relevent Opinion:\u001b[0m 104135\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=10 # number of words to get\n",
    "\n",
    "top_words = top_k_words(dict_top_n_clusters[1], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[1], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[1], all_the_opinions, k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "most_relev_op = document_closest_to_mean(dict_top_n_clusters[1], tfidf_matrix, op_id_to_bow_id)\n",
    "\n",
    "\n",
    "print '\\x1b[1;31m' + \"Top K Words:\" + '\\x1b[0m', [x.encode('utf-8') for x in top_words]\n",
    "print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster):\" + '\\x1b[0m', [x.encode('utf-8') for x in top_words_from_mean]\n",
    "print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster - Mu_Complement):\" + '\\x1b[0m', [x.encode('utf-8') for x in top_words_from_diff]\n",
    "print '\\x1b[1;31m' + \"Most Relevent Opinion:\" + '\\x1b[0m', most_relev_op\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 3 Summary (1458 opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mTop K Words:\u001b[0m ['shaeffer', 'wool', 'carusi', 'toy', 'seed', 'jen', 'paper', 'renfrow', 'pearl', 'cork']\n",
      "\u001b[1;31mTop K Words (Mu_Cluster):\u001b[0m ['court', 'state', 'act', 'unit', 'case', 'v', 'upon', 'said', 'contract', 'offic']\n",
      "\u001b[1;31mTop K Words (Mu_Cluster - Mu_Complement):\u001b[0m ['indict', 'offic', 'collector', 'duti', 'unit', 'contract', 'navi', 'claimant', 'treasuri', 'act']\n",
      "\u001b[1;31mMost Relevent Opinion:\u001b[0m 86062\n",
      "Wall time: 14.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=10 # number of words to get\n",
    "\n",
    "top_words = top_k_words(dict_top_n_clusters[3], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[3], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[3], all_the_opinions, k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "most_relev_op = document_closest_to_mean(dict_top_n_clusters[3], tfidf_matrix, op_id_to_bow_id)\n",
    "\n",
    "\n",
    "print '\\x1b[1;31m' + \"Top K Words:\" + '\\x1b[0m', [x.encode('utf-8') for x in top_words]\n",
    "print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster):\" + '\\x1b[0m', [x.encode('utf-8') for x in top_words_from_mean]\n",
    "print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster - Mu_Complement):\" + '\\x1b[0m', [x.encode('utf-8') for x in top_words_from_diff]\n",
    "print '\\x1b[1;31m' + \"Most Relevent Opinion:\" + '\\x1b[0m', most_relev_op\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 15 Summary (76 opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mTop K Words:\u001b[0m ['flaglor', 'dippold', 'nailor', 'goff', 'turpin', 'reeder', 'bilsland', 'shappirio', 'randel', 'forsyth']\n",
      "\u001b[1;31mTop K Words (Mu_Cluster):\u001b[0m ['deed', 'court', 'properti', 'wife', 'convey', 'husband', 'estat', 'said', 'land', 'upon']\n",
      "\u001b[1;31mTop K Words (Mu_Cluster - Mu_Complement):\u001b[0m ['deed', 'wife', 'convey', 'husband', 'estat', 'properti', 'titl', 'lot', 'said', 'complain']\n",
      "\u001b[1;31mMost Relevent Opinion:\u001b[0m 87645\n",
      "Wall time: 4.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=10 # number of words to get\n",
    "\n",
    "top_words = top_k_words(dict_top_n_clusters[15], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[15], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[15], all_the_opinions, k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "most_relev_op = document_closest_to_mean(dict_top_n_clusters[15], tfidf_matrix, op_id_to_bow_id)\n",
    "\n",
    "\n",
    "print '\\x1b[1;31m' + \"Top K Words:\" + '\\x1b[0m', [x.encode('utf-8') for x in top_words]\n",
    "print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster):\" + '\\x1b[0m', [x.encode('utf-8') for x in top_words_from_mean]\n",
    "print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster - Mu_Complement):\" + '\\x1b[0m', [x.encode('utf-8') for x in top_words_from_diff]\n",
    "print '\\x1b[1;31m' + \"Most Relevent Opinion:\" + '\\x1b[0m', most_relev_op\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
