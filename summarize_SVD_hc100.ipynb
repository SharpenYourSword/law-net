{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize HC (K=100) Cluster for SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# modify these for your own computer\n",
    "repo_directory = '/Users/Michael/Documents/GitHub/law-net/'\n",
    "\n",
    "data_dir = '/Users/Michael/Desktop/network_data/'\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cPickle  as pickle\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "\n",
    "\n",
    "# graph package\n",
    "import igraph as ig\n",
    "\n",
    "\n",
    "# stat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
    "from sklearn.metrics import adjusted_mutual_info_score as ami\n",
    "from sklearn.metrics import mutual_info_score as mi\n",
    "from sklearn.metrics import adjusted_rand_score as ar\n",
    "from sklearn.metrics import calinski_harabaz_score as ch # (X, labels)\n",
    "from sklearn.metrics import completeness_score as cs # metric isn't symmetric (labels_true, labels_predicted)\n",
    "from sklearn.metrics import fowlkes_mallows_score as fm\n",
    "from sklearn.metrics import homogeneity_completeness_v_measure as hcvm\n",
    "from sklearn.metrics import homogeneity_score as hs # metric isn't symmetric (labels_true, labels_predicted)\n",
    "from sklearn.metrics import silhouette_score as ss # (X, labels)\n",
    "from sklearn.metrics import silhouette_samples as ss2 # (X, labels)\n",
    "from sklearn.metrics import v_measure_score as vm\n",
    "\n",
    "import scipy.sparse\n",
    "import random\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "# our code\n",
    "sys.path.append(repo_directory + 'code/')\n",
    "from summarize_clusters import *\n",
    "from helpful_functions import *\n",
    "\n",
    "sys.path.append(repo_directory + 'vertex_metrics_experiment/code/')\n",
    "from bag_of_words import * \n",
    "\n",
    "# which network to download data for\n",
    "network_name = 'scotus' # 'federal', 'ca1', etc\n",
    "\n",
    "\n",
    "# some sub directories that get used\n",
    "raw_dir = data_dir + 'raw/'\n",
    "subnet_dir = data_dir + network_name + '/'\n",
    "text_dir = subnet_dir + 'textfiles/'\n",
    "nlp_dir = subnet_dir + 'nlp/'\n",
    "nlp_sub_dir = nlp_dir + 'bow_tfidf/' #tfidf matrix (and other info, i.e. vocab) computed from bag-of-words matrix\n",
    "nlp_bow_dir = nlp_dir + 'bow/' #bag-of-words matrix (and other info, i.e. vocab)\n",
    "nlp_df_sub_dir = nlp_dir + 'bow_tfidf_df/'\n",
    "\n",
    "# csv location\n",
    "csv_dir = \"C:/Users/Michael/Documents/GitHub/law-net/csv/\"\n",
    "csv_dir_SVD_hc100 = \"C:/Users/Michael/Documents/GitHub/law-net/csv/summarize_SVD_hc100/\"\n",
    "csv_dir_SVD_hc100_info = \"C:/Users/Michael/Documents/GitHub/law-net/csv/summarize_SVD_hc100/info/\"\n",
    "csv_dir_SVD_hc100_summary = \"C:/Users/Michael/Documents/GitHub/law-net/csv/summarize_SVD_hc100/summary/\"\n",
    "\n",
    "# all the file paths for .txt files\n",
    "file_paths = glob.glob(text_dir + '*.txt')\n",
    "\n",
    "# all opinions\n",
    "all_the_opinions = all_opinions(file_paths)\n",
    "\n",
    "# clusters directory\n",
    "clusters_dir = \"C:/Users/Michael/Desktop/network_data/raw/scotus/clusters/\"\n",
    "\n",
    "# jupyter notebook settings\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load tf-idf vectors\n",
    "**tfidf_matrix** = (row_index, column_index): tf_idf value (**CSR FORMAT**)  \n",
    "**op_id_to_bow_id** = opinion_id (corresponds to row indices)  \n",
    "**vocab** = all the words in tfidf_matrix (correspond to column indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_matrix, op_id_to_bow_id, vocab = load_tf_idf(nlp_sub_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<27885x567570 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 20817470 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>km_10</th>\n",
       "      <th>km_100</th>\n",
       "      <th>km_1000</th>\n",
       "      <th>gmm_10</th>\n",
       "      <th>gmm_100</th>\n",
       "      <th>gmm_1000</th>\n",
       "      <th>hc_10</th>\n",
       "      <th>hc_100</th>\n",
       "      <th>hc_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145658</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>224</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>392</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89370</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>569</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89371</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>886</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>711</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89372</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>443</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89373</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>213</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  km_10  km_100  km_1000  gmm_10  gmm_100  gmm_1000  hc_10  \\\n",
       "0      145658      0       1      224       3       54       392      1   \n",
       "1       89370      0      68      569       3       95       830      1   \n",
       "2       89371      9      85      886       8       47       711      2   \n",
       "3       89372      0      70      242       3       40       443      1   \n",
       "4       89373      0      22      897       0       64       213      1   \n",
       "\n",
       "   hc_100  hc_1000  \n",
       "0      50      157  \n",
       "1      50      157  \n",
       "2      94      697  \n",
       "3      37      193  \n",
       "4      65       84  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = pd.read_csv(csv_dir + 'clusters_SVD.csv')\n",
    "clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145658    50\n",
       "89370     50\n",
       "89371     94\n",
       "89372     37\n",
       "89373     65\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_tfidf_clusters = clusters['hc_100'].tolist()\n",
    "\n",
    "nlp_clusters = pd.Series(nlp_tfidf_clusters, index=op_id_to_bow_id)\n",
    "nlp_clusters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the top 5 biggest clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 37 : 2142 opinions\n",
      "cluster 20 : 795 opinions\n",
      "cluster 17 : 730 opinions\n",
      "cluster 49 : 658 opinions\n",
      "cluster 74 : 613 opinions\n",
      "cluster 64 : 592 opinions\n",
      "cluster 19 : 582 opinions\n",
      "cluster 13 : 573 opinions\n",
      "cluster 34 : 517 opinions\n",
      "cluster 0 : 516 opinions\n",
      "cluster 3 : 500 opinions\n",
      "cluster 4 : 487 opinions\n",
      "cluster 28 : 482 opinions\n",
      "cluster 35 : 454 opinions\n",
      "cluster 46 : 454 opinions\n",
      "cluster 70 : 433 opinions\n",
      "cluster 8 : 432 opinions\n",
      "cluster 91 : 421 opinions\n",
      "cluster 26 : 403 opinions\n",
      "cluster 29 : 402 opinions\n",
      "cluster 42 : 385 opinions\n",
      "cluster 7 : 381 opinions\n",
      "cluster 61 : 378 opinions\n",
      "cluster 67 : 372 opinions\n",
      "cluster 5 : 371 opinions\n",
      "cluster 65 : 355 opinions\n",
      "cluster 30 : 353 opinions\n",
      "cluster 36 : 334 opinions\n",
      "cluster 43 : 319 opinions\n",
      "cluster 11 : 318 opinions\n",
      "cluster 32 : 318 opinions\n",
      "cluster 44 : 313 opinions\n",
      "cluster 76 : 312 opinions\n",
      "cluster 40 : 304 opinions\n",
      "cluster 60 : 295 opinions\n",
      "cluster 98 : 290 opinions\n",
      "cluster 51 : 288 opinions\n",
      "cluster 18 : 287 opinions\n",
      "cluster 22 : 285 opinions\n",
      "cluster 12 : 281 opinions\n",
      "cluster 41 : 281 opinions\n",
      "cluster 31 : 277 opinions\n",
      "cluster 9 : 275 opinions\n",
      "cluster 1 : 274 opinions\n",
      "cluster 14 : 265 opinions\n",
      "cluster 10 : 254 opinions\n",
      "cluster 33 : 254 opinions\n",
      "cluster 6 : 245 opinions\n",
      "cluster 16 : 243 opinions\n",
      "cluster 56 : 240 opinions\n",
      "cluster 48 : 237 opinions\n",
      "cluster 15 : 235 opinions\n",
      "cluster 38 : 235 opinions\n",
      "cluster 25 : 224 opinions\n",
      "cluster 53 : 206 opinions\n",
      "cluster 50 : 187 opinions\n",
      "cluster 79 : 187 opinions\n",
      "cluster 59 : 185 opinions\n",
      "cluster 24 : 184 opinions\n",
      "cluster 23 : 175 opinions\n",
      "cluster 94 : 173 opinions\n",
      "cluster 2 : 169 opinions\n",
      "cluster 90 : 168 opinions\n",
      "cluster 92 : 168 opinions\n",
      "cluster 85 : 166 opinions\n",
      "cluster 66 : 163 opinions\n",
      "cluster 77 : 160 opinions\n",
      "cluster 45 : 157 opinions\n",
      "cluster 52 : 157 opinions\n",
      "cluster 89 : 151 opinions\n",
      "cluster 72 : 147 opinions\n",
      "cluster 58 : 144 opinions\n",
      "cluster 63 : 135 opinions\n",
      "cluster 54 : 130 opinions\n",
      "cluster 75 : 130 opinions\n",
      "cluster 71 : 127 opinions\n",
      "cluster 83 : 126 opinions\n",
      "cluster 80 : 121 opinions\n",
      "cluster 27 : 119 opinions\n",
      "cluster 39 : 119 opinions\n",
      "cluster 21 : 117 opinions\n",
      "cluster 55 : 115 opinions\n",
      "cluster 88 : 113 opinions\n",
      "cluster 68 : 112 opinions\n",
      "cluster 47 : 100 opinions\n",
      "cluster 78 : 98 opinions\n",
      "cluster 97 : 98 opinions\n",
      "cluster 62 : 91 opinions\n",
      "cluster 86 : 88 opinions\n",
      "cluster 57 : 83 opinions\n",
      "cluster 73 : 83 opinions\n",
      "cluster 87 : 78 opinions\n",
      "cluster 95 : 70 opinions\n",
      "cluster 69 : 63 opinions\n",
      "cluster 84 : 51 opinions\n",
      "cluster 93 : 50 opinions\n",
      "cluster 82 : 49 opinions\n",
      "cluster 81 : 43 opinions\n",
      "cluster 99 : 33 opinions\n",
      "cluster 96 : 32 opinions\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "dict_top_n_clusters = dictionary of top K clusters \n",
    "                      (key=cluster #, value=opinions in cluster)\n",
    "                      \n",
    "biggest_n_clusters = list of top K clusters (int)\n",
    "'''\n",
    "\n",
    "dict_top_n_clusters, biggest_n_clusters = get_top_n_clusters(100, 100, nlp_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top K Words of Each Cluster\n",
    "This function summarizes a set of opinions by returning the words that appear in these opinions with the highest tf-idf scores.\n",
    "\n",
    "# Top K Words ($\\mu_{cluster}$) of Each Cluster\n",
    "compute the mean tf-idf vector of the cluster, return the top K words from this mean vector\n",
    "\n",
    "# Top K Words ($\\mu_{cluster} - \\mu_{complement}$ ) of Each Cluster\n",
    "compute the mean tf-idf vector of the cluster and also of the complement of the cluster,  \n",
    "take the difference mu_cluster - mu_complement, return the top K words in this difference\n",
    "\n",
    "# Most Relevant Opinion of Each Cluster\n",
    "compute the mean tf-idf vector, return the document in the cluster closet to the mean  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_infos_csv(biggest_n_clusters, dict_top_n_clusters, clusters_dir, csv_dir_info):\n",
    "    \n",
    "    for i in biggest_n_clusters:\n",
    "        \n",
    "        opinion_names = []\n",
    "        opinion_dates = []\n",
    "        opinion_links = []\n",
    "        \n",
    "        for j in dict_top_n_clusters[i]:\n",
    "            try:\n",
    "                with open(clusters_dir + j + \".json\") as data_file:\n",
    "                    data = json.load(data_file)\n",
    "            except IOError:\n",
    "                pass\n",
    "                #name, date, link = case_info2(i)\n",
    "                #opinion_names.append(name)\n",
    "                #opinion_dates.append(date)\n",
    "                #opinion_links.append(link)\n",
    "            \n",
    "            name = data['case_name'].encode('utf-8')\n",
    "            date = data['date_filed'].encode('utf-8')\n",
    "            link = 'https://www.courtlistener.com' + data['absolute_url'].encode('utf-8')\n",
    "\n",
    "            opinion_names.append(name)\n",
    "            opinion_dates.append(date)\n",
    "            opinion_links.append(link)\n",
    "\n",
    "        cluster_info = pd.DataFrame()\n",
    "        cluster_info['names'] = opinion_names\n",
    "        cluster_info['dates'] = opinion_dates\n",
    "        cluster_info['url'] = opinion_links\n",
    "\n",
    "        cluster_info.to_csv(csv_dir_info + \"cluster_\"+str(i)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cluster_infos_csv(biggest_n_clusters, dict_top_n_clusters, clusters_dir, csv_dir_SVD_hc100_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_summaries_csv(k, biggest_n_clusters, dict_top_n_clusters, tfidf_matrix, op_id_to_bow_id, vocab, csv_dir_summary):\n",
    "    for i in biggest_n_clusters:\n",
    "        top_words = top_k_words(dict_top_n_clusters[i], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "        top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[i], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "        top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[i], all_the_opinions, k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "        most_relev_op = document_closest_to_mean(dict_top_n_clusters[i], tfidf_matrix, op_id_to_bow_id)\n",
    "        \n",
    "        top_words = [x.encode('utf-8') for x in top_words]\n",
    "        top_words_from_mean = [x.encode('utf-8') for x in top_words_from_mean]\n",
    "        top_words_from_diff = [x.encode('utf-8') for x in top_words_from_diff]\n",
    "\n",
    "        len_old_top_words = len(top_words)\n",
    "        len_old_top_words_from_mean = len(top_words_from_mean)\n",
    "        len_old_top_words_from_diff = len(top_words_from_diff)\n",
    "\n",
    "        if len(top_words) != len(top_words_from_mean):\n",
    "            for j in range(0,len(top_words_from_mean)-len(top_words)):\n",
    "                top_words.append(np.nan)\n",
    "\n",
    "        cluster_summary = pd.DataFrame()\n",
    "        cluster_summary['top_words'] = top_words\n",
    "        cluster_summary['top_words_from_mean'] = top_words_from_mean\n",
    "        cluster_summary['top_words_from_diff'] = top_words_from_diff\n",
    "        cluster_summary['most_relev_op'] = most_relev_op\n",
    "\n",
    "        cluster_summary.to_csv(csv_dir_summary + \"cluster_\"+str(i)+\"_summary.csv\")\n",
    "        print \"cluster\", i, \"is done\", \"(\", len(dict_top_n_clusters[i]), \"opinions )\", len_old_top_words, len_old_top_words_from_mean, len_old_top_words_from_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 37 is done ( 2142 opinions ) 1000 1000 1000\n",
      "cluster 20 is done ( 795 opinions ) 1000 1000 1000\n",
      "cluster 17 is done ( 730 opinions ) 1000 1000 1000\n",
      "cluster 49 is done ( 658 opinions ) 1000 1000 1000\n",
      "cluster 74 is done ( 613 opinions ) 1000 1000 1000\n",
      "cluster 64 is done ( 592 opinions ) 1000 1000 1000\n",
      "cluster 19 is done ( 582 opinions ) 1000 1000 1000\n",
      "cluster 13 is done ( 573 opinions ) 1000 1000 1000\n",
      "cluster 34 is done ( 517 opinions ) 1000 1000 1000\n",
      "cluster 0 is done ( 516 opinions ) 1000 1000 1000\n",
      "cluster 3 is done ( 500 opinions ) 1000 1000 1000\n",
      "cluster 4 is done ( 487 opinions ) 1000 1000 1000\n",
      "cluster 28 is done ( 482 opinions ) 1000 1000 1000\n",
      "cluster 35 is done ( 454 opinions ) 1000 1000 1000\n",
      "cluster 46 is done ( 454 opinions ) 1000 1000 1000\n",
      "cluster 70 is done ( 433 opinions ) 1000 1000 1000\n",
      "cluster 8 is done ( 432 opinions ) 1000 1000 1000\n",
      "cluster 91 is done ( 421 opinions ) 1000 1000 1000\n",
      "cluster 26 is done ( 403 opinions ) 1000 1000 1000\n",
      "cluster 29 is done ( 402 opinions ) 1000 1000 1000\n",
      "cluster 42 is done ( 385 opinions ) 1000 1000 1000\n",
      "cluster 7 is done ( 381 opinions ) 1000 1000 1000\n",
      "cluster 61 is done ( 378 opinions ) 1000 1000 1000\n",
      "cluster 67 is done ( 372 opinions ) 1000 1000 1000\n",
      "cluster 5 is done ( 371 opinions ) 1000 1000 1000\n",
      "cluster 65 is done ( 355 opinions ) 1000 1000 1000\n",
      "cluster 30 is done ( 353 opinions ) 1000 1000 1000\n",
      "cluster 36 is done ( 334 opinions ) 1000 1000 1000\n",
      "cluster 43 is done ( 319 opinions ) 1000 1000 1000\n",
      "cluster 11 is done ( 318 opinions ) 1000 1000 1000\n",
      "cluster 32 is done ( 318 opinions ) 1000 1000 1000\n",
      "cluster 44 is done ( 313 opinions ) 1000 1000 1000\n",
      "cluster 76 is done ( 312 opinions ) 1000 1000 1000\n",
      "cluster 40 is done ( 304 opinions ) 1000 1000 1000\n",
      "cluster 60 is done ( 295 opinions ) 1000 1000 1000\n",
      "cluster 98 is done ( 290 opinions ) 1000 1000 1000\n",
      "cluster 51 is done ( 288 opinions ) 1000 1000 1000\n",
      "cluster 18 is done ( 287 opinions ) 1000 1000 1000\n",
      "cluster 22 is done ( 285 opinions ) 1000 1000 1000\n",
      "cluster 12 is done ( 281 opinions ) 1000 1000 1000\n",
      "cluster 41 is done ( 281 opinions ) 1000 1000 1000\n",
      "cluster 31 is done ( 277 opinions ) 1000 1000 1000\n",
      "cluster 9 is done ( 275 opinions ) 1000 1000 1000\n",
      "cluster 1 is done ( 274 opinions ) 1000 1000 1000\n",
      "cluster 14 is done ( 265 opinions ) 1000 1000 1000\n",
      "cluster 10 is done ( 254 opinions ) 1000 1000 1000\n",
      "cluster 33 is done ( 254 opinions ) 1000 1000 1000\n",
      "cluster 6 is done ( 245 opinions ) 1000 1000 1000\n",
      "cluster 16 is done ( 243 opinions ) 1000 1000 1000\n",
      "cluster 56 is done ( 240 opinions ) 1000 1000 1000\n",
      "cluster 48 is done ( 237 opinions ) 1000 1000 1000\n",
      "cluster 15 is done ( 235 opinions ) 1000 1000 1000\n",
      "cluster 38 is done ( 235 opinions ) 1000 1000 1000\n",
      "cluster 25 is done ( 224 opinions ) 1000 1000 1000\n",
      "cluster 53 is done ( 206 opinions ) 1000 1000 1000\n",
      "cluster 50 is done ( 187 opinions ) 1000 1000 1000\n",
      "cluster 79 is done ( 187 opinions ) 1000 1000 1000\n",
      "cluster 59 is done ( 185 opinions ) 1000 1000 1000\n",
      "cluster 24 is done ( 184 opinions ) 1000 1000 1000\n",
      "cluster 23 is done ( 175 opinions ) 1000 1000 1000\n",
      "cluster 94 is done ( 173 opinions ) 1000 1000 1000\n",
      "cluster 2 is done ( 169 opinions ) 1000 1000 1000\n",
      "cluster 90 is done ( 168 opinions ) 1000 1000 1000\n",
      "cluster 92 is done ( 168 opinions ) 1000 1000 1000\n",
      "cluster 85 is done ( 166 opinions ) 1000 1000 1000\n",
      "cluster 66 is done ( 163 opinions ) 1000 1000 1000\n",
      "cluster 77 is done ( 160 opinions ) 1000 1000 1000\n",
      "cluster 45 is done ( 157 opinions ) 1000 1000 1000\n",
      "cluster 52 is done ( 157 opinions ) 1000 1000 1000\n",
      "cluster 89 is done ( 151 opinions ) 1000 1000 1000\n",
      "cluster 72 is done ( 147 opinions ) 1000 1000 1000\n",
      "cluster 58 is done ( 144 opinions ) 1000 1000 1000\n",
      "cluster 63 is done ( 135 opinions ) 1000 1000 1000\n",
      "cluster 54 is done ( 130 opinions ) 1000 1000 1000\n",
      "cluster 75 is done ( 130 opinions ) 1000 1000 1000\n",
      "cluster 71 is done ( 127 opinions ) 1000 1000 1000\n",
      "cluster 83 is done ( 126 opinions ) 1000 1000 1000\n",
      "cluster 80 is done ( 121 opinions ) 1000 1000 1000\n",
      "cluster 27 is done ( 119 opinions ) 1000 1000 1000\n",
      "cluster 39 is done ( 119 opinions ) 1000 1000 1000\n",
      "cluster 21 is done ( 117 opinions ) 1000 1000 1000\n",
      "cluster 55 is done ( 115 opinions ) 1000 1000 1000\n",
      "cluster 88 is done ( 113 opinions ) 1000 1000 1000\n",
      "cluster 68 is done ( 112 opinions ) 1000 1000 1000\n",
      "cluster 47 is done ( 100 opinions ) 1000 1000 1000\n",
      "cluster 78 is done ( 98 opinions ) 1000 1000 1000\n",
      "cluster 97 is done ( 98 opinions ) 1000 1000 1000\n",
      "cluster 62 is done ( 91 opinions ) 1000 1000 1000\n",
      "cluster 86 is done ( 88 opinions ) 1000 1000 1000\n",
      "cluster 57 is done ( 83 opinions ) 1000 1000 1000\n",
      "cluster 73 is done ( 83 opinions ) 1000 1000 1000\n",
      "cluster 87 is done ( 78 opinions ) 1000 1000 1000\n",
      "cluster 95 is done ( 70 opinions ) 1000 1000 1000\n",
      "cluster 69 is done ( 63 opinions ) 1000 1000 1000\n",
      "cluster 84 is done ( 51 opinions ) 1000 1000 1000\n",
      "cluster 93 is done ( 50 opinions ) 1000 1000 1000\n",
      "cluster 82 is done ( 49 opinions ) 1000 1000 1000\n",
      "cluster 81 is done ( 43 opinions ) 1000 1000 1000\n",
      "cluster 99 is done ( 33 opinions ) 1000 1000 1000\n",
      "cluster 96 is done ( 32 opinions ) 1000 1000 1000\n",
      "Wall time: 12min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cluster_summaries_csv(1000, biggest_n_clusters, dict_top_n_clusters, tfidf_matrix, op_id_to_bow_id, vocab, csv_dir_SVD_hc100_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
