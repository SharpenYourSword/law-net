{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# modify these for your own computer\n",
    "#repo_directory = '/Users/iaincarmichael/Dropbox/Research/law/law-net/'\n",
    "repo_directory = '/Users/Michael/Documents/GitHub/law-net/'\n",
    "\n",
    "#data_dir = '/Users/iaincarmichael/Documents/courtlistener/data/'\n",
    "data_dir = '/Users/Michael/Desktop/network_data/'\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# graph package\n",
    "import igraph as ig\n",
    "\n",
    "\n",
    "# stat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import mixture\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# our code\n",
    "sys.path.append(repo_directory + 'code/')\n",
    "\n",
    "\n",
    "sys.path.append(repo_directory + 'vertex_metrics_experiment/code/')\n",
    "#from bag_of_words import load_tf_idf\n",
    "from bag_of_words import * \n",
    "\n",
    "# which network to download data for\n",
    "network_name = 'scotus' # 'federal', 'ca1', etc\n",
    "\n",
    "\n",
    "# some sub directories that get used\n",
    "raw_dir = data_dir + 'raw/'\n",
    "subnet_dir = data_dir + network_name + '/'\n",
    "text_dir = subnet_dir + 'textfiles/'\n",
    "nlp_dir = subnet_dir + 'nlp/'\n",
    "nlp_bow_dir = nlp_dir + 'bow/' #bag-of-words matrix (and other info, i.e. vocab)\n",
    "nlp_sub_dir = nlp_dir + 'bow_tfidf/' #tfidf matrix (and other info, i.e. vocab) computed from bag-of-words matrix\n",
    "\n",
    "#nlp_df_bow_dir = nlp_dir + 'bow_df/'\n",
    "nlp_df_sub_dir = nlp_dir + 'bow_tfidf_df/'\n",
    "\n",
    "# all the file paths for .txt files\n",
    "file_paths = glob.glob(text_dir + '*.txt')\n",
    "\n",
    "\n",
    "# jupyter notebook settings\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import cPickle as pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from text_normalization import *\n",
    "from pipeline_helper_functions import save_sparse_csr, load_sparse_csr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute bag of words matrix (bow matrix)\n",
    "min_df (0.3) and max_df (0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27885\n",
      "Wall time: 1h 6min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## compute bag_of_words matrix (copied from bag_of_words.py)\n",
    "\n",
    "#tf_iter = textfile_iter(file_paths)\n",
    "text_data = []\n",
    "for fle in file_paths:\n",
    "    text_data.append(open(fle, \"r\").read())\n",
    "        \n",
    "print len(text_data)\n",
    "        \n",
    "\n",
    "\n",
    "# stemmer and stop words\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = stopwords.words(\"english\")\n",
    "min_df = 0.3  # be careful about integer/float, see sklean documentation\n",
    "max_df = 0.7\n",
    "\n",
    "# stem stop words\n",
    "stop_words = [stemmer.stem(w) for w in stop_words]\n",
    "\n",
    "bag_of_words = CountVectorizer(min_df=min_df,\n",
    "                               max_df=max_df,\n",
    "                               tokenizer=StemTokenizer(stemmer),\n",
    "                               stop_words=stop_words)\n",
    "\n",
    "#bow_matrix = bag_of_words.fit_transform(file_paths)\n",
    "bow_matrix = bag_of_words.fit_transform(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<27885x488 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 6029712 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transform the bow matrix to tf-idf matrix using 'TfidfTransformer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 280 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compute tfidf matrix from bag of words\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "tfidf_matrix = tfidf.fit_transform(bow_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<27885x488 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 6029712 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# store tfidf matrix information (vocab, matrix, row indices) in new directory: 'nlp_df_sub_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(nlp_df_sub_dir):\n",
    "    os.mkdir(nlp_df_sub_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# is it ok to save the 'vocab' from 'bag_of_words.get_feature_names()'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vocabulary\n",
    "vocab = bag_of_words.get_feature_names()\n",
    "\n",
    "# map from CL opinion ids to bow matix index\n",
    "op_id_to_bow_id = {re.search(r'(\\d+)\\.txt', file_paths[i]).group(1): i for\n",
    "                   i in range(len(file_paths))}\n",
    "\n",
    "\n",
    "\n",
    "# save data\n",
    "save_sparse_csr(nlp_df_sub_dir + 'tfidf_matrix', tfidf_matrix)\n",
    "\n",
    "# saved row indices\n",
    "with open(nlp_df_sub_dir + 'op_id_to_bow_id.p', 'wb') as fp:\n",
    "    pickle.dump(op_id_to_bow_id, fp)\n",
    "\n",
    "# save vocab\n",
    "with open(nlp_df_sub_dir + 'vocab.p', 'wb') as fp:\n",
    "    pickle.dump(vocab, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'15',\n",
       " u'16',\n",
       " u'17',\n",
       " u'18',\n",
       " u'19',\n",
       " u'20',\n",
       " u'21',\n",
       " u'22',\n",
       " u'23',\n",
       " u'24',\n",
       " u'25',\n",
       " u'26',\n",
       " u'27',\n",
       " u'28',\n",
       " u'29',\n",
       " u'30',\n",
       " u'31',\n",
       " u'32',\n",
       " u'33',\n",
       " u'34',\n",
       " u'35',\n",
       " u'36',\n",
       " u'37',\n",
       " u'38',\n",
       " u'39',\n",
       " u'40',\n",
       " u'41',\n",
       " u'42',\n",
       " u'43',\n",
       " u'44',\n",
       " u'45',\n",
       " u'46',\n",
       " u'47',\n",
       " u'48',\n",
       " u'49',\n",
       " u'50',\n",
       " u'52',\n",
       " u'60',\n",
       " u'absenc',\n",
       " u'accept',\n",
       " u'accord',\n",
       " u'accordingli',\n",
       " u'account',\n",
       " u'action',\n",
       " u'actual',\n",
       " u'ad',\n",
       " u'addit',\n",
       " u'administr',\n",
       " u'admit',\n",
       " u'adopt',\n",
       " u'affect',\n",
       " u'agre',\n",
       " u'al',\n",
       " u'alleg',\n",
       " u'allow',\n",
       " u'alon',\n",
       " u'alreadi',\n",
       " u'although',\n",
       " u'amend',\n",
       " u'among',\n",
       " u'amount',\n",
       " u'anoth',\n",
       " u'answer',\n",
       " u'appar',\n",
       " u'appear',\n",
       " u'appel',\n",
       " u'appli',\n",
       " u'applic',\n",
       " u'appropri',\n",
       " u'approv',\n",
       " u'april',\n",
       " u'argu',\n",
       " u'argument',\n",
       " u'aris',\n",
       " u'ask',\n",
       " u'assert',\n",
       " u'assign',\n",
       " u'assum',\n",
       " u'attempt',\n",
       " u'attorney',\n",
       " u'avail',\n",
       " u'b',\n",
       " u'bar',\n",
       " u'base',\n",
       " u'basi',\n",
       " u'bear',\n",
       " u'becam',\n",
       " u'becom',\n",
       " u'believ',\n",
       " u'benefit',\n",
       " u'beyond',\n",
       " u'bill',\n",
       " u'board',\n",
       " u'bound',\n",
       " u'brief',\n",
       " u'bring',\n",
       " u'brought',\n",
       " u'busi',\n",
       " u'c',\n",
       " u'call',\n",
       " u'carri',\n",
       " u'caus',\n",
       " u'certain',\n",
       " u'certiorari',\n",
       " u'chang',\n",
       " u'charact',\n",
       " u'charg',\n",
       " u'chief',\n",
       " u'circuit',\n",
       " u'circumst',\n",
       " u'cite',\n",
       " u'citi',\n",
       " u'claus',\n",
       " u'clear',\n",
       " u'clearli',\n",
       " u'co',\n",
       " u'come',\n",
       " u'common',\n",
       " u'compani',\n",
       " u'compel',\n",
       " u'complet',\n",
       " u'concern',\n",
       " u'conclud',\n",
       " u'conclus',\n",
       " u'concur',\n",
       " u'condit',\n",
       " u'conduct',\n",
       " u'conflict',\n",
       " u'congress',\n",
       " u'connect',\n",
       " u'consequ',\n",
       " u'consid',\n",
       " u'consider',\n",
       " u'consist',\n",
       " u'constitut',\n",
       " u'constru',\n",
       " u'construct',\n",
       " u'contain',\n",
       " u'contend',\n",
       " u'content',\n",
       " u'continu',\n",
       " u'contract',\n",
       " u'contrari',\n",
       " u'control',\n",
       " u'controversi',\n",
       " u'corpor',\n",
       " u'correct',\n",
       " u'cost',\n",
       " u'counsel',\n",
       " u'counti',\n",
       " u'cours',\n",
       " u'cover',\n",
       " u'creat',\n",
       " u'ct',\n",
       " u'date',\n",
       " u'day',\n",
       " u'decemb',\n",
       " u'declar',\n",
       " u'decre',\n",
       " u'deem',\n",
       " u'defend',\n",
       " u'demand',\n",
       " u'deni',\n",
       " u'depart',\n",
       " u'depend',\n",
       " u'describ',\n",
       " u'design',\n",
       " u'determin',\n",
       " u'differ',\n",
       " u'direct',\n",
       " u'directli',\n",
       " u'discuss',\n",
       " u'dismiss',\n",
       " u'dissent',\n",
       " u'distinct',\n",
       " u'done',\n",
       " u'doubt',\n",
       " u'due',\n",
       " u'duti',\n",
       " u'e',\n",
       " u'ed',\n",
       " u'either',\n",
       " u'employ',\n",
       " u'enact',\n",
       " u'end',\n",
       " u'enforc',\n",
       " u'engag',\n",
       " u'enter',\n",
       " u'entir',\n",
       " u'entitl',\n",
       " u'equal',\n",
       " u'error',\n",
       " u'essenti',\n",
       " u'establish',\n",
       " u'et',\n",
       " u'even',\n",
       " u'event',\n",
       " u'everi',\n",
       " u'evid',\n",
       " u'examin',\n",
       " u'except',\n",
       " u'exclus',\n",
       " u'execut',\n",
       " u'exercis',\n",
       " u'exist',\n",
       " u'express',\n",
       " u'expressli',\n",
       " u'extend',\n",
       " u'extent',\n",
       " u'f',\n",
       " u'fail',\n",
       " u'failur',\n",
       " u'far',\n",
       " u'favor',\n",
       " u'februari',\n",
       " u'feder',\n",
       " u'file',\n",
       " u'final',\n",
       " u'find',\n",
       " u'forc',\n",
       " u'form',\n",
       " u'former',\n",
       " u'forth',\n",
       " u'found',\n",
       " u'free',\n",
       " u'full',\n",
       " u'fulli',\n",
       " u'gave',\n",
       " u'give',\n",
       " u'given',\n",
       " u'go',\n",
       " u'good',\n",
       " u'govern',\n",
       " u'grant',\n",
       " u'great',\n",
       " u'ground',\n",
       " u'h',\n",
       " u'hand',\n",
       " u'hear',\n",
       " u'hold',\n",
       " u'howev',\n",
       " u'id',\n",
       " u'immedi',\n",
       " u'import',\n",
       " u'impos',\n",
       " u'includ',\n",
       " u'inde',\n",
       " u'indic',\n",
       " u'individu',\n",
       " u'inform',\n",
       " u'insist',\n",
       " u'instanc',\n",
       " u'intend',\n",
       " u'intent',\n",
       " u'interest',\n",
       " u'interpret',\n",
       " u'involv',\n",
       " u'issu',\n",
       " u'j',\n",
       " u'januari',\n",
       " u'john',\n",
       " u'judg',\n",
       " u'judici',\n",
       " u'june',\n",
       " u'juri',\n",
       " u'jurisdict',\n",
       " u'justifi',\n",
       " u'kind',\n",
       " u'known',\n",
       " u'l',\n",
       " u'land',\n",
       " u'languag',\n",
       " u'larg',\n",
       " u'last',\n",
       " u'later',\n",
       " u'latter',\n",
       " u'least',\n",
       " u'leav',\n",
       " u'left',\n",
       " u'legal',\n",
       " u'legisl',\n",
       " u'less',\n",
       " u'light',\n",
       " u'like',\n",
       " u'limit',\n",
       " u'line',\n",
       " u'long',\n",
       " u'maintain',\n",
       " u'mani',\n",
       " u'manner',\n",
       " u'march',\n",
       " u'materi',\n",
       " u'matter',\n",
       " u'mean',\n",
       " u'mention',\n",
       " u'mere',\n",
       " u'might',\n",
       " u'money',\n",
       " u'motion',\n",
       " u'much',\n",
       " u'n',\n",
       " u'name',\n",
       " u'nation',\n",
       " u'natur',\n",
       " u'necessari',\n",
       " u'necessarili',\n",
       " u'need',\n",
       " u'neither',\n",
       " u'never',\n",
       " u'new',\n",
       " u'note',\n",
       " u'noth',\n",
       " u'notic',\n",
       " u'number',\n",
       " u'object',\n",
       " u'oblig',\n",
       " u'observ',\n",
       " u'obtain',\n",
       " u'octob',\n",
       " u'offer',\n",
       " u'offic',\n",
       " u'omit',\n",
       " u'open',\n",
       " u'oper',\n",
       " u'origin',\n",
       " u'otherwis',\n",
       " u'owner',\n",
       " u'p',\n",
       " u'page',\n",
       " u'paid',\n",
       " u'parti',\n",
       " u'particular',\n",
       " u'pass',\n",
       " u'pay',\n",
       " u'payment',\n",
       " u'per',\n",
       " u'perform',\n",
       " u'period',\n",
       " u'permit',\n",
       " u'person',\n",
       " u'petit',\n",
       " u'petition',\n",
       " u'place',\n",
       " u'plaintiff',\n",
       " u'point',\n",
       " u'polici',\n",
       " u'portion',\n",
       " u'posit',\n",
       " u'possess',\n",
       " u'possibl',\n",
       " u'power',\n",
       " u'practic',\n",
       " u'prescrib',\n",
       " u'prevent',\n",
       " u'princip',\n",
       " u'principl',\n",
       " u'prior',\n",
       " u'proceed',\n",
       " u'process',\n",
       " u'produc',\n",
       " u'prohibit',\n",
       " u'proof',\n",
       " u'proper',\n",
       " u'properli',\n",
       " u'properti',\n",
       " u'protect',\n",
       " u'prove',\n",
       " u'provis',\n",
       " u'public',\n",
       " u'purchas',\n",
       " u'put',\n",
       " u'r',\n",
       " u'rais',\n",
       " u'rather',\n",
       " u'reach',\n",
       " u'read',\n",
       " u'receiv',\n",
       " u'recogn',\n",
       " u'record',\n",
       " u'recov',\n",
       " u'refer',\n",
       " u'refus',\n",
       " u'regard',\n",
       " u'regul',\n",
       " u'reject',\n",
       " u'relat',\n",
       " u'reli',\n",
       " u'relief',\n",
       " u'remain',\n",
       " u'remand',\n",
       " u'remov',\n",
       " u'render',\n",
       " u'report',\n",
       " u'repres',\n",
       " u'request',\n",
       " u'respect',\n",
       " u'respond',\n",
       " u'respons',\n",
       " u'rest',\n",
       " u'result',\n",
       " u'return',\n",
       " u'revers',\n",
       " u'review',\n",
       " u'sale',\n",
       " u'satisfi',\n",
       " u'say',\n",
       " u'second',\n",
       " u'section',\n",
       " u'secur',\n",
       " u'see',\n",
       " u'seek',\n",
       " u'seem',\n",
       " u'separ',\n",
       " u'serv',\n",
       " u'servic',\n",
       " u'set',\n",
       " u'settl',\n",
       " u'sever',\n",
       " u'show',\n",
       " u'shown',\n",
       " u'similar',\n",
       " u'simpli',\n",
       " u'sinc',\n",
       " u'situat',\n",
       " u'sole',\n",
       " u'sought',\n",
       " u'special',\n",
       " u'specif',\n",
       " u'st',\n",
       " u'stand',\n",
       " u'stat',\n",
       " u'statement',\n",
       " u'statut',\n",
       " u'statutori',\n",
       " u'still',\n",
       " u'subject',\n",
       " u'submit',\n",
       " u'subsequ',\n",
       " u'substanti',\n",
       " u'suffici',\n",
       " u'suggest',\n",
       " u'suit',\n",
       " u'sum',\n",
       " u'support',\n",
       " u'supra',\n",
       " u'suprem',\n",
       " u'sustain',\n",
       " u'take',\n",
       " u'taken',\n",
       " u'therebi',\n",
       " u'therein',\n",
       " u'thereof',\n",
       " u'thing',\n",
       " u'think',\n",
       " u'third',\n",
       " u'though',\n",
       " u'three',\n",
       " u'thu',\n",
       " u'titl',\n",
       " u'took',\n",
       " u'treat',\n",
       " u'trial',\n",
       " u'true',\n",
       " u'turn',\n",
       " u'u',\n",
       " u'unless',\n",
       " u'use',\n",
       " u'valid',\n",
       " u'valu',\n",
       " u'variou',\n",
       " u'view',\n",
       " u'violat',\n",
       " u'w',\n",
       " u'want',\n",
       " u'washington',\n",
       " u'way',\n",
       " u'well',\n",
       " u'whatev',\n",
       " u'whole',\n",
       " u'whose',\n",
       " u'william',\n",
       " u'word',\n",
       " u'work',\n",
       " u'writ',\n",
       " u'year',\n",
       " u'yet',\n",
       " u'york',\n",
       " u'\\xa7']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
