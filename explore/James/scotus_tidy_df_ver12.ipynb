{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../../code/')\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "from math import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "import igraph as ig\n",
    "\n",
    "import random as random\n",
    "\n",
    "from collections import *\n",
    "\n",
    "from load_data import load_citation_network_igraph, case_info\n",
    "\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, log_loss\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "data_dir = '../../data/'\n",
    "court_name = 'scotus'\n",
    "\n",
    "# %load ../standard_import.txt\n",
    "from __future__ import division\n",
    "import matplotlib as mpl\n",
    "\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 seconds for 250465 edges\n",
      "loaded scotus network with 33248 cases and 250465 edges\n"
     ]
    }
   ],
   "source": [
    "G = load_citation_network_igraph(data_dir, court_name)\n",
    "print 'loaded %s network with %d cases and %d edges' % (court_name, len(G.vs), len(G.es))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete bad edges (cases that cite forward in time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded scotus network with 33248 cases and 250449 edges\n"
     ]
    }
   ],
   "source": [
    "all_edges = G.get_edgelist() # list of tuples\n",
    "\n",
    "bad_edges = []\n",
    "for edge in all_edges:\n",
    "    citing_year = G.vs(edge[0])['year'][0]\n",
    "    cited_year = G.vs(edge[1])['year'][0]\n",
    "    \n",
    "    if citing_year < cited_year:\n",
    "        bad_edges.append(edge)\n",
    "\n",
    "G.delete_edges(bad_edges)\n",
    "print 'loaded %s network with %d cases and %d edges' % (court_name, len(G.vs), len(G.es))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1760 :  2 vertices and  0  edges\n",
      "1770 :  12 vertices and  3  edges\n",
      "1780 :  19 vertices and  3  edges\n",
      "1790 :  109 vertices and  6  edges\n",
      "1800 :  252 vertices and  17  edges\n",
      "1810 :  478 vertices and  48  edges\n",
      "1820 :  803 vertices and  120  edges\n",
      "1830 :  1148 vertices and  156  edges\n",
      "1840 :  1584 vertices and  294  edges\n",
      "1850 :  1956 vertices and  474  edges\n",
      "1860 :  2680 vertices and  831  edges\n",
      "1870 :  3475 vertices and  884  edges\n",
      "1880 :  5319 vertices and  2271  edges\n",
      "1890 :  7902 vertices and  10255  edges\n",
      "1900 :  10446 vertices and  25673  edges\n",
      "1910 :  12463 vertices and  37863  edges\n",
      "1920 :  14880 vertices and  52273  edges\n",
      "1930 :  16887 vertices and  67360  edges\n",
      "1940 :  18585 vertices and  86575  edges\n",
      "1950 :  20079 vertices and  106643  edges\n",
      "1960 :  21329 vertices and  118368  edges\n",
      "1970 :  23642 vertices and  136683  edges\n",
      "1980 :  25734 vertices and  166571  edges\n",
      "1990 :  27848 vertices and  199816  edges\n",
      "2000 :  29206 vertices and  221711  edges\n",
      "2010 :  32505 vertices and  238165  edges\n",
      "2020 :  33248 vertices and  250449  edges\n"
     ]
    }
   ],
   "source": [
    "# start from 1760\n",
    "scotus_years = range(1760, 2021) # scotus years actually from 1754-2016\n",
    "scotus_decades = [year for year in scotus_years if year % 10 == 0] # 1760, ... , 2000, 2010, 2020\n",
    "\n",
    "subgraph_dict = OrderedDict() # key: decade, value: subgraph with vertices less than that decade year\n",
    "for i in scotus_decades:\n",
    "    sub_vs = G.vs.select(year_lt=i)\n",
    "    sub_G = G.subgraph(sub_vs) # IMPORTANT NOTE: THESE NEW SUBGRAPHS RE-INDEX (DIFFERENT INDICES THAN G_2)\n",
    "    subgraph_dict[i] = sub_G\n",
    "    print i, \": \", len(sub_G.vs), \"vertices and \", len(sub_G.es), \" edges\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create vertex DFs (with metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vertex_df_dict = OrderedDict()\n",
    "for key in scotus_decades:\n",
    "    #get subgraph\n",
    "    subgraph = subgraph_dict[key]\n",
    "    \n",
    "    #get metrics in lists\n",
    "    vertex_name = subgraph.vs['name']\n",
    "    vertex_year = subgraph.vs['year']\n",
    "    indegree = subgraph.indegree()\n",
    "    pagerank = subgraph.pagerank()\n",
    "    \n",
    "    #build df from lists\n",
    "    column_names = ['name','year','indegree','pagerank']\n",
    "    vertex_tuples = zip(vertex_name,vertex_year,indegree,pagerank)\n",
    "    vertex_df = pd.DataFrame(vertex_tuples, columns=column_names)\n",
    "    \n",
    "    #add df to dict\n",
    "    vertex_df_dict[key] = vertex_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         name  year  indegree  pagerank\n",
       "0      100000  1922         1  0.000022\n",
       "1      100001  1922         1  0.000025\n",
       "2      100002  1922         4  0.000022\n",
       "3      100003  1922         3  0.000023\n",
       "4      100004  1922         4  0.000028\n",
       "5      100005  1922         6  0.000029\n",
       "6      100006  1922         5  0.000053\n",
       "7      100007  1922        16  0.000061\n",
       "8      100008  1922         0  0.000020\n",
       "9      100009  1922        16  0.000056\n",
       "10     100010  1922        21  0.000055\n",
       "11     100011  1922        23  0.000090\n",
       "12     100012  1922         1  0.000020\n",
       "13     100013  1922         4  0.000034\n",
       "14     100014  1922         4  0.000028\n",
       "15     100015  1922         9  0.000045\n",
       "16     100016  1922         2  0.000026\n",
       "17     100017  1922         0  0.000020\n",
       "18     100018  1922        28  0.000161\n",
       "19     100019  1922         0  0.000020\n",
       "20     100020  1922        16  0.000074\n",
       "21     100021  1922         3  0.000026\n",
       "22     100022  1922         8  0.000047\n",
       "23     100023  1922        17  0.000061\n",
       "24     100024  1922         3  0.000023\n",
       "25     100025  1922        13  0.000056\n",
       "26     100026  1922         2  0.000021\n",
       "27     100027  1922         0  0.000020\n",
       "28     100028  1922         6  0.000036\n",
       "29     100029  1922         1  0.000028\n",
       "...       ...   ...       ...       ...\n",
       "20049   99970  1922         2  0.000046\n",
       "20050   99971  1922         4  0.000028\n",
       "20051   99972  1922         3  0.000027\n",
       "20052   99973  1922         1  0.000022\n",
       "20053   99974  1922        18  0.000062\n",
       "20054   99975  1922        14  0.000034\n",
       "20055   99976  1922         9  0.000071\n",
       "20056   99977  1922        31  0.000087\n",
       "20057   99978  1922        16  0.000141\n",
       "20058   99979  1922         6  0.000045\n",
       "20059   99980  1922         5  0.000036\n",
       "20060   99981  1922         3  0.000041\n",
       "20061   99982  1922        22  0.000091\n",
       "20062   99983  1922        23  0.000111\n",
       "20063   99984  1922         0  0.000020\n",
       "20064   99985  1922         6  0.000035\n",
       "20065   99986  1922         1  0.000022\n",
       "20066   99987  1922        20  0.000064\n",
       "20067   99988  1922        26  0.000075\n",
       "20068   99989  1922         4  0.000044\n",
       "20069   99990  1922         4  0.000032\n",
       "20070   99991  1922         3  0.000028\n",
       "20071   99992  1922         4  0.000071\n",
       "20072   99993  1922        12  0.000042\n",
       "20073   99994  1922         6  0.000052\n",
       "20074   99995  1922         1  0.000020\n",
       "20075   99996  1922         0  0.000020\n",
       "20076   99997  1922         1  0.000021\n",
       "20077   99998  1922         6  0.000029\n",
       "20078   99999  1922         3  0.000031\n",
       "\n",
       "[20079 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertex_df_dict[1950]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create edgelist -- 'ed' metric in 'ing' year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create N1 (present edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this took 199.434000015 seconds\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "\n",
    "#list of tuples that will become N1 df\n",
    "#each tuple in the form: 0 (non-present edge), citing_name, cited_name, cited metrics (indegree, pagerank, etc.)\n",
    "n1_list = []\n",
    "\n",
    "#get all present edges\n",
    "n1 = subgraph_dict[scotus_decades[-1]].get_edgelist() #list of tuples\n",
    "\n",
    "for edge in n1:\n",
    "    #get info from edge\n",
    "    citing_year = G.vs(edge[0])['year'][0]\n",
    "    cited_year = G.vs(edge[1])['year'][0]\n",
    "    citing_name = G.vs(edge[0])['name'][0]\n",
    "    cited_name = G.vs(edge[1])['name'][0]\n",
    "\n",
    "    #determine which vertex_df to retrieve\n",
    "    decade = citing_year + (10 - citing_year%10)\n",
    "    vertex_df = vertex_df_dict[decade]\n",
    "    \n",
    "    #get row from df using cited_name\n",
    "    row = vertex_df.loc[vertex_df['name']==cited_name].values.tolist()\n",
    "    \n",
    "    edge_tuple = (1, citing_name) + tuple(row[0])\n",
    "    n1_list.append(edge_tuple)\n",
    "        \n",
    "column_names = ['edge','citing_name','cited_name','cited_year','cited_indegree','cited_pagerank']\n",
    "n1_df = pd.DataFrame(n1_list, columns=column_names)\n",
    "\n",
    "time2 = time.time()\n",
    "print \"this took \" + str(time2-time1) + \" seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fix some columns that are type double\n",
    "integer_columns = ['edge', 'citing_name', 'cited_name', 'cited_year', 'cited_indegree'] # keep pagerank as float (obviously)\n",
    "n1_df[integer_columns] = n1_df[integer_columns].astype(np.int64) # turn double columns into integer columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create N0 (non-present edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this took 556.496999979 seconds\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "\n",
    "# set of tuples that will become N0 df\n",
    "# each tuple in the form: 0 (non-present edge), citing_name, cited_name, cited metrics (indegree, pagerank, etc.)\n",
    "\n",
    "n0_set = set([]) # set makes adding 'edge_tuple' unique in the while loop (need b/c random sampling can return duplicates)\n",
    "n1_edges = set(subgraph_dict[scotus_decades[-1]].get_edgelist()) # when searching for element, set is faster than list\n",
    "n1_vertices_set = set(subgraph_dict[scotus_decades[-1]].vs) # just for consistency\n",
    "\n",
    "while len(n0_set) < len(n1_edges):\n",
    "    # get random_edge\n",
    "    temp = random.sample(n1_vertices_set, 2) # default: without replacement\n",
    "    random_edge = (temp[0].index, temp[1].index)\n",
    "    \n",
    "    # get info from edge\n",
    "    citing_year = G.vs(random_edge[0])['year'][0]\n",
    "    cited_year = G.vs(random_edge[1])['year'][0]\n",
    "    citing_name = G.vs(random_edge[0])['name'][0]\n",
    "    cited_name = G.vs(random_edge[1])['name'][0]\n",
    "    \n",
    "    if random_edge not in n1_edges and citing_year >= cited_year:\n",
    "        # determine which vertex_df to retrieve\n",
    "        decade = citing_year + (10 - citing_year%10)\n",
    "        vertex_df = vertex_df_dict[decade]\n",
    "\n",
    "        # get row from df using cited name\n",
    "        row = vertex_df.loc[vertex_df['name']==cited_name].values.tolist()\n",
    "\n",
    "        edge_tuple = (0, citing_name) + tuple(row[0])\n",
    "        n0_set.add(edge_tuple)\n",
    "\n",
    "time2 = time.time()\n",
    "print \"this took \" + str(time2-time1) + \" seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_names = ['edge','citing_name','cited_name','cited_year','cited_indegree','cited_pagerank']\n",
    "n0_df = pd.DataFrame(list(n0_set), columns=column_names)\n",
    "\n",
    "# Fix some columns that are type double\n",
    "integer_columns = ['edge', 'citing_name', 'cited_name', 'cited_year', 'cited_indegree'] # keep pagerank as float (obviously)\n",
    "n0_df[integer_columns] = n0_df[integer_columns].astype(np.int64) # turn double columns into integer columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine n0_df and n1_df into edges_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edges_df = n0_df.append(n1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        edge  citing_name  cited_name  cited_year  cited_indegree  \\\n",
       "0          0       105146       94388        1896               2   \n",
       "1          0       111030       99966        1922              20   \n",
       "2          0       106778       84925        1809               0   \n",
       "3          0       110601      109319        1975               0   \n",
       "4          0       104605       87232        1859               1   \n",
       "5          0      1087630      101060        1927               0   \n",
       "6          0       145708       87720        1866              13   \n",
       "7          0       111872      106361        1962               1   \n",
       "8          0       107721     1964908        1921               6   \n",
       "9          0       104397      102881        1937               0   \n",
       "10         0       110958       95957        1903              10   \n",
       "11         0       106207      105235        1954              13   \n",
       "12         0        96289       86537        1850              12   \n",
       "13         0        99592       94969        1899               7   \n",
       "14         0       142132      105699        1958               6   \n",
       "15         0        99671     1216059        1891               3   \n",
       "16         0       107497       86195        1842               3   \n",
       "17         0       106165      102512        1935              10   \n",
       "18         0       100790       91700        1886              18   \n",
       "19         0       109487       88940        1874               0   \n",
       "20         0       101654      100022        1922               8   \n",
       "21         0       102826       85584        1828               2   \n",
       "22         0        91152       85349        1821               4   \n",
       "23         0       115911       86052        1838               4   \n",
       "24         0       112090       90772        1883              10   \n",
       "25         0        97991       85288        1820               0   \n",
       "26         0       110329      104005        1944               6   \n",
       "27         0       141908       96617        1907               9   \n",
       "28         0       111492       95202        1900              15   \n",
       "29         0       102202       86869        1854               0   \n",
       "...      ...          ...         ...         ...             ...   \n",
       "250419     1        99996       96757        1908               3   \n",
       "250420     1        99996       97535        1912               4   \n",
       "250421     1        99996       97866        1913              10   \n",
       "250422     1        99996       99828        1921               1   \n",
       "250423     1        99997     1115307        1915               6   \n",
       "250424     1        99997       91281        1885               8   \n",
       "250425     1        99997       92749        1890               4   \n",
       "250426     1        99997       93383        1892               5   \n",
       "250427     1        99997       94313        1895               6   \n",
       "250428     1        99997       94340        1896              22   \n",
       "250429     1        99997       94989        1899               4   \n",
       "250430     1        99997       95589        1902               5   \n",
       "250431     1        99997       97624        1912               7   \n",
       "250432     1        99997       99427        1919              10   \n",
       "250433     1        99997       99544        1920               5   \n",
       "250434     1        99998       87550        1864               7   \n",
       "250435     1        99998       89603        1877              15   \n",
       "250436     1        99998       89876        1879              18   \n",
       "250437     1        99998       95389        1901              10   \n",
       "250438     1        99998       97634        1912               5   \n",
       "250439     1        99999       97905        1913              17   \n",
       "250440     1        99999       98508        1915              14   \n",
       "250441     1        99999       98613        1916              12   \n",
       "250442     1        99999       98727        1916               6   \n",
       "250443     1        99999       98791        1916               4   \n",
       "250444     1        99999       98837        1917               2   \n",
       "250445     1        99999       98951        1916               6   \n",
       "250446     1        99999       99312        1919               2   \n",
       "250447     1        99999       99399        1919               1   \n",
       "250448     1        99999       99494        1920               2   \n",
       "\n",
       "        cited_pagerank  \n",
       "0             0.000021  \n",
       "1             0.000049  \n",
       "2             0.000016  \n",
       "3             0.000012  \n",
       "4             0.000020  \n",
       "5             0.000016  \n",
       "6             0.000030  \n",
       "7             0.000027  \n",
       "8             0.000041  \n",
       "9             0.000020  \n",
       "10            0.000084  \n",
       "11            0.000065  \n",
       "12            0.000246  \n",
       "13            0.000055  \n",
       "14            0.000016  \n",
       "15            0.000049  \n",
       "16            0.000028  \n",
       "17            0.000029  \n",
       "18            0.000118  \n",
       "19            0.000014  \n",
       "20            0.000047  \n",
       "21            0.000036  \n",
       "22            0.000175  \n",
       "23            0.000032  \n",
       "24            0.000039  \n",
       "25            0.000031  \n",
       "26            0.000020  \n",
       "27            0.000028  \n",
       "28            0.000126  \n",
       "29            0.000022  \n",
       "...                ...  \n",
       "250419        0.000037  \n",
       "250420        0.000042  \n",
       "250421        0.000070  \n",
       "250422        0.000029  \n",
       "250423        0.000041  \n",
       "250424        0.000084  \n",
       "250425        0.000050  \n",
       "250426        0.000063  \n",
       "250427        0.000054  \n",
       "250428        0.000198  \n",
       "250429        0.000061  \n",
       "250430        0.000049  \n",
       "250431        0.000044  \n",
       "250432        0.000050  \n",
       "250433        0.000043  \n",
       "250434        0.000135  \n",
       "250435        0.000148  \n",
       "250436        0.000184  \n",
       "250437        0.000080  \n",
       "250438        0.000045  \n",
       "250439        0.000134  \n",
       "250440        0.000129  \n",
       "250441        0.000096  \n",
       "250442        0.000068  \n",
       "250443        0.000038  \n",
       "250444        0.000031  \n",
       "250445        0.000048  \n",
       "250446        0.000033  \n",
       "250447        0.000028  \n",
       "250448        0.000029  \n",
       "\n",
       "[500898 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run logistic regression for different training sets (combinations of metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createLogReg(dataframe, x_train_list):\n",
    "    #set up training data\n",
    "    y_train = dataframe['edge']\n",
    "    x_train = dataframe[x_train_list]\n",
    "\n",
    "    #calculate logistical regression\n",
    "    clf = skl_lm.LogisticRegression(solver='newton-cg')\n",
    "    clf.fit(x_train, y_train)\n",
    "    return clf\n",
    "\n",
    "def getProb(clf, x_test_df):\n",
    "    # get attachment probabilities on testing set\n",
    "    prob = clf.predict_proba(x_test_df)\n",
    "    \n",
    "    # predicted probabilities for ALL case for edge present (1)\n",
    "    prob_present = prob[:,1:2]\n",
    "    # convert to list\n",
    "    prob_present2 = [i.tolist()[0] for i in prob_present]\n",
    "    \n",
    "    return prob_present2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcRankScore(R_list, edges_df, vertex_df_dict, x_train_columns, x_test_columns):\n",
    "    ### get attachment probabilities added into dataframe for one vertex\n",
    "\n",
    "    time1 = time.time()\n",
    "\n",
    "    # get year of each case in R\n",
    "    # attachment probabilities for all vertices in that year\n",
    "    # rank the dataframe\n",
    "    # get neighbors of each case \n",
    "    # see how each neighbor ranks\n",
    "    # get each neighbor's score\n",
    "    # sum up scores for one case in R\n",
    "    # final score = sum of all 1000 scores\n",
    "\n",
    "    #The logistical regression is calculated outside the for loop and saved as clf\n",
    "    x_train_list = x_train_columns\n",
    "    clf = createLogReg(edges_df, x_train_list)\n",
    "\n",
    "    final_scores = [] # sum of scores for each case\n",
    "    for vertex_r in R_list:\n",
    "        # get year of each case in R\n",
    "        year = vertex_r['year']\n",
    "\n",
    "        # determine which vertex_df to retrieve\n",
    "        decade = year + (10 - year%10)\n",
    "        vertex_df = vertex_df_dict[decade]\n",
    "\n",
    "        # attachment probabilities for all vertices in that year\n",
    "        #use the logreg already calculated and just apply a new test set\n",
    "        x_test_df = vertex_df[x_test_columns]\n",
    "        indeg_attach_p = getProb(clf, x_test_df)\n",
    "\n",
    "        # add the attachment probabilities as column\n",
    "        vertex_df['indegree_attachment_p'] = indeg_attach_p\n",
    "        # sort by attachment probabilities\n",
    "        vertex_df = vertex_df.sort_values('indegree_attachment_p', ascending=False, kind='mergesort').reset_index(drop=True)\n",
    "\n",
    "        # get neighbors\n",
    "        neighbors = G.neighbors(vertex_r.index, mode='OUT')\n",
    "\n",
    "        # rank and score neighbors using dataframe indices\n",
    "        scores = [] # list of scores for each vertex\n",
    "        for i in neighbors:\n",
    "            rank = vertex_df.loc[vertex_df['name']==G.vs[i]['name']].index[0] + 1\n",
    "            score = 1-rank/len(indeg_attach_p)\n",
    "            scores.append(score)\n",
    "\n",
    "        sum_scores = sum(scores) # sum up the scores for each case\n",
    "        final_scores.append(sum_scores)\n",
    "\n",
    "    score_M = sum(final_scores) # score of metric\n",
    "\n",
    "    time2 = time.time()\n",
    "    print \"this took \" + str(time2-time1) + \" seconds\"\n",
    "    print \"Score: \" + str(score_M)\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick R Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R = 500 # number of random cases\n",
    "n1_vertices_set = set(G.vs)\n",
    "R_list = random.sample(n1_vertices_set, R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test R cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indegree\n",
      "this took 9.77799987793 seconds\n",
      "Score: 2998.94088151\n",
      "\n",
      "Pagerank\n",
      "this took 9.22500014305 seconds\n",
      "Score: 2563.98054996\n",
      "\n",
      "Indegree and Pagerank\n",
      "this took 10.3090000153 seconds\n",
      "Score: 2970.85944083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train_columns = ['cited_indegree']\n",
    "x_test_columns = ['indegree']\n",
    "print \"Indegree\"\n",
    "calcRankScore(R_list, edges_df, vertex_df_dict, x_train_columns, x_test_columns)\n",
    "\n",
    "x_train_columns = ['cited_pagerank']\n",
    "x_test_columns = ['pagerank']\n",
    "print \"Pagerank\"\n",
    "calcRankScore(R_list, edges_df, vertex_df_dict, x_train_columns, x_test_columns)\n",
    "\n",
    "x_train_columns = ['cited_indegree','cited_pagerank']\n",
    "x_test_columns = ['indegree','pagerank']\n",
    "print \"Indegree and Pagerank\"\n",
    "calcRankScore(R_list, edges_df, vertex_df_dict, x_train_columns, x_test_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
