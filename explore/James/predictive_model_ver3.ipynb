{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../../code/')\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "from math import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "import igraph as ig\n",
    "\n",
    "from collections import *\n",
    "import random\n",
    "\n",
    "from load_data import load_citation_network_igraph, case_info\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "data_dir = '../../data/'\n",
    "court_name = 'scotus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 seconds for 250465 edges\n",
      "loaded scotus network with 33248 cases and 250465 edges\n"
     ]
    }
   ],
   "source": [
    "# this will be a little slow the first time you run it\n",
    "G = load_citation_network_igraph(data_dir, court_name)\n",
    "\n",
    "print 'loaded %s network with %d cases and %d edges' % (court_name, len(G.vs), len(G.es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#takes a graph of cases and returns the min and max years in a tuple\n",
    "def find_year_range(graph):\n",
    "    min_year = 10000\n",
    "    max_year = -1\n",
    "    \n",
    "    for v in graph.vs:\n",
    "        year = v[\"year\"]\n",
    "        if year < min_year:\n",
    "            min_year = year\n",
    "        if year > max_year:\n",
    "            max_year = year\n",
    "    return (min_year, max_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#takes a graph and creates a subgraph for each year containing all vertices and edges explicitly before that year\n",
    "def make_subgraph_dict(graph):\n",
    "    time1 = time.time()\n",
    "    \n",
    "    subgraph_dict = {}\n",
    "    min_year = find_year_range(graph)[0]\n",
    "    max_year = find_year_range(graph)[1]    \n",
    "    \n",
    "    #for each year finds all vertices that have a year attrubute less than year i,\n",
    "    #  makes a subgraph from those vertices, and adds that subgraph to a dict with year as the key\n",
    "    for i in range (min_year,max_year+2):\n",
    "        sub_vs = graph.vs.select(year_lt=i)\n",
    "        sub_G = graph.subgraph(sub_vs)\n",
    "        subgraph_dict[i] = sub_G\n",
    "\n",
    "    time2 = time.time()\n",
    "    print \"Making sub-graph dict took \" + str(time2-time1) + \" seconds\"\n",
    "    return subgraph_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#determines the number of citing cases to a particular case that are within some year difference (threshold)\n",
    "def time_decay_indegree(graph, vertex, threshold=10):\n",
    "    td_indeg = 0\n",
    "    vertex_year = vertex[\"year\"]\n",
    "    neighbors = graph.neighbors(vertex.index, mode='IN')\n",
    "    #for each in-edge adds 1 to the count only if the year diff is less than the given threshold\n",
    "    for neighbor in neighbors:\n",
    "        neighbor_year = graph.vs[neighbor][\"year\"]\n",
    "        if neighbor_year - vertex_year <= threshold:\n",
    "            td_indeg += 1\n",
    "    return td_indeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#takes a dict of subgraphs by year and returns a dict of case tuples that contain info and that are sorted by a metric\n",
    "#  current metrics supported are: indegree, pagerank, and timedecay (indegree with a time decay threshold)\n",
    "def make_case_dict(subgraph_dict, metric=\"indegree\"):\n",
    "    time1 = time.time()\n",
    "\n",
    "    past_cases_dict = {}\n",
    "    min_year = sorted(subgraph_dict.keys())[0]\n",
    "    max_year = sorted(subgraph_dict.keys())[-1]\n",
    "    \n",
    "    #for each year multiple list are filled and zipped together to form a list of tuples\n",
    "    for i in range (min_year,max_year+1):\n",
    "        sub_G = subgraph_dict[i]\n",
    "\n",
    "        tuple_list = []\n",
    "        igraph_subg_index_list = []\n",
    "        name_list = []\n",
    "        year_list = []\n",
    "        metric_list = []\n",
    "        \n",
    "        #pagerank metric calculates a list of values for all vertices\n",
    "        if metric == \"pagerank\":\n",
    "            metric_list = sub_G.pagerank()\n",
    "        \n",
    "        #goes through all vertices in the subgraph and adds info to lists\n",
    "        for j in range(0,len(sub_G.vs)):\n",
    "            vertex = sub_G.vs[j]\n",
    "            igraph_subg_index_list.append(vertex.index)\n",
    "            name_list.append(vertex['name'])\n",
    "            year_list.append(vertex['year'])\n",
    "            \n",
    "            #these two metrics calculate value for each individual vertex \n",
    "            if metric == \"indegree\":\n",
    "                metric_list.append(vertex.indegree())\n",
    "            if metric == \"timedecay\":\n",
    "                metric_list.append(time_decay_indegree(sub_G, vertex, 10))\n",
    "        \n",
    "        tuple_list = zip(igraph_subg_index_list, name_list, year_list, metric_list)\n",
    "\n",
    "        #sorts the tuples by their metric value so each case's rank is now its index + 1\n",
    "        sorted_tuple_list = sorted(tuple_list, key=lambda tup: tup[3], reverse=True)\n",
    "\n",
    "        past_cases_dict[i] = sorted_tuple_list\n",
    "\n",
    "    time2 = time.time()\n",
    "    print \"Making past case dict for \" + metric + \" took \" + str(time2-time1) + \" seconds\"\n",
    "    return past_cases_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#produces a score for a particular case based on the metric that the past_case_dict is sorted by\n",
    "def calculate_score_for_case(graph, case_index, past_cases_dict):\n",
    "    all_past_cases = past_cases_dict[graph.vs[case_index]['year']]\n",
    "    \n",
    "    #finds the neighbors the particular case points to and creates a list of their court_listener names\n",
    "    neighbors = graph.neighbors(case_index, mode='OUT')\n",
    "    neighbors_names = [graph.vs[i]['name'] for i in neighbors]\n",
    "    \n",
    "    #finds the ranks of all neighbors that are in the sub_graph of cases before the case's year\n",
    "    #  (so cases with the same year as the particular case will not be found)\n",
    "    ranks = [i+1.0 for i, v in enumerate(all_past_cases) if v[1] in neighbors_names]\n",
    "\n",
    "    #calculates scores based on rank and total number of ases before\n",
    "    scores = []\n",
    "    for some_rank in ranks:\n",
    "        some_score = 1 - some_rank/len(all_past_cases)\n",
    "        scores.append(some_score)\n",
    "    \n",
    "    #sums up scores to find the final score for the case\n",
    "    final_score = sum(scores)\n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#finds the total score for all cases in a graph based on the metric of the past_case_dict\n",
    "def calculate_score_from_case_dict(graph, past_case_dict):\n",
    "    time1 = time.time()\n",
    "\n",
    "    metric_score = 0\n",
    "    for i in graph.vs():\n",
    "        metric_score += calculate_score_for_case(graph, i.index, past_case_dict)\n",
    "\n",
    "    time2 = time.time()\n",
    "    print \"Total score was: \" + str(metric_score)\n",
    "    print \"This took \" + str(time2-time1) + \" seconds\"\n",
    "    return metric_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combines all the functions to calculate the score of a supported metric from just the original graph\n",
    "def calculate_metric_score_from_graph(graph, metric=\"indegree\"):\n",
    "    subgraph_dict = make_subgraph_dict(graph)\n",
    "    case_dict = make_case_dict(subgraph_dict, metric)\n",
    "    metric_score = calculate_score_from_case_dict(G, case_dict)\n",
    "    return metric_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making sub-graph dict took 6.31699991226 seconds\n",
      "Making sorted case tuples for indegree took 9.47200012207 seconds\n",
      "Making sorted case tuples for pagerank took 24.8499999046 seconds\n",
      "Making sorted case tuples for timedecay took 19.9869999886 seconds\n"
     ]
    }
   ],
   "source": [
    "subgraph_dict = make_subgraph_dict(G)\n",
    "case_dict_indegree  = make_case_dict(subgraph_dict, \"indegree\")\n",
    "case_dict_pagerank  = make_case_dict(subgraph_dict, \"pagerank\")\n",
    "case_dict_timedecay = make_case_dict(subgraph_dict, \"timedecay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indegree\n",
      "Total score was: 174094.901772\n",
      "This took 157.934999943 seconds\n"
     ]
    }
   ],
   "source": [
    "print \"indegree\"\n",
    "indegree_score = calculate_score_from_case_dict(G, case_dict_indegree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pagerank\n",
      "Total score was: 149192.224771\n",
      "This took 179.652000189 seconds\n"
     ]
    }
   ],
   "source": [
    "print \"pagerank\"\n",
    "pagerank_score = calculate_score_from_case_dict(G, case_dict_pagerank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indegree with time decay\n",
      "Total score was: 180027.49242\n",
      "This took 185.852999926 seconds\n"
     ]
    }
   ],
   "source": [
    "print \"indegree with time decay\"\n",
    "timedecay_score = calculate_score_from_case_dict(G, case_dict_timedecay)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
