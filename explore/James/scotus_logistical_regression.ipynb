{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../../code/')\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "from math import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "import igraph as ig\n",
    "\n",
    "from collections import *\n",
    "\n",
    "from load_data import load_citation_network_igraph, case_info\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "data_dir = '../../data/'\n",
    "court_name = 'scotus'\n",
    "\n",
    "# %load ../standard_import.txt\n",
    "from __future__ import division\n",
    "import matplotlib as mpl\n",
    "#import seaborn as sns\n",
    "\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, log_loss\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 seconds for 250465 edges\n",
      "loaded scotus network with 33248 cases and 250465 edges\n"
     ]
    }
   ],
   "source": [
    "G = load_citation_network_igraph(data_dir, court_name)\n",
    "\n",
    "print 'loaded %s network with %d cases and %d edges' % (court_name, len(G.vs), len(G.es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#scotus_adjacency_full = G.get_adjacency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH DN-- 10446 25674 -- \n",
      "+ attr: court (v), name (v), year (v)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sub_vs = G.vs.select(year_lt=1900)\n",
    "sub_G = G.subgraph(sub_vs)\n",
    "print ig.summary(sub_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this took 13.9709999561 seconds\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "scotus_adjacency = sub_G.get_adjacency()\n",
    "time2 = time.time()\n",
    "print \"this took \" + str(time2-time1) + \" seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of edges: 25674\n",
      "number of possible edges: 55491372\n",
      "this took 587.805000067 seconds\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "number_of_edges = 0\n",
    "edge_tuples = []\n",
    "for i in range(0,scotus_adjacency.shape[1]):\n",
    "    for j in range(0,scotus_adjacency.shape[1]):\n",
    "        citing_index = i\n",
    "        cited_index = j\n",
    "        time_diff = sub_G.vs[i][\"year\"]-sub_G.vs[j][\"year\"]\n",
    "        cited_indegree = sub_G.vs[j].indegree()\n",
    "        edge = scotus_adjacency[i,j]\n",
    "        edge_tuple = (citing_index, cited_index, time_diff, cited_indegree, edge)\n",
    "        if edge == 1:\n",
    "            number_of_edges += 1\n",
    "        if not i==j and time_diff >= 0:\n",
    "            edge_tuples.append(edge_tuple)\n",
    "print \"number of edges: \" + str(number_of_edges)\n",
    "print \"number of possible edges: \" + str(len(edge_tuples))\n",
    "time2 = time.time()\n",
    "print \"this took \" + str(time2-time1) + \" seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          citing index  cited index  time difference  cited indegree  edge\n",
      "0                    0            1               35               1     0\n",
      "1                    0            2               56               3     0\n",
      "2                    0            9               13               4     0\n",
      "3                    0           10               13               5     0\n",
      "4                    0           11               13               2     0\n",
      "5                    0           12               13               4     0\n",
      "6                    0           13               64               0     0\n",
      "7                    0           14               22              12     0\n",
      "8                    0           15               16               2     0\n",
      "9                    0           16               16               4     0\n",
      "10                   0           22               49               1     0\n",
      "11                   0           26               24               1     0\n",
      "12                   0           27                5               0     0\n",
      "13                   0           28               11               3     0\n",
      "14                   0           29               10               1     0\n",
      "15                   0           30               10               0     0\n",
      "16                   0           31               10               6     0\n",
      "17                   0           32                1               2     0\n",
      "18                   0           39                3               1     0\n",
      "19                   0           40               73               0     0\n",
      "20                   0           41                3               1     0\n",
      "21                   0           54               75               0     0\n",
      "22                   0           55               75               0     0\n",
      "23                   0           56               75               1     0\n",
      "24                   0           57               75               1     0\n",
      "25                   0           58               75               0     0\n",
      "26                   0           59               75               1     0\n",
      "27                   0           60               75               0     0\n",
      "28                   0           61               83               1     0\n",
      "29                   0           62               83               1     0\n",
      "...                ...          ...              ...             ...   ...\n",
      "55491342         10445        10415                0               0     0\n",
      "55491343         10445        10416                0               0     0\n",
      "55491344         10445        10417                0               0     0\n",
      "55491345         10445        10418                0               0     0\n",
      "55491346         10445        10419                0               0     0\n",
      "55491347         10445        10420                0               0     0\n",
      "55491348         10445        10421                0               0     0\n",
      "55491349         10445        10422                0               0     0\n",
      "55491350         10445        10423                0               0     0\n",
      "55491351         10445        10424                0               0     0\n",
      "55491352         10445        10425                0               0     0\n",
      "55491353         10445        10426                0               0     0\n",
      "55491354         10445        10427                0               0     0\n",
      "55491355         10445        10428                0               0     0\n",
      "55491356         10445        10429                0               0     0\n",
      "55491357         10445        10430                0               0     0\n",
      "55491358         10445        10431                0               0     0\n",
      "55491359         10445        10432                0               0     0\n",
      "55491360         10445        10433                0               0     0\n",
      "55491361         10445        10434                0               0     0\n",
      "55491362         10445        10435                0               0     0\n",
      "55491363         10445        10436                0               1     0\n",
      "55491364         10445        10437                0               1     0\n",
      "55491365         10445        10438                0               1     0\n",
      "55491366         10445        10439                0               1     0\n",
      "55491367         10445        10440                0               0     0\n",
      "55491368         10445        10441                0               0     0\n",
      "55491369         10445        10442                0               0     0\n",
      "55491370         10445        10443                0               0     0\n",
      "55491371         10445        10444                0               0     0\n",
      "\n",
      "[55491372 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "list_of_column_names = [\"citing index\",\"cited index\", \"time difference\", \"cited indegree\", \"edge\"]\n",
    "df = pd.DataFrame(edge_tuples, columns=list_of_column_names)\n",
    "print df\n",
    "time2 = time.time()\n",
    "print \"this took \" + str(time2-time1) + \" seconds\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression on Training Set = All Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhj3\\Anaconda2\\lib\\site-packages\\scipy\\optimize\\linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\jhj3\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\optimize.py:193: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes:  [0 1]\n",
      "coefficients:  [[-0.02953166  0.10705958]]\n",
      "intercept : [-7.5718848]\n"
     ]
    }
   ],
   "source": [
    "y_train = df['edge']\n",
    "\n",
    "# dataset --for training set\n",
    "x_train = df[['time difference', 'cited indegree']]\n",
    "\n",
    "clf = skl_lm.LogisticRegression(solver='newton-cg')\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print 'classes: ',clf.classes_\n",
    "print 'coefficients: ',clf.coef_\n",
    "print 'intercept :', clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire Probabilities of Direction == Yes for Training Set = All Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Matrix, where column = probability for no edge (0), probability for edge (1)--reference: clf.classes_\n",
    "prob = clf.predict_proba(x_train)\n",
    "\n",
    "# predicted probabilities for ALL years for UP direction\n",
    "prob_up = prob[:,1:2]\n",
    "\n",
    "# convert to list\n",
    "prob_up2 = [i.tolist()[0] for i in prob_up]\n",
    "\n",
    "y_predicted = []\n",
    "for i in prob_up2:\n",
    "    if i>0.5:\n",
    "        y_predicted.append(1)\n",
    "    else:\n",
    "        y_predicted.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1: 0-1 Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 (0-1 loss):  0.9995373515\n"
     ]
    }
   ],
   "source": [
    "right_prediction = [i for i,j in zip(y_train, y_predicted) if i==j]\n",
    "number_right = len(right_prediction)\n",
    "zero_one_loss = number_right/len(y_predicted)\n",
    "print \"L1 (0-1 loss): \", zero_one_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2: Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 (Cross Entropy Loss) by sci-kit:  0.00375218860171\n",
      "L2 (Cross Entropy Loss) by manually:  0.00375218860174\n"
     ]
    }
   ],
   "source": [
    "# source: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html\n",
    "#         https://en.wikipedia.org/wiki/Cross_entropy\n",
    "\n",
    "# using sci-kit:\n",
    "y_train2 = []\n",
    "for i in y_train:\n",
    "    if i==1:\n",
    "        y_train2.append(1)\n",
    "    else:\n",
    "        y_train2.append(0)\n",
    "\n",
    "print \"L2 (Cross Entropy Loss) by sci-kit: \", log_loss(y_train2, prob_up2)\n",
    "\n",
    "# manually:\n",
    "def ln(x):\n",
    "    return np.log(x)\n",
    "\n",
    "cross_entropy_losses = [-i*ln(j)-(1-i)*ln(1-j) for i,j in zip(y_train2, prob_up2)]\n",
    "print \"L2 (Cross Entropy Loss) by manually: \", sum(cross_entropy_losses)/len(cross_entropy_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L3: Logistic Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# source (with ln(2)): https://en.wikipedia.org/wiki/Loss_functions_for_classification\n",
    "\n",
    "# source (without ln(2)): https://people.eecs.berkeley.edu/~russell/classes/cs194/f11/lectures/CS194%20Fall%202011%20Lecture%2006.pdf\n",
    "#                         https://github.com/JohnLangford/vowpal_wabbit/wiki/Loss-functions\n",
    "#                         http://www.cs.cmu.edu/~yandongl/loss.html\n",
    "\n",
    "logistic_losses = [(1/ln(2))*(ln(1+np.exp(-i*j))) for i,j in zip(y_train2, prob_up2)]        \n",
    "print \"L3 (Logistic Loss) with ln(2): \", sum(logistic_losses)/len(logistic_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
