{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../../code/')\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "from math import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "import igraph as ig\n",
    "\n",
    "import random as random\n",
    "\n",
    "from collections import *\n",
    "\n",
    "from load_data import load_citation_network_igraph, case_info\n",
    "\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, log_loss\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "data_dir = '../../data/'\n",
    "court_name = 'scotus'\n",
    "\n",
    "# %load ../standard_import.txt\n",
    "from __future__ import division\n",
    "import matplotlib as mpl\n",
    "\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_ranking_metrics(G, logistic_regression_object, columns_to_use, path_to_vertex_metrics_folder, year_interval, R):\n",
    "    '''\n",
    "    Computes the rank score metric for a given logistic regression object.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    G: network (so we can get each cases' ancestor network)\n",
    "\n",
    "    logistic_regression_object: a logistic regression object (i.e. the output of fit_logistic_regression)\n",
    "\n",
    "    columns_to_use: list of column names of edge metrics data frame that we should use to fit logistic regression\n",
    "\n",
    "    path_to_vertex_metrics_folder: we will need these for prediciton\n",
    "\n",
    "    year_interval: the year interval between each vertex metric .csv file\n",
    "\n",
    "    R: how many cases to compute ranking metrics for\n",
    " \n",
    "    Output\n",
    "    -------\n",
    "    The average ranking score over all R cases we tested\n",
    "    '''\n",
    "    \n",
    "    #select cases for sample\n",
    "    vertices = set(G.vs)\n",
    "    cases_to_test = random.sample(vertices, R)\n",
    "\n",
    "    cases_to_test_rank_scores = []\n",
    "\n",
    "    #load all the vertex metric dataframes into a dict so they only have to be read in once\n",
    "    all_vertex_metrics_df = glob.glob(path_to_vertex_metrics_folder + \"/vertex_metrics*.csv\")\n",
    "    vertex_metric_dict = {}\n",
    "    for vertex_metrc_df in all_vertex_metrics_df:\n",
    "        #add df to dict with filepath as key\n",
    "        vertex_metric_dict[vertex_metrc_df] = pd.read_csv(vertex_metrc_df, index_col=0)\n",
    "    \n",
    "    #calculate each case's score\n",
    "    for case in cases_to_test:\n",
    "\n",
    "        #determine which vertex_df to retrieve\n",
    "        year = case['year'] + (year_interval - case['year']%year_interval)\n",
    "        \n",
    "        #look-up that dataframe from given path\n",
    "        vertex_df = vertex_metric_dict[path_to_vertex_metrics_folder + '\\\\vertex_metrics_' + str(year) + '.csv']\n",
    "        \n",
    "        #create df that the logistical regression object will evaluate\n",
    "        x_test_df = vertex_df[columns_to_use]\n",
    "        attachment_p = get_attachment_probabilty(logistic_regression_object, x_test_df)\n",
    "\n",
    "        # add the attachment probabilities as column\n",
    "        vertex_df['attachment_p'] = attachment_p\n",
    "        # sort by attachment probabilities\n",
    "        vertex_df = vertex_df.sort_values('attachment_p', ascending=False, kind='mergesort')#.reset_index(drop=True)\n",
    "\n",
    "        # get neighbors\n",
    "        neighbors = G.neighbors(case.index, mode='OUT')\n",
    "\n",
    "        # rank and score neighbors using dataframe indices\n",
    "        scores = [] # list of scores for each vertex\n",
    "        for i in neighbors:\n",
    "            rank = vertex_df.index.get_loc(G.vs[i]['name']) + 1\n",
    "            score = 1-rank/len(attachment_p)\n",
    "            scores.append(score)\n",
    "        \n",
    "        case_rank_score = sum(scores) # sum up the scores for each case\n",
    "        \n",
    "        #add score to list of all cases' scores\n",
    "        cases_to_test_rank_scores.append(case_rank_score)\n",
    "\n",
    "    return np.mean(cases_to_test_rank_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_attachment_probabilty(logistic_regression_object, x_test_df):\n",
    "    '''\n",
    "    Evaluates our logistic regression model for a given dataset.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    logistic_regression_object: a logistic regression object (i.e. the output of fit_logistic_regression)\n",
    "\n",
    "    x_test_df: columns of vertex_df used in evaluating the logistical regression\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    returns a list of attachment probabilities for the dataset\n",
    "    '''\n",
    "    \n",
    "    # get attachment probabilities on testing set\n",
    "    prob = logistic_regression_object.predict_proba(x_test_df)\n",
    "    \n",
    "    # predicted probabilities for ALL case for edge present (1)\n",
    "    prob_present = prob[:,1:2]\n",
    "    # convert to list\n",
    "    prob_present_list = [i.tolist()[0] for i in prob_present]\n",
    "    \n",
    "    return prob_present_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing above defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_logistic_regression(path_to_edge_data_frame, columns_to_use):\n",
    "    '''\n",
    "    Fits our logistic regression model. Any data you need for logistic regression should be in the edge data frame\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    path_to_edge_data_frame:\n",
    "\n",
    "    columns_to_use: list of column names of edge metrics data frame that we should use to fit logistic regression\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    returns a logistic regression object \n",
    "    '''\n",
    "    #set up training data\n",
    "    df = pd.read_csv(path_to_edge_data_frame, index_col=0)\n",
    "    y_train = df['edge']\n",
    "    x_train = df[columns_to_use]\n",
    "\n",
    "    #calculate logistical regression\n",
    "    clf = skl_lm.LogisticRegression(solver='newton-cg')\n",
    "    clf.fit(x_train, y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This def is not required, I just used it to make excuted code concise\n",
    "def load_scotus_graph():\n",
    "    G = load_citation_network_igraph(data_dir, court_name)\n",
    "    all_edges = G.get_edgelist() # list of tuples\n",
    "    bad_edges = []\n",
    "    for edge in all_edges:\n",
    "        citing_year = G.vs(edge[0])['year'][0]\n",
    "        cited_year = G.vs(edge[1])['year'][0]\n",
    "    \n",
    "        if citing_year < cited_year:\n",
    "            bad_edges.append(edge)\n",
    "\n",
    "    G.delete_edges(bad_edges)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_edge_data_frame = 'C:\\\\Research\\\\law-net\\\\explore\\\\James\\\\edge_data.csv'\n",
    "columns_to_use = ['indegree','pagerank']\n",
    "logistic_regression_object = fit_logistic_regression(path_to_edge_data_frame, columns_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 seconds for 250465 edges\n"
     ]
    }
   ],
   "source": [
    "G = load_scotus_graph()\n",
    "path_to_vertex_metrics_folder = 'C:\\\\Research\\\\law-net\\\\explore\\\\James'\n",
    "year_interval = 10\n",
    "R = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.9000145966315207"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_ranking_metrics(G, logistic_regression_object, columns_to_use, path_to_vertex_metrics_folder, year_interval, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
