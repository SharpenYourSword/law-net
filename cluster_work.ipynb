{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# modify these for your own computer\n",
    "#repo_directory = '/Users/iaincarmichael/Dropbox/Research/law/law-net/'\n",
    "repo_directory = '/Users/Michael/Documents/GitHub/law-net/'\n",
    "\n",
    "#data_dir = '/Users/iaincarmichael/Documents/courtlistener/data/'\n",
    "data_dir = '/Users/Michael/Desktop/network_data/'\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# graph package\n",
    "import igraph as ig\n",
    "\n",
    "\n",
    "# stat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import scipy.sparse\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "\n",
    "# our code\n",
    "sys.path.append(repo_directory + 'code/')\n",
    "from summarize_clusters import *\n",
    "\n",
    "sys.path.append(repo_directory + 'vertex_metrics_experiment/code/')\n",
    "#from bag_of_words import load_tf_idf\n",
    "from bag_of_words import * \n",
    "\n",
    "# which network to download data for\n",
    "network_name = 'scotus' # 'federal', 'ca1', etc\n",
    "\n",
    "\n",
    "# some sub directories that get used\n",
    "raw_dir = data_dir + 'raw/'\n",
    "subnet_dir = data_dir + network_name + '/'\n",
    "text_dir = subnet_dir + 'textfiles/'\n",
    "nlp_dir = subnet_dir + 'nlp/'\n",
    "nlp_sub_dir = nlp_dir + 'bow_tfidf/' #tfidf matrix (and other info, i.e. vocab) computed from bag-of-words matrix\n",
    "nlp_bow_dir = nlp_dir + 'bow/' #bag-of-words matrix (and other info, i.e. vocab)\n",
    "\n",
    "# all the file paths for .txt files\n",
    "file_paths = glob.glob(text_dir + '*.txt')\n",
    "\n",
    "# csv location\n",
    "csv_dir = \"C:/Users/Michael/Documents/GitHub/law-net/csv/\"\n",
    "\n",
    "# jupyter notebook settings\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import cPickle as pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from text_normalization import *\n",
    "from pipeline_helper_functions import save_sparse_csr, load_sparse_csr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load tf-idf vector, bow vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_matrix, op_id_to_bow_id, vocab = load_tf_idf(nlp_sub_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_bow(nlp_dir):\n",
    "    \"\"\"\n",
    "    bow_matrix, op_id_to_bow_id = load_bow(nlp_dir)\n",
    "    \"\"\"\n",
    "    bow_matrix = load_sparse_csr(nlp_dir + 'bag_of_words_matrix.npz')\n",
    "\n",
    "    with open(nlp_dir + 'op_id_to_bow_id.p', 'rb') as f:\n",
    "        op_id_to_bow_id = pickle.load(f)\n",
    "\n",
    "    with open(nlp_dir + 'vocab.p', 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "\n",
    "    return bow_matrix, op_id_to_bow_id, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow_matrix, op_id_to_bow_id_2, vocab_2 = load_bow(nlp_bow_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the graph\n",
    "G = ig.Graph.Read_GraphML(subnet_dir + network_name +'_network.graphml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# largest connected component\n",
    "\n",
    "restrict our attention to the largest connected componenet on the network. also we are missing some text files from 2016 so lets ignore 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# limit ourselves to cases upto and including 2015 since we are missing some textfiles from 2016\n",
    "G = G.subgraph(G.vs.select(year_le=2015))\n",
    "\n",
    "# make graph undirected\n",
    "Gud = G.copy()\n",
    "Gud = Gud.as_undirected()\n",
    "\n",
    "# get largest connected componenet\n",
    "components = Gud.clusters(mode='STRONG')\n",
    "g = components.subgraphs()[np.argmax(components.sizes())]\n",
    "\n",
    "# CL ids of cases in largest connected component\n",
    "CLids = g.vs['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph clustering\n",
    "\n",
    "Do community detection on network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modularity on undirected scotus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering with 24724 elements and 126 clusters\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# modularity clustering\n",
    "cd_modularity = g.community_fastgreedy() # .as_clustering().membership\n",
    "\n",
    "mod_clust = cd_modularity.as_clustering()\n",
    "\n",
    "print mod_clust.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_clusters = pd.Series(mod_clust.membership, index=g.vs['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get a cluster of opinions (cluster 3 of modularity) to use for summarize cluster functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of opinions in cluster 3 of modularity:  1458\n"
     ]
    }
   ],
   "source": [
    "cluster_3_mod = graph_clusters[graph_clusters == 3].index.tolist()\n",
    "print \"number of opinions in cluster 3 of modularity: \", len(cluster_3_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## walktrap on undirected scotus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering with 24724 elements and 2264 clusters\n",
      "Wall time: 2min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# walktrap clustering\n",
    "cd_walktrap = g.community_walktrap()\n",
    "\n",
    "wt_clust = cd_walktrap.as_clustering()\n",
    "\n",
    "print wt_clust.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "walktrap_clusters = pd.Series(wt_clust.membership, index=g.vs['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K means clustering on tf-idf\n",
    "**problem**: takes 1-3 hours for me..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# set number of clusters\n",
    "num_clusters = 30\n",
    "\n",
    "# run kmeans\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(tfidf_matrix)\n",
    "\n",
    "nlp_tfidf_clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian-Mixture-Model (GMM) Clustering on tf-idf\n",
    "**problem**: can't do it on sparse matrices  \n",
    "**treatments/solutions**:  \n",
    "1. remove words with really high or low document frequency (tweak min_df and max_df when making bow or tfidf matrices)  \n",
    "2. apply PCA to severely cut down dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# set number of clusters\n",
    "\n",
    "# run GMM\n",
    "gmm = GaussianMixture(n_components=1)\n",
    "gmm.fit(tfidf_matrix)\n",
    "\n",
    "gmm_clusters = gmm.labels_.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare NLP clustering (tfidf) vs graph clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clusters = pd.DataFrame(index=normalized_text_dict.keys(), columns=['nlp', 'graph'])\n",
    "clusters = pd.DataFrame(index=op_id_to_bow_id, columns=['km', 'mod'])\n",
    "\n",
    "# add in communities \n",
    "clusters['mod'] = graph_clusters\n",
    "\n",
    "# consider nodes not considered in CD to be their own cluster\n",
    "# i.e. nodes outside the largest connected component\n",
    "clusters['mod'].fillna(max(graph_clusters) + 1, inplace=True)\n",
    "\n",
    "# make formatting\n",
    "clusters['mod'] = clusters['mod'].astype(np.int)\n",
    "\n",
    "# add in NLP clusters\n",
    "clusters['km'] = nlp_tfidf_clusters\n",
    "\n",
    "# add in walktrap clusters\n",
    "clusters['wt'] = walktrap_clusters\n",
    "clusters['wt'].fillna(max(walktrap_clusters) + 1, inplace=True)\n",
    "clusters['wt'] = clusters['wt'].astype(np.int)\n",
    "\n",
    "clusters.to_csv(csv_dir + \"clusters_full_tfidf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cluster pandas dataframe saved in current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>km</th>\n",
       "      <th>mod</th>\n",
       "      <th>wt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145658</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89370</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89371</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89372</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89373</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>89374</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>89375</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>89376</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>89377</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>89378</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>89379</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2224796</td>\n",
       "      <td>24</td>\n",
       "      <td>126</td>\n",
       "      <td>2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>103549</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>103548</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>103541</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>103540</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>103543</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>103542</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>103545</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>103544</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>103547</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>103546</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>88395</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>88394</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>88397</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>88396</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>88391</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>88390</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>88393</td>\n",
       "      <td>22</td>\n",
       "      <td>126</td>\n",
       "      <td>2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>88392</td>\n",
       "      <td>16</td>\n",
       "      <td>126</td>\n",
       "      <td>2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27855</th>\n",
       "      <td>88977</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27856</th>\n",
       "      <td>88976</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27857</th>\n",
       "      <td>88979</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27858</th>\n",
       "      <td>88978</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27859</th>\n",
       "      <td>96208</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27860</th>\n",
       "      <td>96209</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27861</th>\n",
       "      <td>96200</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27862</th>\n",
       "      <td>96201</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27863</th>\n",
       "      <td>96202</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27864</th>\n",
       "      <td>96203</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27865</th>\n",
       "      <td>96204</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27866</th>\n",
       "      <td>96205</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27867</th>\n",
       "      <td>96206</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27868</th>\n",
       "      <td>96207</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27869</th>\n",
       "      <td>88971</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27870</th>\n",
       "      <td>88970</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27871</th>\n",
       "      <td>88973</td>\n",
       "      <td>12</td>\n",
       "      <td>126</td>\n",
       "      <td>2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27872</th>\n",
       "      <td>88972</td>\n",
       "      <td>10</td>\n",
       "      <td>126</td>\n",
       "      <td>2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27873</th>\n",
       "      <td>88975</td>\n",
       "      <td>27</td>\n",
       "      <td>126</td>\n",
       "      <td>2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27874</th>\n",
       "      <td>88974</td>\n",
       "      <td>12</td>\n",
       "      <td>126</td>\n",
       "      <td>2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27875</th>\n",
       "      <td>103099</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27876</th>\n",
       "      <td>103098</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27877</th>\n",
       "      <td>103097</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27878</th>\n",
       "      <td>103096</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27879</th>\n",
       "      <td>103095</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27880</th>\n",
       "      <td>103094</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27881</th>\n",
       "      <td>103093</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27882</th>\n",
       "      <td>103092</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27883</th>\n",
       "      <td>103091</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27884</th>\n",
       "      <td>103090</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27885 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  km  mod    wt\n",
       "0          145658  12    1     5\n",
       "1           89370  12    3   294\n",
       "2           89371   9    0    35\n",
       "3           89372  12    0     3\n",
       "4           89373  20    0     3\n",
       "5           89374   2    2     4\n",
       "6           89375  16    2     5\n",
       "7           89376  25    2     6\n",
       "8           89377  22    2     7\n",
       "9           89378  14    2     7\n",
       "10          89379  14    2     8\n",
       "11        2224796  24  126  2264\n",
       "12         103549   8    2     1\n",
       "13         103548   8    0     1\n",
       "14         103541  14    0     1\n",
       "15         103540   2    0    11\n",
       "16         103543  12    2     9\n",
       "17         103542  14    2     9\n",
       "18         103545   7    0    12\n",
       "19         103544   4    0     1\n",
       "20         103547  22    2    13\n",
       "21         103546  22    0    12\n",
       "22          88395   1    0    15\n",
       "23          88394  14    0    58\n",
       "24          88397  14    2     1\n",
       "25          88396  10    0    16\n",
       "26          88391  28    2    17\n",
       "27          88390  22    2    18\n",
       "28          88393  22  126  2264\n",
       "29          88392  16  126  2264\n",
       "...           ...  ..  ...   ...\n",
       "27855       88977  24    1     3\n",
       "27856       88976  14    2   802\n",
       "27857       88979  12    2     7\n",
       "27858       88978   6    0    52\n",
       "27859       96208  11    2    13\n",
       "27860       96209  27    0   215\n",
       "27861       96200  12    1     2\n",
       "27862       96201  27    0   956\n",
       "27863       96202  16    0   116\n",
       "27864       96203  12   40     1\n",
       "27865       96204  12    3    41\n",
       "27866       96205  17    1    30\n",
       "27867       96206  14    0  2263\n",
       "27868       96207  22    0    12\n",
       "27869       88971  13    1     2\n",
       "27870       88970  14    2     1\n",
       "27871       88973  12  126  2264\n",
       "27872       88972  10  126  2264\n",
       "27873       88975  27  126  2264\n",
       "27874       88974  12  126  2264\n",
       "27875      103099  27    1    68\n",
       "27876      103098  14    0    21\n",
       "27877      103097  12    1     1\n",
       "27878      103096  14    2     1\n",
       "27879      103095  14    2    25\n",
       "27880      103094   2    0     1\n",
       "27881      103093  15    2    30\n",
       "27882      103092  17    2    30\n",
       "27883      103091   2    3   352\n",
       "27884      103090  14    3    13\n",
       "\n",
       "[27885 rows x 4 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = pd.read_csv(csv_dir + 'clusters_full_tfidf.csv')\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize Cluster Function 1\n",
    "This function summarizes a set of opinions by returning the words that appear in these opinions with the highest tf-idf scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sort_coo(m):\n",
    "    '''\n",
    "    iterating through a csr (compressed sparse row) matrix:\n",
    "    (row_index, column_index) tf_idf_value\n",
    "    \n",
    "    return a list of tuples (row, column, value), sorted by tf-idf values in descending order\n",
    "    '''\n",
    "    m = m.tocoo()\n",
    "    list_of_tuples = []\n",
    "    for i,j,k in zip(m.row, m.col, m.data):\n",
    "        list_of_tuples.append((i,j,k)) # list of tuples\n",
    "    return sorted(list_of_tuples, key=lambda x: x[2], reverse=True) # sort by tfidf values (descending)\n",
    "\n",
    "def top_k_words(opinions, num_words, tfidf_matrix, op_id_to_bow_id, vocab):\n",
    "    \"\"\"\n",
    "    This function summarizes a set of opinions by returning the words that appear in these opinions with the highest tf-idf scores.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    opinions: list of opinion ids\n",
    "    num_words: number of words to return as the summary\n",
    "    tfidf_matrix: the tf-idf matrix of all SCOTUS opinions\n",
    "    op_id_to_bow_id: dict that maps opinion ids to rows of the tfidf matrix\n",
    "\n",
    "    Output\n",
    "    -------\n",
    "    a list of the words with highest tf-idf scores amount the given opinions\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # op_id_to_bow_id['opinion_id'] = 'row_index'\n",
    "    \n",
    "    vocab = np.array(vocab)\n",
    "    n = num_words\n",
    "    row_indices = []\n",
    "    \n",
    "    # get row indices corresponding to the opinions\n",
    "    for each_opinion in opinions:\n",
    "        row_index = op_id_to_bow_id[each_opinion]\n",
    "        row_indices.append(row_index)\n",
    "    \n",
    "    # construct matrix with rows (opinions) from cluster\n",
    "    new_matrix = tfidf_matrix[row_indices, :]\n",
    "    \n",
    "    # return the matrix as sorted listed-of-tuples (descending sort by tf-idf values)\n",
    "    sorted_matrix = sort_coo(new_matrix)\n",
    "    \n",
    "    # get the column indices\n",
    "    column_ind = [x[1] for x in sorted_matrix]\n",
    "    \n",
    "    # get the words from column indices\n",
    "    top_words = vocab[column_ind].tolist()[:n]\n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'shaeffer', u'wool', u'carusi', u'toy', u'seed', u'jen', u'paper', u'renfrow', u'pearl', u'cork', u'tile', u'cadet', u'pardon', u'postmast', u'hilsman', u'ore', u'collector', u'nail', u'hoppl', u'frerich']\n",
      "Wall time: 2.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#opinions = ['1722', '1723', '1724']\n",
    "top_words = top_k_words(cluster_3_mod, 20, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "print top_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize Cluster Function 2\n",
    "compute the mean tf-idf vector of the cluster, return the top K words from this mean vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def top_k_words_from_mean_vector(opinions, num_words, tfidf_matrix, op_id_to_bow_id, vocab):\n",
    "    '''\n",
    "    compute the mean tf-idf vector of the cluster, return the top K words from this mean vector\n",
    "    '''\n",
    "    \n",
    "    # op_id_to_bow_id['opinion_id'] = 'row_index'\n",
    "\n",
    "    vocab = np.array(vocab)\n",
    "    n = num_words\n",
    "    row_indices = []\n",
    "    \n",
    "    # get row indices corresponding to the opinions\n",
    "    for each_opinion in opinions:\n",
    "        row_index = op_id_to_bow_id[each_opinion]\n",
    "        row_indices.append(row_index)\n",
    "    \n",
    "    # construct a matrix with rows (opinions) from cluster\n",
    "    new_matrix = tfidf_matrix[row_indices, :]\n",
    "    \n",
    "    # to take the mean of each col (use axis=1 to take mean of each row)\n",
    "    mean_matrix = new_matrix.mean(axis=0) # 1 X 567570 row matrix \n",
    "    \n",
    "    # get the column indices\n",
    "    column_ind = np.argsort(mean_matrix, axis=1)[:, ::-1] # descending order\n",
    "    \n",
    "    # get the words from column indices\n",
    "    top_words = vocab[column_ind].tolist()[0][:n]\n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'court', u'state', u'act', u'unit', u'case', u'v', u'upon', u'said', u'contract', u'offic', u'law', u'made', u'shall', u'defend', u'plaintiff', u'error', u'duti', u'u', u'section', u'claim']\n",
      "Wall time: 449 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#opinions = ['1722', '1723', '1724']\n",
    "top_words_from_mean = top_k_words_from_mean_vector(cluster_3_mod, 20, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "print top_words_from_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize Cluster Function 3\n",
    "compute the mean tf-idf vector of the cluster and also of the complement of the cluster,  \n",
    "take the difference mu_cluster - mu_complement, return the top K words in this difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def top_k_words_from_difference(opinions, all_opinions, num_words, tfidf_matrix, op_id_to_bow_id, vocab):\n",
    "    '''\n",
    "    compute the mean tf-idf vector of the cluster and also of the complement of the cluster, \n",
    "    take the difference mu_cluster - mu_complement, return the top K words in this difference    \n",
    "    '''\n",
    "    \n",
    "    # op_id_to_bow_id['opinion_id'] = 'row_index'\n",
    "    \n",
    "    vocab = np.array(vocab)\n",
    "    n = num_words\n",
    "    row_indices = []\n",
    "    \n",
    "    # get row indices corresponding to the opinions\n",
    "    for each_opinion in opinions:\n",
    "        row_index = op_id_to_bow_id[each_opinion]\n",
    "        row_indices.append(row_index)\n",
    "    \n",
    "    # construct a matrix with rowss (opinions) from cluster\n",
    "    cluster_matrix = tfidf_matrix[row_indices, :]\n",
    "\n",
    "    # to take the mean of each col (use axis=1 to take mean of each row)\n",
    "    mean_matrix = cluster_matrix.mean(axis=0) # 1 X 567570 row matrix\n",
    "    \n",
    "    \n",
    "    \n",
    "    # complement of cluster (all the other opinions)\n",
    "    opinions_compl = [x for x in all_opinions if x not in opinions]\n",
    "    \n",
    "    # get row indices corresponding to complement of cluster\n",
    "    row_indices_compl = []\n",
    "    for each_opinion in opinions_compl:\n",
    "        row_index = op_id_to_bow_id[each_opinion]\n",
    "        row_indices_compl.append(row_index)\n",
    "    \n",
    "    # construct a matrix with rows (opinions) from complement of cluster\n",
    "    compl_matrix = tfidf_matrix[row_indices_compl, :]\n",
    "    \n",
    "    # to take the mean of each col (use axis=1 to take mean of each row)\n",
    "    mean_matrix_compl = compl_matrix.mean(axis=0) # 1 X 567570 row matrix\n",
    "    \n",
    "    \n",
    "    \n",
    "    # mu_cluster - mu_complement\n",
    "    final_mean_matrix = mean_matrix - mean_matrix_compl\n",
    "    \n",
    "    # get the column indices\n",
    "    column_ind = np.argsort(final_mean_matrix, axis=1)[:, ::-1] # descending order\n",
    "    \n",
    "    # get the words from column indices\n",
    "    top_words = vocab[column_ind].tolist()[0][:n]\n",
    "    \n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of all text files (all opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_opinions(file_paths):\n",
    "    '''\n",
    "    Get list of all opinions/text files from the (.txt) file paths\n",
    "    '''\n",
    "    \n",
    "    all_opinions = []\n",
    "    for i in file_paths:\n",
    "        num = re.search(r'(\\d+)', i)\n",
    "        num = num.group()\n",
    "        all_opinions.append(num)\n",
    "    \n",
    "    # sort the list\n",
    "    all_opinions = map(int, all_opinions) # convert all elements of list into type(int)\n",
    "    all_opinions.sort()\n",
    "    \n",
    "    # convert list back to list of strings\n",
    "    all_opinions = map(str, all_opinions)\n",
    "    \n",
    "    return all_opinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1722\n",
      "4023639\n",
      "<type 'str'>\n"
     ]
    }
   ],
   "source": [
    "all_the_opinions = all_opinions(file_paths)\n",
    "print all_the_opinions[0]\n",
    "print all_the_opinions[-1]\n",
    "print type(all_the_opinions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'indict', u'offic', u'collector', u'duti', u'unit', u'contract', u'navi', u'claimant', u'treasuri', u'act', u'servic', u'depart', u'articl', u'cent', u'shall', u'apprais', u'govern', u'section', u'charg', u'made']\n",
      "Wall time: 3.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#opinions = ['1722', '1723', '1724']\n",
    "top_words_from_diff = top_k_words_from_difference(cluster_3_mod, all_the_opinions, 20, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "print top_words_from_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize Cluster Function 4\n",
    "compute the mean tf-idf vector, return the document in the cluster closet to the mean  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def document_closest_to_mean(opinions, tfidf_matrix, op_id_to_bow_id):\n",
    "    '''\n",
    "    compute the mean tf-idf vector, return the document in the cluster closet to the mean  \n",
    "    '''\n",
    "    \n",
    "    # op_id_to_bow_id['opinion_id'] = 'row_index'\n",
    "\n",
    "    row_indices = []\n",
    "    \n",
    "    # get row indices corresponding to the opinions\n",
    "    for each_opinion in opinions:\n",
    "        row_index = op_id_to_bow_id[each_opinion]\n",
    "        row_indices.append(row_index)\n",
    "    \n",
    "    # construct a matrix with rows (opinions) from cluster\n",
    "    new_matrix = tfidf_matrix[row_indices, :]\n",
    "    \n",
    "    # to take the mean of each col (use axis=1 to take mean of each row)\n",
    "    mean_matrix = new_matrix.mean(axis=0) # 1 X 567570 row matrix\n",
    "    \n",
    "    # convert to vector (since row matrix)\n",
    "    mean_vector = np.squeeze(np.asarray(mean_matrix))\n",
    "    \n",
    "    # get the euclidean distance between mean vector and all other cluster, row vectors\n",
    "    euc_dist = {}\n",
    "    for i in row_indices:\n",
    "        row_vector = np.squeeze(np.asarray(tfidf_matrix[i].toarray()))\n",
    "        euc_dist[i] = np.linalg.norm(mean_vector-row_vector)\n",
    "    \n",
    "    # get row index closest to mean vector (minimum euclidian distance to mean vector)\n",
    "    row_index_close = min(euc_dist, key=euc_dist.get)\n",
    "    \n",
    "    # get opinion closest to mean vector\n",
    "    for opinion, row_index in op_id_to_bow_id.iteritems():\n",
    "        if row_index == row_index_close:\n",
    "            return opinion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opinion 86062\n",
      "Wall time: 7.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#opinions = ['1722', '1723', '1724']\n",
    "most_relev_op = document_closest_to_mean(cluster_3_mod, tfidf_matrix, op_id_to_bow_id)\n",
    "print \"opinion\", most_relev_op"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
